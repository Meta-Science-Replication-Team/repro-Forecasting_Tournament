---
title: "Wave 1+2 Analyses"
author: "Igor Grossmann"
date: "7/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)

options(max.print = 20000, scipen = 1000)

```

```{r setup working directory}
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
```

```{r Import Data}

dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)

# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 )

#datasets that are filtered by phase (1 = May submission, 2 = November submission)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)

# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)

objective<-dat %>% filter(Method=="Objective", phase ==1) %>% select(domain:Month.12)
```


```{r create subsets for separate visualizations}
#####download of phase 1 and 2 files########################
t1.academ.sorted<-phase1_exp %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% mutate(Rank = row_number()) %>% add_count(name="Nteams")%>% select(team_name,domain,Rank, Nteams,Method.code, Month.1:Month.12,mean_abs_error_w1,MASE1_w1)
t1.academ.sorted$Domains[t1.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="polar"]<-"Political Polarization"


t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>% 
  group_by(domain) %>% summarise(across(where(is.numeric), mean)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="average non-academic")

t1.nonacadem.median.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,,Method.code) %>% 
  group_by(domain) %>% summarise(across(where(is.numeric), median)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="median non-academic")

t1.nonacadem.best.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>% 
  group_by(domain) %>% summarise(across(where(is.numeric), min)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="top non-academic")

t1.academ.best.sorted<-phase1 %>% filter(isExpert.factor == 'Academic') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>% 
  group_by(domain) %>% summarise(across(where(is.numeric), min)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="top academic")

t1.top.scores<-rbind(t1.academ.best.sorted,t1.nonacadem.best.sorted)%>% arrange(domain,MASE1_w1)
#so, only for life satisfaction and polarization, best academic was better than best non-academic. For all other domains, non-academics were in fact better (but note that the sample of non-academic was larger)

#what is the percentage of academics and lay people, respectively, who were below 1 on MASE?

t1.scores<-rbind(t1.academ.sorted,t1.nonacadem.median.sorted)
write.csv(t1.scores,"wave1.scores.csv")

t2.academ.sorted<-academic_only %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% mutate(Rank = row_number()) %>% add_count(name="Nteams") %>% select(team_name,domain,Rank,Nteams,Method.code,phase,revised,Month.7:Month.12,mean_abs_error_w2,MASE1_w2)
t2.academ.sorted$Domains[t2.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="polar"]<-"Political Polarization"

write.csv(t2.academ.sorted,"wave2.scores.csv")

objective$Domains[objective$domain=="eafric"]<-"Explicit African American Bias"
objective$Domains[objective$domain=="easian"]<-"Explicit Asian American Bias"
objective$Domains[objective$domain=="egend"]<-"Explicit Gender-Career Bias"
objective$Domains[objective$domain=="iafric"]<-"Implicit African American Bias"
objective$Domains[objective$domain=="iasian"]<-"Implicit Asian American Bias"
objective$Domains[objective$domain=="igend"]<-"Implicit Gender-Career Bias"
objective$Domains[objective$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
objective$Domains[objective$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
objective$Domains[objective$domain=="lifesat"]<-"Life Satisfaction"
objective$Domains[objective$domain=="negaffect"]<-"Negative Affect in Social Media"
objective$Domains[objective$domain=="posaffect"]<-"Positive Affect in Social Media"
objective$Domains[objective$domain=="polar"]<-"Political Polarization"
```

```{r create a file to share with teams}
t1.academ.sorted<-t1.academ.sorted %>% rename(MASE=MASE1_w1,MAE=mean_abs_error_w1,
                                              May2020=Month.1,
                                              June2020=Month.2,
                                              July2020=Month.3,
                                              August2020=Month.4,
                                              Sept2020=Month.5,
                                              Oct2020=Month.6,
                                              Nov2020=Month.7,
                                              Dec2020=Month.8,
                                              Jan2021=Month.9,
                                              Feb2021=Month.10,
                                              March2021=Month.11,
                                              April2021=Month.12)
t1.academ.sorted$Tournament<-"May - 12-months"
t2.academ.sorted<-t2.academ.sorted %>% rename(MASE=MASE1_w2,MAE=mean_abs_error_w2,
                                              Nov2020=Month.7,
                                              Dec2020=Month.8,
                                              Jan2021=Month.9,
                                              Feb2021=Month.10,
                                              March2021=Month.11,
                                              April2021=Month.12)

t2.academ.sorted$Tournament<-"November - 6-months"

objective<-objective %>% rename(May2020=Month.1,
                                              June2020=Month.2,
                                              July2020=Month.3,
                                              August2020=Month.4,
                                              Sept2020=Month.5,
                                              Oct2020=Month.6,
                                              Nov2020=Month.7,
                                              Dec2020=Month.8,
                                              Jan2021=Month.9,
                                              Feb2021=Month.10,
                                              March2021=Month.11,
                                              April2021=Month.12)
objective$Tournament<-"Ground truth marker"

results<-rbind(t1.academ.sorted,t2.academ.sorted,objective) %>% ungroup() %>% select(-domain,-Method.code, -(phase:revised)) 

results<-results %>% arrange(Tournament) %>% relocate(where(is.numeric), .after = where(is.character))
write.csv(results,"final.results.csv")

```


```{r visualize top performers}

pd <- position_dodge(0.7) # move them .07 to the left and right
labels<-c(
  eafric = "Exp. African\n-Am. Bias",
  easian = "Exp. Asian\n-Am. Bias",
  egend = "Exp. \nGender Bias",
  iafric = "Imp. African\n-Am. Bias",
  iasian = "Imp. Asian\n-Am. Bias",
  ideoldem = "Dem.\nSupport",
  ideolrep ="Rep.\nSupport",
  igend = "Imp.\nGender Bias",
  lifesat = "Life\nSatisfaction",
  negaffect = "Negative\nAffect",
  polar = "Polit.\nPolarization",
  posaffect = "Positive\nAffect")

#T1
##########################################################

#who won?
top.1.MASE.t1<-phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 1) %>% select(team_name,mean_abs_error_w1,MASE1_w1,Month.1:Month.12,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise) %>% arrange(MASE1_w1)
write.csv(top.1.MASE.t1,"top.t1.csv")

#examine top 5
top.5.MASE.t1<-phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w1,domain,compare_to_naive_linear_MASE,compare_to_naive_rwf_MASE,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)

top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=Method.code)) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_aaas(name="Approach")+ylab("MASE")

proportions(xtabs( ~ Method.code,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ domain+Method.code,top.5.MASE.t1),"domain")*100 #by domain

top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=compare_to_naive_linear_MASE, shape =compare_to_naive_rwf_MASE )) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Compared to\nLinear Model")+scale_shape_discrete(name="Compared to\nRandom Walk")+ylab("MASE")

top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=discipline)) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Field")+ylab("MASE")

proportions(xtabs( ~ discipline,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ domain+discipline,top.5.MASE.t1),"domain")*100 #by domain

top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=as.factor(previous_tournament.coded))) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Prior Forecasting Experience")+ylab("MASE")

proportions(xtabs( ~ previous_tournament.coded,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ previous_tournament.coded,phase1 %>% filter(isExpert.factor == 'Academic') ))*100 #baserate of prior experience to compare to top 5
proportions(xtabs( ~ domain+previous_tournament.coded,top.5.MASE.t1),"domain")*100 #by domain

phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
  ggplot(aes(x = domain, y = team_size.coded))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Size of Top 10 Teams (M +/- 95%CI)")
 
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
  ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)")

phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_gender))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")

phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_education))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y=" (M +/- 95%CI)")

phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_Age))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")

phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = non_US))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")

##comparison to lay people
proportions(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation

proportions(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1))

##comparison by method among academics
proportions(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1_exp))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1_exp, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))

proportions(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1))
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1_exp)) #just comparison of academics

##PHASE 2

#who won?
top.1.MASE.t2<-academic_only  %>% filter(!(phase == 1 & revised == 1)) %>% 
  arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 1) %>% select(domain,mean_abs_error_w2,MASE1_w2,team_name,mean_abs_percent_error_w2,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE_w2,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
  
write.csv(top.1.MASE.t2,"top.t2.csv")



#examine top 5

top.5.MASE.t2<-academic_only %>% filter(!(phase == 1 & revised == 1)) %>% 
  arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w2,domain,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE_w2,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
  
top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=Method.code)) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_aaas(name="Approach")+ylab("MASE")

proportions(xtabs( ~ Method.code,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ domain+Method.code,top.5.MASE.t2),"domain")*100 #by domain


top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=compare_to_naive_linear_MASE_w2, shape =compare_to_naive_rwf_MASE_w2 )) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Compared to\nLinear Model")+scale_shape_discrete(name="Compared to\nRandom Walk")+ylab("MASE")

top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=discipline)) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Field")+ylab("MASE")

proportions(xtabs( ~ discipline,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ domain+discipline,top.5.MASE.t2),"domain")*100 #by domain

top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=as.factor(previous_tournament.coded))) +  
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Prior Forecasting Experience")+ylab("MASE")

proportions(xtabs( ~ previous_tournament.coded,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ previous_tournament.coded,academic_only%>% filter(!(phase == 1 & revised == 1))))*100 #baserate of prior experience to compare to top 5
proportions(xtabs( ~ domain+previous_tournament.coded,top.5.MASE.t2),"domain")*100 #by domain

academic_only   %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
  ggplot(aes(x = domain, y = team_size.coded))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Size of Top 10 Teams (M +/- 95%CI)")
 
academic_only    %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
  ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)")

academic_only%>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
  ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)") #same as for top 10


academic_only   %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_gender))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")

academic_only   %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_education))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non_PHD per Team (M +/- 95%CI)")

academic_only   %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = team_Age))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")

academic_only  %>% filter(!(phase == 1 & revised == 1)) %>% 
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
  ggplot(aes(x = domain, y = non_US))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")



##comparison by method among academics
proportions(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,academic_only %>% filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,subset(academic_only%>% filter(!(phase == 1 & revised == 1)), compare_to_naive_rwf_MASE_w2!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation

proportions(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))))

#############################################################
```

# Visualize historical results

```{r}
historical<-read.csv("historical_data.csv")
library(tsibble)
historical_tsbl <- as_tsibble(historical, index = Month)

historical_tsbl %>% pivot_longer(negaffect:polar,names_to="Domain",values_to="Score") %>% 
  ggplot(aes(x = Month, y = Score, colour = Domain))+
  geom_smooth(aes(x = Month, y = Score, colour = Domain),method = "loess") +  
    facet_wrap(~Domain, scales = "free", nrow = 3, labeller=labeller(Domain=labels))+
  theme_minimal(base_size = 14) +
   theme(legend.position="none") +
  labs(x="Months (< 0 = before May 2020)",y="Estimate") 





```

# Phase 1 analyses 

```{r PHASE 1}


#do by method (among experts now)
#get ground truth markers (subset)
dat_long$Month0<-dat_long$Month-1

objective<-as.data.frame(subset(dat_long,phase == 1 & !is.na(Method.code)& Method.code=="Ground Truth"))

#get subset for analyses, focusing on value.dif column i -  absolute percent deviation for each predicted Month
#For models evaluating accuracy of individual time points, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain and time points as predictors, with absolute percent deviation scores nested within teams. 

dat_long_phase1<-dat_long %>%subset(phase == 1 & Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw")
dat_long_phase1$Method.code <- relevel(factor(dat_long_phase1$Method.code), "Lay People") #use lay people as a reference group

phase1$Method.code <- relevel(factor(phase1$Method.code), "Lay People") #use lay people as a reference group
phase1_exp$updated<-ifelse(phase1_exp$revised==1,"update","no update")
phase1$compare_to_naive_rwf_MASE.update<-ifelse(phase1$compare_to_naive_rwf_MASE!="Equal to Naive rwf",phase1$compare_to_naive_rwf_MASE,ifelse(phase1$compare_to_naive_rwf_MASE=="Equal to Naive rwf","Below Naive rwf",NA))
phase1_exp$teamS<-as.factor(ifelse(phase1_exp$team_size.coded>=6,3,ifelse(phase1_exp$team_size.coded<6&phase1_exp$team_size.coded>1,2,ifelse(phase1_exp$team_size.coded==1,1,NA))))
phase1_exp$is_multidisciplinary<-ifelse(phase1_exp$discipline=="Multi-disciplinary",1,0)
phase1_exp$objectivexpert<-ifelse(phase1_exp$pub==1,"Expert",ifelse(phase1_exp$pub==2,"Non Expert",NA))

dat_long_phase1$teamS<-as.factor(ifelse(dat_long_phase1$team_size.coded>=6,3,ifelse(dat_long_phase1$team_size.coded<6&dat_long_phase1$team_size.coded>1,2,ifelse(dat_long_phase1$team_size.coded==1,1,NA))))
dat_long_phase1$is_multidisciplinary<-ifelse(dat_long_phase1$discipline=="Multi-disciplinary",1,0)
dat_long_phase1$objectivexpert<-ifelse(dat_long_phase1$pub==1,"Expert",ifelse(dat_long_phase1$pub==2,"Non Expert",NA))

dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth") %>% 
   ggplot(aes(x = Month0, y = value, colour = Method.code, fill=Method.code))+
  geom_smooth(aes(x = Month0, y = value, colour = Method.code, fill=Method.code),method = "loess") +  
    facet_wrap(~domain, scales = "free", nrow = 3, labeller=labeller(domain=labels))+
  theme_minimal(base_size = 14) +
  geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ 
  labs(colour = "Sample",fill="Sample", x="Months (from May 2021)",y="Estimate (M +/- 95%CI)") 

#without the naive benchmarks
dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw") %>% 
   ggplot(aes(x = Month0, y = value, colour = Method.code, fill=Method.code))+
  geom_smooth(aes(x = Month0, y = value, colour = Method.code, fill=Method.code),method = "loess") +  
  facet_wrap(~domain, scales = "free", nrow = 3, labeller=labeller(domain=labels))+theme_minimal(base_size = 14) +
  geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ 
  labs(colour = "Sample",fill="Sample", x="Months (from May 2021)",y="Estimate (M +/- 95%CI)")


#######JUST PLOT _ ==>ELEGANT BUT ERRORS! IT MISSES THE WITHIN-PERSON STRUCTURE AND REPEATED OBSERVATIONS
#dat_long_phase1 %>% ggplot(aes(x = as.factor(Month), y = value.dif,colour = Method.code, fill=Method.code))+
#   stat_summary(fun.data="mean_cl_boot",  position=pd)+
#    facet_wrap(vars(domain), scales = "free", nrow = 4)+theme_minimal(base_size = 14) +
#   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
#  labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
# THIS METHOD ASSUMES INDEPENDENCE OF RESPONSES!!!

model.long.phase1<-  lmer(value.dif~domain*Method.code*Month0+(1|domain/ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #marg effect of method, sig Month, and domain * method

summ(model.long.phase1, digits=4) #to get R2
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain, adjust = "none") #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain|Month0, adjust = "none", at=list(Month0=c(0,5,11))) #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric
emmeans(model.long.phase1,pairwise ~domain|Method.code, adjust = "none") #overall differences by domain.
interactions::interact_plot(model.long.phase1,pred=Month0,modx =Method.code,mod2 = domain,interval = T, mod2.labels = c("Exp. Af-Am. Bias","Exp. As-Am. Bias","Exp. Gender Bias","Imp. Af-Am. Bias","Imp. As.-Am. Bias",
         "Democrats","Republicans","Imp. Gender Bias","Life Satisfaction","Negative Affect","Polit. Polarization","Positive Affect"),legend.main="", colors="Qual1")+facet_wrap(vars(domain), scales = "free", nrow = 4)+labs(x="Months (from May 2021)",y="Absolute Percentage Deviation (M +/- 95%CI)")
#get scores for visualizations
dat_long_phase1$Month.F<-as.factor(dat_long_phase1$Month0)
model.long.phase1.fac<-  lmer(value.dif~domain*Method.code*Month.F+(1|domain/ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1.fac,type="III") #marg effect of method, sig Month, and domain * method

data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1.fac,pairwise ~Method.code|domain|Month.F, adjust = "none")$emmeans) #get estimates for each month from a model where time is a factor


data.long.phase1.abs.dev %>% 
 ggplot(aes(x = Month.F, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=asymp.LCL, ymax=asymp.UCL), position=pd)+  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(~domain, scales = "free", nrow = 4, labeller=labeller(domain=labels))+
  labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")

#different plotting version (but weirdly adds a missing value where there can be none - so don't use)
interactions::cat_plot(model.long.phase1.fac,pred=Month.F,modx =Method.code,mod2 = domain,interval = T, mod2.labels = c("Exp. Af-Am. Bias","Exp. As-Am. Bias","Exp. Gender Bias","Imp. Af-Am. Bias","Imp. As.-Am. Bias",
         "Democrats","Republicans","Imp. Gender Bias","Life Satisfaction","Negative Affect","Polit. Polarization","Positive Affect"),legend.main="", colors="Qual3",interval.geom="linerange")+facet_wrap(vars(domain), scales = "free", nrow = 4)+labs(x="Months (from May 2021)",y="Absolute Percentage Deviation (M +/- 95%CI)")


#by method for phase 1

#analyses of phase 1  - MASE overall
#For models evaluating overall accuracy of the forecasted model, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain as predictors, with MASE scores nested within teams. 
model.phase1<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=phase1)
car::Anova(model.phase1,type="III") #no interaction, so just look at main effects

summ(model.phase1, digits=4)
emmeans(model.phase1,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")

data.phase1.MASE<-as.data.frame(emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")$emmeans)
data.phase1.MASE %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 
#data driven and hybrid is better than lay people for igen (marginal), life satisfaction (sig)

phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = Method.code, fill=Method.code))+geom_violin()+
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+
  labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")

##try to estimate overall fixed effects across domains

model.phase1.total<-  lmer(MASE1_w1~Method.code+(1|ResponseId), data=phase1)
car::Anova(model.phase1.total,type="III") #no interaction, so just look at main effects

summ(model.phase1.total, digits=4)
emmeans(model.phase1.total,trt.vs.ctrl ~Method.code, adjust = "none") #no difference, a trend of data being better than lay people

data.phase1.MASE.total<-as.data.frame(emmeans(model.phase1.total,pairwise ~Method.code, adjust = "none")$emmeans)
data.phase1.MASE.total %>% 
 ggplot(aes(x = Method.code, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

##with naive benchmarks
dat$ResponseId[dat$Method.code=="Naive-linear"]<-"Naive\nLinear Regression"
dat$ResponseId[dat$Method.code=="Naive-rfw"]<-"Naive\nRandom Walk"
dat$Method.code[dat$Method.code=="Naive-linear"]<-"Naive\nLinear Regression"
dat$Method.code[dat$Method.code=="Naive-rfw"]<-"Naive\nRandom Walk"
model.phase1.naive<-  lmer(MASE1_w1~Method.code+(1|ResponseId), data=filter(dat,Method.code=="Naive\nLinear Regression"|Method.code=="Naive\nRandom Walk"))

data.phase1.MASE.naive<-as.data.frame(emmeans(model.phase1.naive,pairwise ~Method.code, adjust = "none")$emmeans)

data.phase1.MASE.total.w.naive<-rbind(data.phase1.MASE.total,data.phase1.MASE.naive)
data.phase1.MASE.total.w.naive %>% 
 ggplot(aes(x = Method.code, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="none") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)

model.phase1.contrast<-  lmer(MASE1_w1~domain*method.contrast+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast,type="III") #sig domain effect,  and sig interaction

summ(model.phase1.contrast, digits=4) #get effect size for the overall model
emmeans(model.phase1.contrast,pairwise ~method.contrast|domain, adjust = "none")

#examine vs. benchmarks of accuracy 
## naive random walk
#to be able to calculate estimate scores==> equate at naive RW to below.
model.phase1.belowrw<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=subset(phase1,compare_to_naive_rwf_MASE.update=="Below Naive rwf"))
model.phase1.aboverw<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=subset(phase1,compare_to_naive_rwf_MASE.update=="Above Naive rwf"))

data.phase1.MASE.belowrw<-as.data.frame(emmeans(model.phase1.belowrw,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase1.MASE.aboverw<-as.data.frame(emmeans(model.phase1.aboverw,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase1.MASE.belowrw$cut<-"Better than Random Walk"
data.phase1.MASE.aboverw$cut<-"Worse than Random Walk"
data.phase1.MASE.rw<-rbind(data.phase1.MASE.belowrw,data.phase1.MASE.aboverw)
  
data.phase1.MASE.rw %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code,fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+facet_wrap(~cut, nrow=2, scale="free")+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labels, name="")+
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

emmeans(model.phase1.belowrw,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase1.aboverw,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest

# What percentage is better than naive random walk benchmark, per domain
naive_rwf_MASE_domain <- phase1_exp %>% group_by(domain, compare_to_naive_rwf_MASE) %>% 
  dplyr::summarise(N = length(compare_to_naive_rwf_MASE)) %>% ungroup() %>% 
  group_by(domain) %>% mutate(ptg = prop.table(N)*100) %>% ungroup() %>% 
  arrange(by_group=compare_to_naive_rwf_MASE,desc(ptg))
knitr::kable((naive_rwf_MASE_domain))

# Implicit Asian bias, explicit African American, and positive affect were all 100% above the cutoff
# More than 50% of predictions for implicit gender, ideology-republican, and ideology-democrat were below the cutoff

## naive linear regression
#to be able to calculate estimate scores==> equate at naive RWF to below.
phase1$compare_to_naive_linear_MASE.update<-ifelse(phase1$compare_to_naive_linear_MASE!="Equal to Naive linear",phase1$compare_to_naive_linear_MASE,ifelse(phase1$compare_to_naive_linear_MASE=="Equal to Naive linear","Below Naive linear",NA))
model.phase1.belowlinear<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=subset(phase1,compare_to_naive_linear_MASE.update=="Below Naive linear"))
model.phase1.abovelinear<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=subset(phase1,compare_to_naive_linear_MASE.update=="Above Naive linear"))

data.phase1.MASE.belowlinear<-as.data.frame(emmeans(model.phase1.belowlinear,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase1.MASE.abovelinear<-as.data.frame(emmeans(model.phase1.abovelinear,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase1.MASE.belowlinear$cut<-"Better than Linear Regression"
data.phase1.MASE.abovelinear$cut<-"Worse than Linear Regression"
data.phase1.MASE.linear<-rbind(data.phase1.MASE.belowlinear,data.phase1.MASE.abovelinear)
  
data.phase1.MASE.linear %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code,fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+facet_wrap(~cut, nrow=2, scale="free")+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labels, name="")+
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

emmeans(model.phase1.belowlinear,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase1.abovelinear,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest

# What percentage is better than naive linear regression benchmark, per domain
naive_linear_MASE_domain <- phase1_exp %>% group_by(domain, compare_to_naive_linear_MASE) %>% 
  dplyr::summarise(N = length(compare_to_naive_linear_MASE)) %>% ungroup() %>% 
  group_by(domain) %>% mutate(ptg = prop.table(N)*100) %>% ungroup() %>% 
  arrange(by_group=compare_to_naive_linear_MASE,desc(ptg))
knitr::kable((naive_linear_MASE_domain))

# Implicit Asian bias, explicit African American, and positive affect were all 100% above the cutoff
# More than 50% of predictions for implicit gender, ideology-republican, and ideology-democrat were below the cutoff

#get scores for ranking visualizations
phase1.means<-as.data.frame(emmeans(model.phase1,pairwise ~domain|Method.code, adjust = "none")$emmeans)
# reorder and get the order variable to maintain facet-specific orders (otherwise it get screwy)
phase1.means <- phase1.means %>%
  # 1. Remove grouping
  ungroup() %>%
  # 2. Arrange by
  #   i.  facet group
  #   ii. bar height
  arrange(Method.code, emmean) %>%
  # 3. Add order column of row numbers
  mutate(order = row_number())

#errorbar charts, with scores ordered
phase1.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +  
geom_point(size=3) + 
geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL))+
 facet_wrap(vars(Method.code), scales = "free", nrow=4)+theme_minimal() +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
  scale_x_continuous(   # Add categories to axis
    breaks = phase1.means$order,
    labels = phase1.means$domain,expand = c(0,0))+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE +/- 95% CI") 

#lollipop chart
phase1.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +  
geom_point(size=3) + 
  geom_segment(aes(x=order, 
                   xend=order, 
                   y=0, 
                   yend=emmean)) +facet_wrap(vars(Method.code), scales = "free")+
  scale_x_continuous(   # Add categories to axis
    breaks = phase1.means$order,
    labels = phase1.means$domain)+theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE") 

## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
model.phase1.update<-  lmer(MASE1_w1~domain*updated+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.update,type="III") #no interaction, just a sig effect of domain

emmeans(model.phase1.update,pairwise ~updated|domain, adjust = "none") #nonsig
#contrast difference of updating forecasts for explicit asian bias, life satisfaction, neg affect, polarization, pos affect

data.phase1.update<-as.data.frame(emmeans(model.phase1.update,pairwise ~updated|domain, adjust = "none")$emmeans) #nonsig

#visualize
data.phase1.update %>% 
 ggplot(aes(x = domain, y = emmean, colour = updated, fill=updated))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labels, name="")+
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

## TEAM TYPE AND CONFIDENCE (instead of forecasting type) as predictors. Academics only.

### overall MASE 
#### first, confidence
model.phase1.conf<-  lmer(MASE1_w1~domain*confidence+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.conf,type="III") #sig interaction
summ(model.phase1.conf, digits=4, center=T)
emtrends(model.phase1.conf,specs=pairwise~domain,var="confidence") #confidence plays a role for ideology republicans - the more confident the LOWER the mase scores and for LIFE SATISFACTION - the MORE confident the MORE error

##### second, team type - just academics
#####just count
model.phase1.team<-  lmer(MASE1_w1~domain*team_size.coded+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team,type="III") #sig interaction between domain and team size
summ(model.phase1.team, digits=4, center=T)
emtrends(model.phase1.team,specs=pairwise~domain,var="team_size.coded") #nothing
#####apriori defined groups
model.phase1.team3<-  lmer(MASE1_w1~domain*teamS+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team3,type="III") #no interaction between domain and team size
summ(model.phase1.team3, digits=4, center=T)
emmeans(model.phase1.team3,pairwise ~teamS|domain, adjust = "none") #nonsig

#### third, multidisciplinarity of the teams - just academics
model.phase1.multidis.team<-  lmer(MASE1_w1~domain*is_multidisciplinary+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.multidis.team,type="III") #interdisciplinary did not matter
summ(model.phase1.multidis.team, digits=4, center=T)
emmeans(model.phase1.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #nonsig

#### fourth, Rating of 1-7 of whether participants considered themselves experts on the domain being predicted
model.phase1.subexpert<-  lmer(MASE1_w1~domain*subexpert+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.subexpert,type="III") #
summ(model.phase1.subexpert, digits=4, center=T)
emtrends(model.phase1.subexpert,specs=pairwise~domain,var="subexpert") #

#### fifth, objective expertise based on publications in the domain (yes - no)
model.phase1.obexpert<-  lmer(MASE1_w1~domain*objectivexpert+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.obexpert,type="III") #
summ(model.phase1.obexpert, digits=4, center=T)
emmeans(model.phase1.obexpert,pairwise ~objectivexpert|domain, adjust = "none") #

#### six, number of predictors in the model 
model.phase1.predictors<-  lmer(MASE1_w1~numpred*domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.predictors,type="III") #npred matters!
summ(model.phase1.predictors, digits=4, center=T)
emtrends(model.phase1.predictors,specs=~domain,var="numpred") #
sjPlot::plot_model(model.phase1.predictors,type="int")

#### six and a half, number of predictors in the model using CODED scores
model.phase1.predictors.coded<-  lmer(MASE1_w1~parameters_coded*domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.predictors.coded,type="III") #npred matters!
summ(model.phase1.predictors.coded, digits=4, center=T)
emtrends(model.phase1.predictors.coded,specs=~domain,var="parameters_coded") #
sjPlot::plot_model(model.phase1.predictors.coded,type="int")

#### seventh, complexity of the model
model.phase1.complex<-  lmer(MASE1_w1~domain*Method.complex+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.complex,type="III") #npred matters!
summ(model.phase1.complex, digits=4, center=T)
emtrends(model.phase1.complex,specs=~domain,var="Method.complex") #
sjPlot::plot_model(model.phase1.complex,type="int")

model.phase1.complexF<-  lmer(MASE1_w1~domain*Method.complex.factor+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.complexF,type="III") #npred matters!
emmeans(model.phase1.complexF,pairwise ~Method.complex.factor|domain, adjust = "none") #nonsig
sjPlot::plot_model(model.phase1.complexF,type="int")

#### eight - CONDITIONALS - where they right for wrong reasons?

##### presence of covid as a conditional
phase1_exp$covidconditional<-ifelse(phase1_exp$covidcondyn==0,"No",ifelse(phase1_exp$covidcondyn==1,"Yes",NA))
model.phase1.wcovid<-  lmer(MASE1_w1~domain*covidconditional+(1|ResponseId), data=phase1_exp) 
car::Anova(model.phase1.wcovid,type="III") #sig interaction
summ(model.phase1.wcovid, digits=4, center=T)
emmeans(model.phase1.wcovid,pairwise ~covidconditional|domain, adjust = "none")
 
##### accuracy of thecovid as a conditional - using MASE
model.phase1.covid<-  lmer(MASE1_w1~domain*MASE1_covid+(1|ResponseId), data=phase1_exp) 
car::Anova(model.phase1.covid,type="III") #
summ(model.phase1.covid, digits=4, center=T)
emtrends(model.phase1.covid,specs=pairwise~domain,var="MASE1_covid") #

#### Nine, counterfactuals (yes/no) when reflecting on predictions
model.phase1.counterfac<-  lmer(MASE1_w1~domain*CounterFactual_Presence_Final+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.counterfac,type="III") #nothing
summ(model.phase1.counterfac, digits=4, center=T)
emmeans(model.phase1.counterfac,pairwise ~CounterFactual_Presence_Final|domain, adjust = "none") #

#### Nine and 1/2, number of counterfactuals when reflecting on predictions
model.phase1.counterfac.N<-  lmer(MASE1_w1~domain*counterNum+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.counterfac.N,type="III") #nothing
summ(model.phase1.counterfac.N, digits=4, center=T)
emtrends(model.phase1.counterfac.N,specs=pairwise~domain,var="counterNum") #

#### Nine and 2/3, number of counterfactuals when reflecting on predictions
model.phase1.counterfac.covid<-  lmer(MASE1_w1~domain*as.factor(COVID.Final)+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.counterfac.covid,type="III") #nothing
summ(model.phase1.counterfac.covid, digits=4, center=T)
emmeans(model.phase1.counterfac.covid,pairwise ~as.factor(COVID.Final)|domain, adjust = "none") #


#### Ten: experience with prior previous_tournaments
model.phase1.tournexperience<-  lmer(MASE1_w1~domain*as.factor(previous_tournament.coded)+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.tournexperience,type="III") #nothing
summ(model.phase1.tournexperience, digits=4, center=T)
emmeans(model.phase1.tournexperience,pairwise ~as.factor(previous_tournament.coded)|domain, adjust = "none") #nonsig

#### Eleven: only used data provided or also other data? - just those that used data
model.phase1.dataonly<-  lmer(MASE1_w1~domain*as.factor(DataOnly)+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.dataonly,type="III") #3 way
summ(model.phase1.dataonly, digits=4, center=T)
emmeans(model.phase1.dataonly,pairwise ~as.factor(DataOnly)|domain, adjust = "none") #nonsig

#### Twelve: team composition

model.phase1.team<-  lmer(MASE1_w1~domain+team_gender+team_education+team_Age+non_US+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team,type="III") ##% teams who did not have a PhD matters - i.e., fewer PhDs on the team=> greater MASE score (i.e., lower accuracy)
summ(model.phase1.team, digits=4, center=T)

model.phase1.team<-  lmer(MASE1_w1~domain*team_gender+domain*team_education+domain*team_Age+domain*non_US+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team,type="III")
emtrends(model.phase1.team,specs=~domain,var="team_education") #


### Time-specific absolute percentage error

#### first, confidence
model.long.phase1.conf<-  lmer(value.dif~domain*confidence*Month0+(1|domain/ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase1.conf,type="III") #sig interaction between domain and confidence, also a marginal 3 way - domain x confidence x month
summ(model.long.phase1.conf, digits=4, center=T) #the more confidence, the greater the error!
emtrends(model.long.phase1.conf,specs=pairwise~domain,var="confidence") #confidence does  play a role for explicit asian bias (african american): high confidence more APE, but nothing else
emtrends(model.long.phase1.conf,~Month0|domain,var="confidence", at=list(Month0=c(0,5,11))) #

##### second, team type - just academics

#####just count
model.long.phase1.team<-  lmer(value.dif~domain*team_size.coded*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.team,type="III") #nothing
summ(model.long.phase1.team, digits=4, center=T)
emtrends(model.long.phase1.team,specs=pairwise~domain,var="team_size.coded") #larger team size linked to less bias for east asian explicit bias, but not any other domain
emtrends(model.long.phase1.team,~Month0|domain,var="team_size.coded", at=list(Month0=c(0,5,11))) #

#####apriori defined groups
model.long.phase1.team3<-  lmer(value.dif~domain*teamS*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.team3,type="III") #nothing for team size
summ(model.long.phase1.team3, digits=4, center=T) #
emmeans(model.long.phase1.team3, pairwise~teamS|domain, adjust = "none") #explicit asian bias - team more inaccurate than singular
emmeans(model.long.phase1.team3, pairwise~teamS|domain*Month0, adjust = "none",at=list(Month0=c(0,5,11))) 

#### third, multidisciplinarity of the teams - just academics
model.long.phase1.multidis.team<-  lmer(value.dif~domain*is_multidisciplinary*Month0+(1|domain/ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase1.multidis.team,type="III") #nothing for interdisciplinary 
summ(model.long.phase1.multidis.team, digits=4, center=T)
emmeans(model.long.phase1.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #for e asian bias, more interdisciplionary is better at M1,and M12, 
emmeans(model.long.phase1.multidis.team,pairwise ~is_multidisciplinary|domain*Month0, adjust = "none", at=list(Month0=c(0,5,11))) #for e asian bias, more interdisciplionary is better at M1,and M12, 

#### fourth, Rating of 1-7 of whether participants considered themselves experts on the domain being predicted
model.long.phase1.subexpert<-  lmer(value.dif~domain*subexpert*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.subexpert,type="III") #3 way interaction
summ(model.long.phase1.subexpert, digits=4, center=T)
emtrends(model.long.phase1.subexpert,~Month0|domain,var="subexpert") #
emtrends(model.long.phase1.subexpert,~Month0|domain,var="subexpert", at=list(Month0=c(0,5,11))) #

#### fifth, objective expertise based on publications in the domain (yes - no)
model.long.phase1.obexpert<-  lmer(value.dif~domain*objectivexpert*Month0+(1|domain/ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase1.obexpert,type="III") #pubs play a role!
summ(model.long.phase1.obexpert, digits=4, center=T)
emmeans(model.long.phase1.obexpert,pairwise ~objectivexpert|Month0|domain, adjust = "none") #
emmeans(model.long.phase1.obexpert,pairwise ~objectivexpert|Month0|domain, adjust = "none", at=list(Month0=c(0,5,11))) #

#### six, number of predictors in the model 
model.long.phase1.predictors<-  lmer(value.dif~numpred*domain*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.predictors,type="III") #
summ(model.long.phase1.predictors, digits=4, center=T)
emtrends(model.long.phase1.predictors,specs=~domain,var="numpred") #
sjPlot::plot_model(model.long.phase1.predictors,type="int")

#### six and a half, number of CODED parameters in the model 
model.long.phase1.predictors.coded<-  lmer(value.dif~parameters_coded*domain*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.predictors.coded,type="III") #
summ(model.long.phase1.predictors.coded, digits=4, center=T)
emtrends(model.long.phase1.predictors.coded,specs=~domain,var="parameters_coded") #
sjPlot::plot_model(model.long.phase1.predictors.coded,type="int")

#### seventh, complexity of the model
model.long.phase1.complex<-  lmer(value.dif~domain*Method.complex*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.complex,type="III") #complexity matters
summ(model.long.phase1.complex, digits=4, center=T)
emtrends(model.long.phase1.complex,specs=~domain,var="Method.complex") #
sjPlot::plot_model(model.long.phase1.complex,type="int")

model.long.phase1.complex<-  lmer(value.dif~domain*as.factor(Method.complex)*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.complex,type="III") #complexity matters
emmeans(model.long.phase1.complex,pairwise ~as.factor(Method.complex)|Month0|domain, adjust = "none") 

##### eight, presence of covid as a conditional
model.phase1.long.wcovid<-  lmer(value.dif~Month0*covidcondyn*domain+(1|domain/ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic'), REML=F) #
car::Anova(model.phase1.long.wcovid,type="III") #significant 3 way interaction, and also main effect 
summ(model.phase1.long.wcovid, digits=4, center=T)
emmeans(model.phase1.long.wcovid,pairwise ~covidcondyn|Month0|domain, adjust = "none") 
emmeans(model.phase1.long.wcovid,pairwise ~covidcondyn|Month0|domain, adjust = "none", at=list(Month0=c(0,5,11))) 

###### accuracy of covid conditional (MASE)
model.phase1.long.covid<-  lmer(value.dif~Month0*MASE1_covid*domain+(1|domain/ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic' & is.na(MASE1_covid)==F), REML=F) #
car::Anova(model.phase1.long.covid,type="III") #marginal month & mase1:COVID interaction
emtrends(model.phase1.long.covid,specs=~domain,var="MASE1_covid") #
emtrends(model.phase1.long.covid,~domain|Month0,var="MASE1_covid", at=list(Month0=c(0,5,11))) #nothing
interactions::interact_plot(model.phase1.long.covid,pred=Month0, modx=MASE1_covid,mod2=domain) #REALLY WEIRD STUFF, better to redo by domain to test specific effects independently.

#### Nine, counterfactuals (yes/no) when reflecting on predictions
model.long.phase1.counterfac<-  lmer(value.dif~domain*CounterFactual_Presence_Final*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.counterfac,type="III") #nothing
summ(model.long.phase1.counterfac, digits=4, center=T)
emmeans(model.long.phase1.counterfac,pairwise ~CounterFactual_Presence_Final|domain, adjust = "none") #nonsig

#### Nine and 1/2, number of counterfactuals when reflecting on predictions
model.long.phase1.counterfac.N<-  lmer(value.dif~domain*counterNum*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.counterfac.N,type="III") #nothing
summ(model.long.phase1.counterfac.N, digits=4, center=T)
emtrends(model.long.phase1.counterfac.N,specs=pairwise~domain,var="counterNum") #

#### Nine and 2/3, mentioning COVID pandemic as a counterfactual when reflecting on predictions 
model.long.phase1.counterfac.covid<-  lmer(value.dif~domain*as.factor(COVID.Final)*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.counterfac.covid,type="III") #nothing
summ(model.long.phase1.counterfac.covid, digits=4, center=T)
emmeans(model.long.phase1.counterfac.covid,pairwise ~as.factor(COVID.Final)|domain, adjust = "none") #

#### Ten: experience with prior previous_tournaments
model.long.phase1.tournexperience<-  lmer(value.dif~domain*as.factor(previous_tournament.coded)*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.tournexperience,type="III") #nothing
summ(model.long.phase1.tournexperience, digits=4, center=T)
emmeans(model.long.phase1.tournexperience,pairwise ~as.factor(previous_tournament.coded)|Month0|domain, adjust = "none") 
emmeans(model.long.phase1.tournexperience,pairwise ~as.factor(previous_tournament.coded)|Month0|domain, adjust = "none", at=list(Month0=c(0,5,11))) 

#### Eleven: only used data provided or also other data? - just those that used data
model.long.phase1.dataonly<-  lmer(value.dif~domain*as.factor(DataOnly)*Month0+(1|domain/ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1.dataonly,type="III") #nothing
summ(model.long.phase1.dataonly, digits=4, center=T)
emmeans(model.long.phase1.dataonly,pairwise ~as.factor(DataOnly)|domain, adjust = "none") #nonsig

###### Twelve: team composition

model.long.phase1.team<-  lmer(value.dif~domain+team_gender+team_education+team_Age+non_US+domain*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.team,type="III") ##% teams who did not have a PhD matters - i.e., fewer PhDs on the team=> greater MASE score (i.e., lower accuracy)
summ(model.long.phase1.team, digits=4, center=T)

model.long.phase1.team<-  lmer(value.dif~domain*team_gender*Month0+domain*team_education*Month0+domain*team_Age*Month0+domain*non_US*Month0+(1|domain/ResponseId), data=dat_long_phase1, REML=F)
car::Anova(model.long.phase1.team,type="III")
emtrends(model.long.phase1.team,specs=~domain,var="team_gender") #


```

# Phase 2 analyses

```{r PHASE 2}

pd <- position_dodge(0.7) # move them .07 to the left and right
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
dat_phase2$Method.code <- relevel(factor(dat_phase2$Method.code), "Intuition/Theory") #use lay people as a reference group
dat_phase2$method.contrast<-ifelse(dat_phase2$Method.code=='Intuition/Theory',0,1)
dat_phase2$compare_to_naive_rwf_MASE2.update<-ifelse(dat_phase2$compare_to_naive_rwf_MASE_w2!="Equal to Naive rwf",dat_phase2$compare_to_naive_rwf_MASE_w2,ifelse(dat_phase2$compare_to_naive_rwf_MASE_w2=="Equal to Naive rwf","Below Naive rwf",NA))
dat_phase2$compare_to_naive_linear_MASE2.update<-ifelse(dat_phase2$compare_to_naive_linear_MASE_w2!="Equal to Naive linear",dat_phase2$compare_to_naive_linear_MASE_w2,ifelse(dat_phase2$compare_to_naive_linear_MASE_w2=="Equal to Naive linear","Below Naive linear",NA))
dat_phase2$Group[dat_phase2$TournamentStart=="May"&dat_phase2$revised == 0]<-"Original May"
dat_phase2$Group[dat_phase2$TournamentStart=="November"&dat_phase2$revised == 0]<-"Original November"
dat_phase2$Group[dat_phase2$TournamentStart=="May"&dat_phase2$revised == 1]<-"Updated May"
dat_phase2$teamS<-as.factor(ifelse(dat_phase2$team_size.coded>=6,3,ifelse(dat_phase2$team_size.coded<6&dat_phase2$team_size.coded>1,2,ifelse(dat_phase2$team_size.coded==1,1,NA))))
dat_phase2$is_multidisciplinary<-ifelse(dat_phase2$discipline=="Multi-disciplinary",1,0)
dat_phase2$objectivexpert<-ifelse(dat_phase2$pub==1,"Expert",ifelse(dat_phase2$pub==2,"Non Expert",NA))
dat_phase2$covidconditional<-ifelse(dat_phase2$covidcondyn==0,"No",ifelse(dat_phase2$covidcondyn==1,"Yes",NA))

#subset long data so that we only examine forecasts/accuracy of most updated scores (among those who decided to update at phase 2), keeping phase 1 predictions of those who did not decide to update.
#Use  revised  - 0 = Only submitted in one phase (initial forecasts for phase 1 / initial forecasts for phase 2), 1 = prediction in both phase 1 & 2

dat_long$Month7<-dat_long$Month-7
dat_long_phase2<-dat_long %>%filter(!(phase == 1 & revised == 1)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" & Month %in% c(7,8,9,10,11,12))
dat_long_phase2$objectivexpert<-ifelse(dat_long_phase2$pub==1,"Expert",ifelse(dat_long_phase2$pub==2,"Non Expert",NA))
dat_long_phase2$Method.code <- relevel(factor(dat_long_phase2$Method.code), "Intuition/Theory") #use Intuition/Theory as a reference group
dat_long_phase2$method.contrast<-ifelse(dat_long_phase2$Method.code=='Intuition/Theory',0,1)
dat_long_phase2$teamS<-as.factor(ifelse(dat_long_phase2$team_size.coded>=6,3,ifelse(dat_long_phase2$team_size.coded<6&dat_long_phase2$team_size.coded>1,2,ifelse(dat_long_phase2$team_size.coded==1,1,NA))))
dat_long_phase2$is_multidisciplinary<-ifelse(dat_long_phase2$discipline=="Multi-disciplinary",1,0)

#get ground truth markers (subset)
objective2<-as.data.frame(filter(dat_long,phase != 1 & !is.na(Method.code)& Method.code=="Ground Truth" & (Month >6|Month<13) ))

dat_long %>% filter(!(phase == 1 & revised == 1)& !is.na(Method.code)& Month %in% c(7,8,9,10,11,12)) %>% 
   ggplot(aes(x = Month7, y = value, colour = Method.code, fill=Method.code))+
  geom_smooth(aes(x = Month7, y = value, colour = Method.code, fill=Method.code),method = "loess") +  
    facet_wrap(~domain, scales = "free", nrow = 3, labeller=labeller(domain=labels))+
  theme_minimal(base_size = 14) +
  geom_smooth(data=objective2,se=F) + #here we add the ground truth markers without confidence band
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ 
  labs(colour = "Sample",fill="Sample", x="Months (from November 2021)",y="Estimate (M +/- 95%CI)") 

#without the naive benchmarks
dat_long_phase2 %>% 
ggplot(aes(x = Month7, y = value, colour = Method.code, fill=Method.code))+
  geom_smooth(aes(x = Month7, y = value, colour = Method.code, fill=Method.code),method = "loess") +  
    facet_wrap(~domain, scales = "free", nrow = 3, labeller=labeller(domain=labels))+
  theme_minimal(base_size = 14) +
  geom_smooth(data=objective2,se=F) + #here we add the ground truth markers without confidence band
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ 
  labs(colour = "Sample",fill="Sample", x="Months (from November 2021)",y="Estimate (M +/- 95%CI)") 

#For models evaluating accuracy of individual time points, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain and time points as predictors, with absolute percent deviation scores nested within teams. 

model.long.phase2<-  lmer(value.dif~domain*Method.code*Month7+(1|domain/ResponseId), data=dat_long_phase2,REML = F, control = lmerControl(optimizer ="Nelder_Mead"))
car::Anova(model.long.phase2,type="III") #sig 3 way interaction

summ(model.long.phase2, digits=4) #to get R2
emmeans(model.long.phase2,specs = trt.vs.ctrl ~Method.code|domain, adjust = "none") #overall month (half a year estimate), contrast to intuition/theory. Intuition/thoery sig worse for eafric, easian
emmeans(model.long.phase2,specs = trt.vs.ctrl ~Method.code|domain|Month7, adjust = "none", at=list(Month0=c(0,5))) #overall month (half a year estimate), contrast to intuition/theory. Lay ppl sig worse for eafric
emmeans(model.long.phase2,pairwise ~domain|Method.code, adjust = "none") #overall differences by domain.
interactions::interact_plot(model.long.phase2,pred=Month7,modx =Method.code,mod2 = domain,interval = T, mod2.labels = c("Exp. Af-Am. Bias","Exp. As-Am. Bias","Exp. Gender Bias","Imp. Af-Am. Bias","Imp. As.-Am. Bias",
         "Democrats","Republicans","Imp. Gender Bias","Life Satisfaction","Negative Affect","Polit. Polarization","Positive Affect"),legend.main="", colors="Qual1")+facet_wrap(~domain, scales = "free", nrow = 4)+labs(x="Months (from Nov 2021)",y="Absolute Percentage Deviation (M +/- 95%CI)")

#compare contrast : data-inclusive vs. just pure intuition/theory
model.long.phase2.contrast<-  lmer(value.dif~domain*method.contrast*Month7+(1|domain/ResponseId), data=dat_long_phase2,REML = F, control = lmerControl(optimizer ="Nelder_Mead"))
car::Anova(model.long.phase2.contrast,type="III") #sig 3 way interaction
emmeans(model.long.phase2.contrast,pairwise ~method.contrast|domain, adjust = "none") #overall differences by domain.

#get scores for visualizations
model.long.phase2.cat<-  lmer(value.dif~domain*Method.code*as.factor(Month7)+(1|domain/ResponseId), data=dat_long_phase2,REML = F, control = lmerControl(optimizer ="Nelder_Mead"))
car::Anova(model.long.phase2.cat,type="III") #sig effect of domain, method, Month, and domain * method
data.long.phase2.abs.dev<-as.data.frame(emmeans(model.long.phase2.cat,pairwise ~Method.code*domain*as.factor(Month7), adjust = "none",  type = "response")$emmeans) #estimates for plotting

data.long.phase2.abs.dev %>% 
 ggplot(aes(x = Month7, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=asymp.LCL, ymax=asymp.UCL), position=pd)+  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(~domain, scales = "free", nrow = 4, labeller=labeller(domain=labels))+
  labs(colour = "Sample",fill="Sample", x="Months (from Nov 2021)",y="Absolute Percentage Deviation (M +/- 95%CI)")


#OVERALL MASE by method for phase 2
#For models evaluating overall accuracy of the forecasted model, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain as predictors, with MASE scores nested within teams. 
model.phase2<-  lmer(MASE1_w2~domain*Method.code+(1|ResponseId), data=academic_only)
car::Anova(model.phase2,type="III") #nothing

summ(model.phase2, digits=4)

data.phase2.MASE<-as.data.frame(emmeans(model.phase2,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase2.MASE %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)

emmeans(model.phase2,trt.vs.ctrl ~Method.code|domain, adjust = "none") #intuition/theory vs. rest
emmeans(model.phase2,pairwise ~Method.code|domain, adjust = "none")


##across all domains
model.phase2.total<-  lmer(MASE1_w2~Method.code+(1|ResponseId), data=academic_only)
car::Anova(model.phase2.total,type="III") #nothing

summ(model.phase2.total, digits=4)

data.phase2.MASE.total<-as.data.frame(emmeans(model.phase2.total,pairwise ~Method.code, adjust = "none")$emmeans)
data.phase2.MASE.total %>% 
 ggplot(aes(x = Method.code, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_npg()+scale_fill_npg()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)

emmeans(model.phase2.total,pairwise ~Method.code, adjust = "none")

##with naive benchmarks
dat$ResponseId[dat$Method.code=="Naive-linear"]<-"Naive\nLinear Regression"
dat$ResponseId[dat$Method.code=="Naive-rfw"]<-"Naive\nRandom Walk"
dat$Method.code[dat$Method.code=="Naive-linear"]<-"Naive\nLinear Regression"
dat$Method.code[dat$Method.code=="Naive-rfw"]<-"Naive\nRandom Walk"
model.phase2.naive<-  lmer(MASE1_w2~Method.code+(1|ResponseId), data=filter(dat,Method.code=="Naive\nLinear Regression"|Method.code=="Naive\nRandom Walk"))

data.phase2.MASE.naive<-as.data.frame(emmeans(model.phase2.naive,pairwise ~Method.code, adjust = "none")$emmeans)

data.phase2.MASE.total.w.naive<-rbind(data.phase2.MASE.total,data.phase2.MASE.naive)
data.phase2.MASE.total.w.naive %>% 
 ggplot(aes(x = Method.code, y = emmean, colour = Method.code, fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="none") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 


## EXAMINE CONTRAST OF THEORY vs. DATA.HYBRID
model.phase2.contrast<-  lmer(MASE1_w2~domain*method.contrast+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast,type="III") #no sig

summ(model.phase2.contrast, digits=4) #get effect size for the overall model
emmeans(model.phase2.contrast,pairwise ~method.contrast|domain, adjust = "none")

#examine vs. benchmarks of accuracy 
## naive random walk
#to be able to calculate estimate scores==> equate at naive RW to below.
model.phase2.belowrw<-  lmer(MASE1_w2~domain*Method.code+(1|ResponseId), data=subset(dat_phase2,compare_to_naive_rwf_MASE2.update=="Below Naive rwf"))
model.phase2.aboverw<-  lmer(MASE1_w2~domain*Method.code+(1|ResponseId), data=subset(dat_phase2,compare_to_naive_rwf_MASE2.update=="Above Naive rwf"))

data.phase2.MASE2.belowrw<-as.data.frame(emmeans(model.phase2.belowrw,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase2.MASE2.aboverw<-as.data.frame(emmeans(model.phase2.aboverw,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase2.MASE2.belowrw$cut<-"Better than Random Walk"
data.phase2.MASE2.aboverw$cut<-"Worse than Random Walk"
data.phase2.MASE2.rw<-rbind(data.phase2.MASE2.belowrw,data.phase2.MASE2.aboverw)
  
data.phase2.MASE2.rw %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code,fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+facet_wrap(~cut, nrow=2,scale="free")+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labels, name="")+
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

emmeans(model.phase2.belowrw,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase2.aboverw,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest

# What percentage is better than naive random walk benchmark, per domain
naive_rwf_MASE_domain_w2 <- dat_phase2 %>% group_by(domain, compare_to_naive_rwf_MASE_w2) %>% 
  dplyr::summarise(N = length(compare_to_naive_rwf_MASE_w2)) %>% ungroup() %>% 
  group_by(domain) %>% mutate(ptg = prop.table(N)*100) %>% ungroup() %>% 
  arrange(by_group=compare_to_naive_rwf_MASE_w2,desc(ptg))
knitr::kable((naive_rwf_MASE_domain_w2))


## naive linear regression
#to be able to calculate estimate scores==> equate at naive RWF to below.
model.phase2.belowlinear<-  lmer(MASE1_w2~domain*Method.code+(1|ResponseId), data=subset(dat_phase2,compare_to_naive_linear_MASE2.update=="Below Naive linear"))
model.phase2.abovelinear<-  lmer(MASE1_w2~domain*Method.code+(1|ResponseId), data=subset(dat_phase2,compare_to_naive_linear_MASE2.update=="Above Naive linear"))

data.phase2.MASE2.belowlinear<-as.data.frame(emmeans(model.phase2.belowlinear,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase2.MASE2.abovelinear<-as.data.frame(emmeans(model.phase2.abovelinear,pairwise ~Method.code*domain, adjust = "none")$emmeans)
data.phase2.MASE2.belowlinear$cut<-"Better than Linear Regression"
data.phase2.MASE2.abovelinear$cut<-"Worse than Linear Regression"
data.phase2.MASE2.linear<-rbind(data.phase2.MASE2.belowlinear,data.phase2.MASE2.abovelinear)
  
data.phase2.MASE2.linear %>% 
 ggplot(aes(x = domain, y = emmean, colour = Method.code,fill=Method.code))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+facet_wrap(~cut, nrow=2, scale="free")+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labels, name="")+
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") 

emmeans(model.phase2.belowlinear,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase2.abovelinear,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest

# What percentage is better than naive linear regression, per domain
naive_linear_MASE_domain_w2 <- dat_phase2 %>% group_by(domain, compare_to_naive_linear_MASE_w2) %>% 
  dplyr::summarise(N = length(compare_to_naive_linear_MASE_w2)) %>% ungroup() %>% 
  group_by(domain) %>% mutate(ptg = prop.table(N)*100) %>% ungroup() %>% 
  arrange(by_group=compare_to_naive_linear_MASE_w2,desc(ptg))
knitr::kable((naive_linear_MASE_domain_w2))

#get scores for ranking visualizations
phase2.means<-as.data.frame(emmeans(model.phase2,pairwise ~domain|Method.code, adjust = "none")$emmeans)
# reorder and get the order variable to maintain facet-specific orders (otherwise it get screwy)
phase2.means <- phase2.means %>%
  # 1. Remove grouping
  ungroup() %>%
  # 2. Arrange by
  #   i.  facet group
  #   ii. bar height
  arrange(Method.code, emmean) %>%
  # 3. Add order column of row numbers
  mutate(order = row_number())

#errorbar charts, with scores ordered
phase2.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +  
geom_point(size=3) + 
geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL))+
 facet_wrap(vars(Method.code), scales = "free", nrow=4)+theme_minimal() +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
  scale_x_continuous(   # Add categories to axis
    breaks = phase2.means$order,
    labels = phase2.means$domain,expand = c(0,0))+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE +/- 95% CI") 

#lollipop chart
phase2.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +  
geom_point(size=3) + 
  geom_segment(aes(x=order, 
                   xend=order, 
                   y=0, 
                   yend=emmean)) +facet_wrap(vars(Method.code), scales = "free", ncol=1)+
  scale_x_continuous(   # Add categories to axis
    breaks = phase2.means$order,
    labels = phase2.means$domain)+theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE")

## EXAMINE EFFECTS OF new teams at phase 2 vs. OG teams who updated their forecasts: Just ACADEMICS
##revised  - Indicates whether or not the team has a matching submission in both phase 1 & 2 for the same domain
model.phase2.update<-  lmer(MASE1_w2~domain*Group+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.update,type="III") #sig interaction, and main effect of group
summ(model.phase2.update)
emmeans(model.phase2.update,pairwise ~Group|domain, adjust = "none") #nonsig
#contrast difference of updating forecasts for explicit asian bias, life satisfaction, neg affect, polarization, pos affect

data.phase2.update<-as.data.frame(emmeans(model.phase2.update,pairwise ~Group|domain, adjust = "none")$emmeans) #nonsig

#visualize
data.phase2.update %>% 
 ggplot(aes(x = domain, y = emmean, colour = Group, fill=Group))+
 geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  
  labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)

## TEAM TYPE AND CONFIDENCE (instead of forecasting type) as predictors. Academics only.

### overall MASE 

#### first, confidence
model.phase2.conf<-  lmer(MASE1_w2~domain*confidence+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.conf,type="III") #sig interaction
summ(model.phase2.conf, digits=4, center=T)
emtrends(model.phase2.conf,specs=pairwise~domain,var="confidence") #confidence plays a role for life satisfaction - the MORE confident the MORE error

##### second, team type - just academics
#####just count
model.phase2.team<-  lmer(MASE1_w2~domain*team_size.coded+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.team,type="III") #nothing
summ(model.phase2.team, digits=4, center=T)
emtrends(model.phase2.team,specs=pairwise~domain,var="team_size.coded") #nothing
#####apriori defined groups
model.phase2.team3<-  lmer(MASE1_w2~domain*teamS+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.team3,type="III") #no interaction between domain and team size
summ(model.phase2.team3, digits=4, center=T)
emmeans(model.phase2.team3,pairwise ~teamS|domain, adjust = "none") #nonsig

#### third, multidisciplinarity of the teams - just academics
model.phase2.multidis.team<-  lmer(MASE1_w2~domain*is_multidisciplinary+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.multidis.team,type="III") #interdisciplinary did not matter
summ(model.phase2.multidis.team, digits=4, center=T)
emmeans(model.phase2.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #nonsig

#### fourth, Rating of 1-7 of whether participants considered themselves experts on the domain being predicted
model.phase2.subexpert<-  lmer(MASE1_w2~domain*subexpert+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.subexpert,type="III") #
summ(model.phase2.subexpert, digits=4, center=T)
emtrends(model.phase2.subexpert,specs=pairwise~domain,var="subexpert") #

#### fifth, objective expertise based on publications in the domain (yes - no)
model.phase2.obexpert<-  lmer(MASE1_w2~domain*objectivexpert+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.obexpert,type="III") #
summ(model.phase2.obexpert, digits=4, center=T)
emmeans(model.phase2.obexpert,pairwise ~objectivexpert|domain, adjust = "none") #

#### six, number of predictors in the model 
model.phase2.predictors<-  lmer(MASE1_w2~numpred*domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.predictors,type="III") #
summ(model.phase2.predictors, digits=4, center=T)
emtrends(model.phase2.predictors,specs=~domain,var="numpred") #
sjPlot::plot_model(model.phase2.predictors,type="int")

#### six and a half, number of predictors in the model using CODED scores
model.phase2.predictors.coded<-  lmer(MASE1_w2~parameters_coded*domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.predictors.coded,type="III") 
summ(model.phase2.predictors.coded, digits=4, center=T)
emtrends(model.phase2.predictors.coded,specs=~domain,var="parameters_coded") #
sjPlot::plot_model(model.phase2.predictors.coded,type="int")


#### seventh, complexity of the model
model.phase2.complex<-  lmer(MASE1_w2~domain*Method.complex+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.complex,type="III") 
summ(model.phase2.complex, digits=4, center=T)
emtrends(model.phase2.complex,specs=~domain,var="Method.complex") #
sjPlot::plot_model(model.phase2.complex,type="int")

model.phase2.complexF<-  lmer(MASE1_w2~domain*Method.complex.factor+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.complexF,type="III") #
emmeans(model.phase2.complexF,pairwise ~Method.complex.factor|domain, adjust = "none") #
sjPlot::plot_model(model.phase2.complexF,type="int")

#### eight - CONDITIONALS - where they right for wrong reasons?

##### presence of covid as a conditional
model.phase2.wcovid<-  lmer(MASE1_w2~domain*covidconditional+(1|ResponseId), data=dat_phase2) 
car::Anova(model.phase2.wcovid,type="III") #
summ(model.phase2.wcovid, digits=4, center=T)
emmeans(model.phase2.wcovid,pairwise ~covidconditional|domain, adjust = "none")
 

#### Nine, counterfactuals (yes/no) when reflecting on predictions
model.phase2.counterfac<-  lmer(MASE1_w2~domain*CounterFactual_Presence_Final+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.counterfac,type="III") #nothing
summ(model.phase2.counterfac, digits=4, center=T)
emmeans(model.phase2.counterfac,pairwise ~CounterFactual_Presence_Final|domain, adjust = "none") #


#### Nine and 1/2, number of counterfactuals when reflecting on predictions
model.phase2.counterfac.N<-  lmer(MASE1_w2~domain*counterNum+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.counterfac.N,type="III") #nothing
summ(model.phase2.counterfac.N, digits=4, center=T)
emtrends(model.phase2.counterfac.N,specs=pairwise~domain,var="counterNum") #

#### Nine and 2/3, number of counterfactuals when reflecting on predictions
model.phase2.counterfac.covid<-  lmer(MASE1_w2~domain*as.factor(COVID.Final)+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.counterfac.covid,type="III") #nothing
summ(model.phase2.counterfac.covid, digits=4, center=T)
emmeans(model.phase2.counterfac.covid,pairwise ~as.factor(COVID.Final)|domain, adjust = "none") #

#### Ten: experience with prior previous_tournaments
model.phase2.tournexperience<-  lmer(MASE1_w2~domain*as.factor(previous_tournament.coded)+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.tournexperience,type="III") #nothing
summ(model.phase2.tournexperience, digits=4, center=T)
emmeans(model.phase2.tournexperience,pairwise ~as.factor(previous_tournament.coded)|domain, adjust = "none") #nonsig

#### Eleven: only used data provided or also other data? - just those that used data
model.phase2.dataonly<-  lmer(MASE1_w2~domain*as.factor(DataOnly)+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.dataonly,type="III") #3 way
summ(model.phase2.dataonly, digits=4, center=T)
emmeans(model.phase2.dataonly,pairwise ~as.factor(DataOnly)|domain, adjust = "none") #nonsig

#### Twelve: team composition

model.phase2.team<-  lmer(MASE1_w2~domain+team_gender+team_education+team_Age+non_US+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.team,type="III") ##% teams who did not have a PhD matters - i.e., fewer PhDs on the team=> greater MASE score (i.e., lower accuracy)
summ(model.phase2.team, digits=4, center=T)

model.phase2.team<-  lmer(MASE1_w2~domain*team_gender+domain*team_education+domain*team_Age+domain*non_US+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.team,type="III")
emtrends(model.phase2.team,specs=~domain,var="team_Age") #
emtrends(model.phase2.team,specs=~domain,var="team_gender") #nothing


### Time-specific absolute percentage error

#### first, confidence
model.long.phase2.conf<-  lmer(value.dif~domain*confidence*Month7+(1|domain/ResponseId), data=subset(dat_long_phase2, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase2.conf,type="III") #sig interaction between domain and confidence, also a marginal 3 way - domain x confidence x month
summ(model.long.phase2.conf, digits=4, center=T) #the more confidence, the greater the error!
emtrends(model.long.phase2.conf,specs=pairwise~domain,var="confidence") #confidence does  play a role for explicit asian bias (african american): high confidence more APE, but nothing else
emtrends(model.long.phase2.conf,~Month0|domain,var="confidence", at=list(Month0=c(0,3,5))) #

##### second, team type - just academics
#####just count
model.long.phase2.team<-  lmer(value.dif~domain*team_size.coded*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.team,type="III") #nothing
summ(model.long.phase2.team, digits=4, center=T)
emtrends(model.long.phase2.team,specs=pairwise~domain,var="team_size.coded") 
emtrends(model.long.phase2.team,~Month0|domain,var="team_size.coded", at=list(Month0=c(0,3,5))) #

#####apriori defined groups
model.long.phase2.team3<-  lmer(value.dif~domain*teamS*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.team3,type="III") #nothing for team size
summ(model.long.phase2.team3, digits=4, center=T) #
emmeans(model.long.phase2.team3, pairwise~teamS|domain, adjust = "none") #
emmeans(model.long.phase2.team3, pairwise~teamS|domain*Month7, adjust = "none",at=list(Month7=c(0,3,5))) 

#### third, multidisciplinarity of the teams - just academics
model.long.phase2.multidis.team<-  lmer(value.dif~domain*is_multidisciplinary*Month7+(1|domain/ResponseId), data=subset(dat_long_phase2, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase2.multidis.team,type="III") #nothing for interdisciplinary 
summ(model.long.phase2.multidis.team, digits=4, center=T)
emmeans(model.long.phase2.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #for e asian bias, more interdisciplionary is better at M1,and M12, 
emmeans(model.long.phase2.multidis.team,pairwise ~is_multidisciplinary|domain*Month7, adjust = "none", at=list(Month7=c(0,3,5))) #for e asian bias, more interdisciplionary is better at M1,and M12, 

#### fourth, Rating of 1-7 of whether participants considered themselves experts on the domain being predicted
model.long.phase2.subexpert<-  lmer(value.dif~domain*subexpert*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.subexpert,type="III") #3 way interaction
summ(model.long.phase2.subexpert, digits=4, center=T)
emtrends(model.long.phase2.subexpert,~Month7|domain,var="subexpert") #

emtrends(model.long.phase2.subexpert,~Month7|domain,var="subexpert", at=list(Month7=c(0,3,5))) #

#### fifth, objective expertise based on publications in the domain (yes - no)
model.long.phase2.obexpert<-  lmer(value.dif~domain*objectivexpert*Month7+(1|domain/ResponseId), data=subset(dat_long_phase2, isExpert.factor == 'Academic'), REML=F)
car::Anova(model.long.phase2.obexpert,type="III") #pubs play a role!
summ(model.long.phase2.obexpert, digits=4, center=T)
emmeans(model.long.phase2.obexpert,pairwise ~objectivexpert|Month7|domain, adjust = "none") #
emmeans(model.long.phase2.obexpert,pairwise ~objectivexpert|Month7|domain, adjust = "none", at=list(Month7=c(0,3,5))) #

#### six, number of predictors in the model 
model.long.phase2.predictors<-  lmer(value.dif~numpred*domain*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.predictors,type="III") #
summ(model.long.phase2.predictors, digits=4, center=T)
emtrends(model.long.phase2.predictors,specs=~domain,var="numpred") #
sjPlot::plot_model(model.long.phase2.predictors,type="int")

#### six and a half, number of CODED parameters in the model 
model.long.phase2.predictors.coded<-  lmer(value.dif~parameters_coded*domain*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.predictors.coded,type="III") #nothing
summ(model.long.phase2.predictors.coded, digits=4, center=T)
emtrends(model.long.phase2.predictors.coded,specs=~domain,var="parameters_coded") #
sjPlot::plot_model(model.long.phase2.predictors.coded,type="int")


#### seventh, complexity of the model
model.long.phase2.complex<-  lmer(value.dif~domain*Method.complex*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.complex,type="III") #
summ(model.long.phase2.complex, digits=4, center=T)
emtrends(model.long.phase2.complex,specs=~domain,var="Method.complex") #
sjPlot::plot_model(model.long.phase2.complex,type="int")

model.long.phase2.complex<-  lmer(value.dif~domain*as.factor(Method.complex)*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.complex,type="III") #complexity matters
emmeans(model.long.phase2.complex,pairwise ~as.factor(Method.complex)|Month7|domain, adjust = "none", at=list(Month7=c(0,3,5))) #nonsig


##### eight, presence of covid as a conditional
model.phase2.long.wcovid<-  lmer(value.dif~Month7*covidcondyn*domain+(1|domain/ResponseId), data=subset(dat_long_phase2, isExpert.factor == 'Academic'), REML=F) #
car::Anova(model.phase2.long.wcovid,type="III") #significant 3 way interaction, and also main effect 
summ(model.phase2.long.wcovid, digits=4, center=T)
emmeans(model.phase2.long.wcovid,pairwise ~covidcondyn|Month7|domain, adjust = "none")
emmeans(model.phase2.long.wcovid,pairwise ~covidcondyn|Month7|domain, adjust = "none", at=list(Month7=c(0,3,5))) #


#### Nine, counterfactuals (yes/no) when reflecting on predictions
model.long.phase2.counterfac<-  lmer(value.dif~domain*CounterFactual_Presence_Final*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.counterfac,type="III") #nothing
summ(model.long.phase2.counterfac, digits=4, center=T)
emmeans(model.long.phase2.counterfac,pairwise ~CounterFactual_Presence_Final|domain, adjust = "none") #nonsig


#### Nine and 1/2, number of counterfactuals when reflecting on predictions
model.long.phase2.counterfac.N<-  lmer(value.dif~domain*counterNum*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.counterfac.N,type="III") #nothing
summ(model.long.phase2.counterfac.N, digits=4, center=T)
emtrends(model.long.phase2.counterfac.N,specs=pairwise~domain,var="counterNum") #

#### Nine and 2/3, number of counterfactuals when reflecting on predictions
model.long.phase2.counterfac.covid<-  lmer(value.dif~domain*as.factor(COVID.Final)*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.counterfac.covid,type="III") #nothing
summ(model.long.phase2.counterfac.covid, digits=4, center=T)
emmeans(model.long.phase2.counterfac.covid,pairwise ~as.factor(COVID.Final)|domain, adjust = "none") #

#### Ten: experience with prior previous_tournaments
model.long.phase2.tournexperience<-  lmer(value.dif~domain*as.factor(previous_tournament.coded)*Month7+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.tournexperience,type="III") #nothing
summ(model.long.phase2.tournexperience, digits=4, center=T)
emmeans(model.long.phase2.tournexperience,pairwise ~as.factor(previous_tournament.coded)|Month7|domain, adjust = "none")
emmeans(model.long.phase2.tournexperience,pairwise ~as.factor(previous_tournament.coded)|Month7|domain, adjust = "none", at=list(Month7=c(0,3,5))) #nonsig, except for one

#### Eleven: only used data provided or also other data? - just those that used data
model.long.phase2.dataonly<-  lmer(value.dif~domain*as.factor(DataOnly)*Month7+(1|domain/ResponseId), data=dat_long_phase2)
car::Anova(model.long.phase2.dataonly,type="III") #nothing
summ(model.long.phase2.dataonly, digits=4, center=T)
emmeans(model.long.phase2.dataonly,pairwise ~as.factor(DataOnly)|domain, adjust = "none") #nonsig

#### Team composition
model.long.phase2.team<-  lmer(value.dif~domain+team_gender+team_education+team_Age+non_US+domain*Month0+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.team,type="III") ##% teams who did not have a PhD matters - i.e., fewer PhDs on the team=> greater MASE score (i.e., lower accuracy)
summ(model.long.phase2.team, digits=4, center=T)

model.long.phase2.team<-  lmer(value.dif~domain*team_gender*Month0+domain*team_education*Month0+domain*team_Age*Month0+domain*non_US*Month0+(1|domain/ResponseId), data=dat_long_phase2, REML=F)
car::Anova(model.long.phase2.team,type="III")
emtrends(model.long.phase2.team,specs=~domain,var="team_gender") #
emtrends(model.long.phase2.team,specs=~domain,var="team_Age") #
emtrends(model.long.phase2.team,specs=~domain,var="non_US") #

```



```{r}
#examine intra-individual consistency in accuracy scores 
library(see)
library(ggraph)
library(correlation)
require(RColorBrewer)

#phase 1

null.model.phase1.lay<-  lmer(MASE1_w1~(1|ResponseId), data=filter(phase1, isExpert == 0))
summ(null.model.phase1.lay, digits=4) #icc is .703

check.phase1.lay<-filter(phase1,isExpert == 0)[c("MASE1_w1","ResponseId","domain")] 

check.phase1.lay.short<-check.phase1.lay %>% group_by(ResponseId) %>% add_count() %>% filter(n>1) %>% ungroup()
check.phase1.lay.wide<-check.phase1.lay.short %>% select(-n) %>% pivot_wider(names_from=domain,values_from=MASE1_w1)
check.phase1.lay.wide %>% select(-ResponseId) %>% cor(use="pairwise.complete.obs")

correlation::correlation(select(check.phase1.lay.wide,-ResponseId), use="pairwise.complete.obs")
check.phase1.lay.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>%  
  plot()+scale_edge_colour_viridis()

check.phase1.lay.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>% summary()


null.model.phase1.academ<-  lmer(MASE1_w1~(1|ResponseId), data=filter(phase1, isExpert == 1))
summ(null.model.phase1.academ, digits=4) #icc is .9190

##check scores
psych::describe(phase1_exp$MASE1_w1) #looks oK
#View(phase1_exp[c("MASE1_w1","ResponseId","domain")]) #looks ok
check.phase1.academ<-phase1_exp[c("MASE1_w1","ResponseId","domain")] 

check.phase1.academ.short<-check.phase1.academ %>% group_by(ResponseId) %>% add_count() %>% filter(n>1) %>% ungroup()
check.phase1.academ.wide<-check.phase1.academ.short %>% select(-n) %>% pivot_wider(names_from=domain,values_from=MASE1_w1)
check.phase1.academ.wide %>% select(-ResponseId) %>% cor(use="pairwise.complete.obs")

correlation::correlation(select(check.phase1.academ.wide,-ResponseId), use="pairwise.complete.obs")
check.phase1.academ.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>%  
  plot()+scale_edge_colour_viridis(alpha=.5, option="C")

check.phase1.academ.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>% summary()

#phase 2

#academics
null.model.phase2.academ<-  lmer(MASE1_w2~(1|ResponseId), data=dat_phase2)
summ(null.model.phase2.academ, digits=4) #icc is .84

check.phase2.academ<-dat_phase2[c("MASE1_w2","ResponseId","domain")] 

check.phase2.academ.short<-check.phase2.academ %>% group_by(ResponseId) %>% add_count() %>% filter(n>1) %>% ungroup()
check.phase2.academ.wide<-check.phase2.academ.short %>% select(-n) %>% pivot_wider(names_from=domain,values_from=MASE1_w2)
check.phase2.academ.wide %>% select(-ResponseId) %>% cor(use="pairwise.complete.obs")

correlation::correlation(select(check.phase2.academ.wide,-ResponseId), use="pairwise.complete.obs")
check.phase2.academ.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>%  
  plot()+scale_edge_colour_viridis(alpha=.5, option="B")

check.phase2.academ.wide %>% 
  select(-ResponseId) %>% 
  correlation(use="pairwise.complete.obs") %>% summary()

##correlation of errors between T1 and T2 (38 groups)
dat_updated<-academic_only %>%filter(revised == 1)
model.phase2.predicted.by.phase1.academ<-  lmer(MASE1_w2~MASE1_w1+(1|ResponseId), data=dat_updated)
summ(model.phase2.predicted.by.phase1.academ, digits=4) #icc is .023

model.phase2.predicted.by.phase1.academ.diff<-  lmer((MASE1_w1-MASE1_w2)~MASE1_w1+(1|ResponseId), data=dat_updated) #effect of inaccuracy in the 12m tournament for changes in inaccuracy between 12 and 6 m tournaments
summ(model.phase2.predicted.by.phase1.academ.diff, digits=4) #icc is .023
```

```{r life satisfaction}

#May Tournament

lifesat <- dat_long_phase1 %>% subset(domain == "lifesat") #note that this is only phase 1, ought to be adjusted to include update predictions for the new six months!!!

lifesat1 <- lifesat %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

lifesat1

Plot.ls <- ggplot(lifesat1, aes(x = Month, y = mean, colour = isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(5.8, 6.4, 0.1), limits = c(5.8, 6.4)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "life satisfaction academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)

Plot.ls

########################################################################
######################Igor update#######################################
########################################################################

# The errorbars overlapped, so use position_dodge to move them horizontally
pd <- position_dodge(0.5) # move them .05 to the left and right

ggplot(lifesat1, aes(x = Month, y = mean, colour = isExpert.factor, fill=isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess",position=pd) + 
  scale_x_continuous(breaks=seq(1, 12, 2)) + 
  scale_y_continuous(breaks=seq(5.8, 6.4, 0.1), limits = c(5.8, 6.4)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), position=pd) + geom_point(position=pd)+
  theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


lifesat %>% 
 ggplot(aes(x = Month, y = value, colour = isExpert.factor, fill=isExpert.factor))+
 stat_summary(fun.data="mean_cl_boot",  position=pd)+
   geom_smooth(method = "loess",position=pd) +  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_continuous(breaks=seq(1, 12, 2)) + 
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") 
  
#boxplots 
lifesat$Months<-as.factor(lifesat$Month)

lifesat %>% 
 ggplot(aes(x = Month, y = value))+
   geom_boxplot(aes(x = Months, y = value, colour = isExpert.factor),  position=pd)+
  geom_smooth(aes(x = Month, y = value, colour = isExpert.factor, fill=isExpert.factor),method = "loess",position=pd) +  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  #scale_x_continuous(breaks=seq(1, 12, 2)) + 
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") 
   
#restrict y axis to region of interest - 4.5 to 7.5
lifesat %>% 
 ggplot(aes(x = Month, y = value))+
   geom_boxplot(aes(x = Months, y = value, colour = isExpert.factor), position=position_dodge(.8))+
  geom_smooth(aes(x = Month, y = value, colour = isExpert.factor, fill=isExpert.factor),method = "loess",position=pd) +  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ ylim(4.5,7.5)+ #scale_x_continuous(breaks=seq(1, 12, 2)) + 
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") 

#add objective data KEY PLOT FOR EACH DOMAIN

lifesat %>% 
 ggplot(aes(x = Month, y = value))+
   geom_boxplot(aes(x = Months, y = value, colour = isExpert.factor), position=position_dodge(.8))+
  geom_smooth(aes(x = Month, y = value, colour = isExpert.factor, fill=isExpert.factor),method = "loess",position=pd) +  theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_tron()+scale_fill_tron()+ ylim(4.5,7.5)+ 
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") +
  geom_segment(x = 0.7, xend=1.3, y=6.333665896, yend=6.333665896, color = "black", linetype = 2) + #here, you need to replace ys with the actual historical value for each data / x axis is set to bounds for each point to ensure no overlap
  geom_segment(x = 1.7, xend=2.3, y=6.217446585, yend=6.217446585, color = "black", linetype = 2) +
  geom_segment(x = 2.7, xend=3.3, y=6.304412691, yend=6.304412691, color = "black", linetype = 2) +
  geom_segment(x = 3.7, xend=4.3, y=6.327005177, yend=6.327005177, color = "black", linetype = 2) +
  geom_segment(x = 4.7, xend=5.3, y=6.336293833, yend=6.336293833, color = "black", linetype = 2) +
  geom_segment(x = 5.7, xend=6.3, y=6.338430537, yend=6.338430537, color = "black", linetype = 2) +
  geom_segment(x = 6.7, xend=7.3, y=6.331353975, yend=6.331353975, color = "black", linetype = 2) +
  geom_segment(x = 7.7, xend=8.3, y=6.300137355, yend=6.300137355, color = "black", linetype = 2) +
  geom_segment(x = 8.7, xend=9.3, y=6.348834431, yend=6.348834431, color = "black", linetype = 2) +
  geom_segment(x = 9.7, xend=10.3, y=6.347219074, yend=6.347219074, color = "black", linetype = 2) +
    geom_segment(x = 10.7, xend=11.3, y=6.330294051, yend=6.330294051, color = "black", linetype = 2) +
    geom_segment(x = 11.7, xend=12.3, y=6.339913808, yend=6.339913808, color = "black", linetype = 2) 



analysis.lifesat <-lmer(value~isExpert+(1|ResponseId),data=lifesat)

anova.lifesat <- car::Anova(analysis.lifesat,type="III")

##############################################################
#6 months tournament
##############################################################

lifesat_6m <- dat_long_phase2 %>% subset(domain == "lifesat") 

#boxplots 
lifesat_6m$Months<-as.factor(lifesat_6m$Month)

lifesat_6m %>% 
 ggplot(aes(x = Month, y = value))+
   geom_boxplot(aes(x = Months, y = value, colour = Method.code), position=position_dodge(.8))+
    theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_color_tron()+scale_fill_tron()+ ylim(4.5,7.5)+ 
  labs(title = "Life Satisfaction",colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)") +
    geom_segment(x = 0.7, xend=1.3, y=6.331353975, yend=6.331353975, color = "black", linetype = 2) +
  geom_segment(x = 1.7, xend=2.3, y=6.300137355, yend=6.300137355, color = "black", linetype = 2) +
  geom_segment(x = 2.7, xend=3.3, y=6.348834431, yend=6.348834431, color = "black", linetype = 2) +
  geom_segment(x = 3.7, xend=4.3, y=6.347219074, yend=6.347219074, color = "black", linetype = 2) +
    geom_segment(x = 4.7, xend=5.3, y=6.330294051, yend=6.330294051, color = "black", linetype = 2) +
    geom_segment(x = 5.7, xend=6.3, y=6.339913808, yend=6.339913808, color = "black", linetype = 2) 




```

```{r positive affect}

posaffect <- dat_long %>% subset(domain == "posaffect" & phase == 1 & !is.na(isExpert.factor))

posaffect1 <- posaffect %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(posaffect1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(-1.15, -0.4, 0.1), limits = c(-1.15, -0.4)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "positive affect academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.posaffect <-lmer(value~isExpert+(1|ResponseId),data=posaffect)
anova.posaffect <- car::Anova(analysis.posaffect,type="III")

```

```{r negative affect}

negaffect <- dat_long %>% subset(domain == "negaffect" & phase == 1 & !is.na(isExpert.factor))

negaffect1 <- negaffect %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(negaffect1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.85, 1.25, 0.1), limits = c(0.85, 1.25)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "negative affect academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.negaffect <-lmer(value~isExpert+(1|ResponseId),data=negaffect)
anova.negaffect <- car::Anova(analysis.negaffect,type="III")

```

```{r ideology - democrat}

ideoldem <- dat_long %>% subset(domain == "ideoldem" & phase == 1 & !is.na(isExpert.factor))

ideoldem1 <- ideoldem %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(ideoldem1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(43, 47, 1), limits = c(43, 47)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "ideology - democrat academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.ideoldem <-lmer(value~isExpert+(1|ResponseId),data=ideoldem)
anova.ideoldem <- car::Anova(analysis.ideoldem,type="III")

```

```{r ideology - republican}

ideolrep <- dat_long %>% subset(domain == "ideolrep" & phase == 1 & !is.na(isExpert.factor))

ideolrep1 <- ideolrep %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(ideolrep1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(35, 39, 1), limits = c(34.5, 39)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "ideology - republican academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.ideolrep <-lmer(value~isExpert+(1|ResponseId),data=ideolrep)
anova.ideolrep <- car::Anova(analysis.ideolrep,type="III")

```

```{r  polarization}

polar <- dat_long %>% subset(domain == "polar" & phase == 1 & !is.na(isExpert.factor))

polar1 <- polar %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(polar1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(73, 85, 2), limits = c(73, 86)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "polarization academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.polar <-lmer(value~isExpert+(1|ResponseId),data=polar)
anova.polar <- car::Anova(analysis.polar,type="III")

```

```{r explicit asian american}

easian <- dat_long %>% subset(domain == "easian" & phase == 1 & !is.na(isExpert.factor))

easian1 <- easian %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(easian1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0, 0.35, 0.07), limits = c(0, 0.35)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit Asian bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.easian <-lmer(value~isExpert.factor+(1|ResponseId),data=easian)
anova.easian <- car::Anova(analysis.easian,type="III")


```

```{r implicit asian american}

iasian <- dat_long %>% subset(domain == "iasian" & phase == 1 & !is.na(isExpert.factor))

iasian1 <- iasian %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(iasian1, aes(x = Month, y = mean, colour = isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.37, 0.43, 0.02), limits = c(0.37, 0.44)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit Asian bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.iasian <-lmer(value~isExpert+(1|ResponseId),data=iasian)
anova.iasian <- car::Anova(analysis.iasian,type="III")

```


```{r explicit african american}

eafric <- dat_long %>% subset(domain == "eafric" & phase == 1 & !is.na(isExpert))
eafric1 <- eafric %>% subset(!is.na(isExpert))

eafric1 <- eafric1 %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)



Plot <- ggplot(eafric1, aes(x = Month, y = mean, colour = isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(-0.20, 0.15, 0.07), limits = c(-0.2, 0.15)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit African bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)

plot(Plot)

analysis.eafric <-lmer(value~isExpert.factor+(1|ResponseId),data=eafric)
anova.eafric <- car::Anova(analysis.eafric,type="III")


```

```{r implicit african american}

iafric <- dat_long %>% subset(domain == "iafric" & phase == 1 & !is.na(isExpert.factor))

iafric1 <- iafric %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(iafric1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.29, 0.33, 0.01), limits = c(0.288, 0.33)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit African bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.iafric <-lmer(value~isExpert+(1|ResponseId),data=iafric)
anova.iafric <- car::Anova(analysis.iafric,type="III")

```

```{r explicit gender-career bias}

egend <- dat_long %>% subset(domain == "egend" & phase == 1 & !is.na(isExpert.factor))

egend1 <- egend %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(egend1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.8, 1.2, 0.1), limits = c(0.78, 1.2)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit gender academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.egend <-lmer(value~isExpert+(1|ResponseId),data=egend)
anova.egend <- car::Anova(analysis.egend,type="III")

```

```{r implicit gender-career bias}

igend <- dat_long %>% subset(domain == "igend" & phase == 2 & !is.na(isExpert.factor))

igend1 <- igend %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(igend1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.35, 0.4, 0.01), limits = c(0.35, 0.405)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit gender academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.igend <-lmer(value~isExpert+(1|ResponseId),data=igend)
anova.igend <- car::Anova(analysis.igend,type="III")

```

```{r differences by team size}

# look at whether team multi-disciplinarity has any impact
analysis.disc <-lmer(root_mean_sqr_error~is_multidisciplinary+(1|ResponseId),data=phase1_exp)
anova.disc <- car::Anova(analysis.disc,type="III")

# no effect of multi-disciplinarity

# look at whether team size has an effect on RMSE
analysis.teams <- lmer(root_mean_sqr_error~team_size.coded+(1|ResponseId), data = phase1_exp)
anova.teams <- car::Anova(analysis.teams,type="III")

# no effect of team size of RMSE

# instead split into 2 groups: solo (team size = 1) and group (team size = 2+)
phase1_exp$team_size.coded.grouped <- ifelse(phase1_exp$team_size.coded > 1, 2, phase1_exp$team_size.coded)

analysis.teams2 <- lmer(root_mean_sqr_error~factor(team_size.coded.grouped)+(1|ResponseId), data = phase1_exp)
anova.teams2 <- car::Anova(analysis.teams2,type="III")

# Still no effect of team size

# look at whether method used has an effect on RMSE
analysis.method <- lmer(root_mean_sqr_error~Method.coded.factor+(1|ResponseId), data = phase1_exp)
anova.teams <- car::Anova(analysis.teams,type="III")

# no effect of method used

```

```{r - Team Updates}

#Question: Did teams that updated predictions do better than those who did not?
#only contains data from phase 2, teams that did vs did not update analyses (also includes firt time predictors)

expert_dat <- filter(dat, isExpert == 1)

  #using MASE1

updated.analysis <-lmer(MASE1_w2~revised +(1|ResponseId),data=expert_dat)
print(updated.analysis)

anova.updated  <- car::Anova(updated.analysis,type="III")
print(anova.updated)

  #using MASE2

updated.analysis2 <-lmer(MASE2_w2~revised+(1|ResponseId),data=expert_dat)
print(updated.analysis2)

anova.updated2  <- car::Anova(updated.analysis2,type="III")
print(anova.updated2)


#comparing predictions for months 7 to 12 from phase 1 and 2 to ground truth estimates



overlapdat_long %>% subset(isExpert == 1 & !is.na(Method.code)& Method.code!="Ground Truth") %>% 
   ggplot(aes(x = Month, y = value, colour = phase, fill=phase))+
  geom_smooth(aes(x = Month, y = value, colour = phase, fill=phase),method = "loess") +  
    facet_wrap(vars(domain), scales = "free", nrow = 3)+theme_minimal(base_size = 14) +
  geom_smooth(data=objective2,se=F) + #here we add the ground truth markers without confidence band
   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ 
  labs(colour = "Phase",fill="Phase", x="Time (in months)",y="Estimate (M +/- 95%CI)") 

```

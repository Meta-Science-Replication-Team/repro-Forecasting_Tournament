---
title: "Oliver Thesis - 2021-04-18"
author: "Oliver Twardus"
date: "18/04/2021"
output:
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    code_folding: 'show'
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = F, # show warnings during codebook generation
  message = F, # show messages during codebook generation
  error = F, # do not interrupt codebook generation in case of errors,
                # usually better for debugging
  echo = T  # show R code
)

options(scipen = 1000)

```

# Setup

```{r Libraries}
options(scipen=999)
library(plyr)
library(tidyverse)
library(readxl)
library(tools)
library(emmeans)
library(lme4)
library(car)
library(sjPlot)
library(RColorBrewer)
library(irr)
library(ggpubr)
library(rstatix)
library(nlme)
library(psych)
library(apaTables)
library(ez)
# library(papaja)
library(effects)
library(lsr)
library(moments)

# date <- as.character(Sys.Date())

# Many thanks to Amanda Rotella, Konstantyn Sharpinksy, and Tianrong Sun for their help on various components of this code, and to Dr. Grossmann for guiding me through this study.


# import cleaned data file
# file was cleaned in previous R file, OT_Thesis_ForecastingDataCleaning_2020-08-10.rmd 


  
```

```{r Import Files}

# cleaned demographics file
datDemoMerged <- read.csv("DemographicInfo.csv")

# basic merged file of participant responses + coded responses for methods + complexity
datMerged <- read.csv("datMerged.csv")

# subset of datLonger that includes difference scores comparing participants forecasts to the baseline
datDif <- read.csv("datDif.csv")
datDif$M0 <- datDif$Month - 2

# datDif in wide format
datDifWider <- read.csv("datDifWider.csv")

# datDif in wide format, but Months contain the absolute difference from baseline instead of raw predictions from participants
datDifWider.Abs <- read.csv("datDifWider_Abs.csv")

# subset of datDif that only contains data-driven or mixed forecasts that could be coded for complexity
datComplexData <- read.csv("datComplex.csv")
datComplexData$M0 <- datComplexData$Month - 2


# datComplexData in wide format
datComplexWider <- ("datComplexWider.csv")

```

```{r Variables}

# these variables are used mainly for troubleshooting, but are generally constants across graphs that can be changed through here instead of individually modifying each graph one at a time.

lineStyle <- "loess"

xAxis <- scale_x_continuous(breaks=seq(2, 13, 2))
xAxis2 <- scale_x_continuous(breaks=seq(-11, 13, 4))

# date variable used for naming graphs to track multiple variations across versions of my code. date <- "Final" is to distinguish the final version once a format has been determined.
date <- as.character(Sys.Date())
#date <- "Final"

# Create lists of domains for use in graphs
uniqueIssues <- unique(datDif$Issue)
uniqueIssues2 <- c("Life Satisfaction", "Positive Affect", "Negative Affect", "Polarization", "Implicit Bias - Asian", "Ideology - Republican", "Ideology - Democrat", "Explicit Bias - Asian", "Implicit Bias - African", "Explicit Bias - African", "Implicit Bias - Gender", "Explicit Bias - Gender")

# Create list of forecast methods used by participants
forecastMethods <- unique(datDif$TypeMerged)

# Presence <- as.character(unique(datDif$Presence.Factor))
# Presence <- Presence[1:3]

# List of forecast methods used by participants
Methods <- unique(datDif$Method)


```

```{r HistoricalData}

# Import historical data for each domain that was provided to all participants, and set time points from -38 to 0 for each one.
setwd("./HistoricalData")

# Life satisfaction
historicalLifeSat <- read.csv("lifesat_Historical.csv", stringsAsFactors = FALSE)
historicalLifeSat$Month <- seq(-38, 0, 1)

# Positive and Negative Affect
historicalAffect <- read.csv("affect_Historical.csv", stringsAsFactors = FALSE)
historicalAffect$Month <- seq(-38, 0, 1)

# Democrat and Republican Ideology
historicalIdeol <- read.csv("ideol_Historical.csv", stringsAsFactors = FALSE)
historicalIdeol$Month <- seq(-38, 1, 1)

# Political Polarization
historicalPolar <- read.csv("polar_Historical2.csv", stringsAsFactors = FALSE)

# Calculate difference scores between Repbulican and Democrat Presidential Approval Ratings
historicalPolar$Difference <- historicalPolar$Republican.Approvals - historicalPolar$Democrat.Approvals
historicalPolar$Month <- seq(-38, 0, 1)

# Implicit Asian-American Bias
historicalIAsian <- read.csv("iasian_Historical.csv", stringsAsFactors = FALSE)
historicalIAsian$Month <- seq(-38, 0, 1)

# Explicit Asian-American Bias
historicalEAsian <- read.csv("easian_Historical.csv", stringsAsFactors = FALSE)
historicalEAsian$Month <- seq(-38, 0, 1)

# Implicit African-American Bias
historicalIAfric <- read.csv("iafric_Historical.csv", stringsAsFactors = FALSE)
historicalIAfric$Month <- seq(-38, 0, 1)

# Explicit African-American Bias
historicalEAfric <- read.csv("eafric_Historical.csv", stringsAsFactors = FALSE)
historicalEAfric$Month <- seq(-38, 0, 1)

# Implicit Gender-Career Bias
historicalIGend <- read.csv("igend_Historical.csv", stringsAsFactors = FALSE)
historicalIGend$Month <- seq(-38, 0, 1)

# Implicit Gender-Career Bias
historicalEGend <- read.csv("egend_Historical.csv", stringsAsFactors = FALSE)
historicalEGend$Month <- seq(-38, 0, 1)

# Stores the baseline (i.e. the last data point) for each domain in a single list for quick reference
startingPoint <- as.numeric(c(
  historicalLifeSat$Life.Satisfaction[nrow(historicalLifeSat)],
  historicalAffect$Positive[nrow(historicalAffect)],
  historicalAffect$Negative[nrow(historicalAffect)],
  historicalPolar$Polarization[nrow(historicalPolar)],
  historicalIAsian$Implicit.Asian.American.Bias[nrow(historicalIAsian)],
  historicalIdeol$Republican[nrow(historicalIdeol)],
  historicalIdeol$Democrat[nrow(historicalIdeol)],
  historicalEAsian$Explicit.Asian.American.Bias[nrow(historicalEAsian)],
  historicalIAfric$Implicit.African.American.Bias[nrow(historicalIAfric)],
  historicalEAfric$Explicit.African.American.Bias[nrow(historicalEAfric)],
  historicalIGend$Implicit.Gender.Career.Bias[nrow(historicalIGend)],
  historicalEGend$Explicit.Gender.Career.Bias[nrow(historicalEGend)]
  ))

# Stores the mean for each domain in a single list for quick reference
historicalMean <- as.numeric(c(
  mean(historicalLifeSat$Life.Satisfaction),
  mean(historicalAffect$Positive),
  mean(historicalAffect$Negative),
  mean(historicalPolar$Difference),
  mean(historicalIAsian$Implicit.Asian.American.Bias),
  mean(historicalIdeol$Republican),
  mean(historicalIdeol$Democrat),
  mean(historicalEAsian$Explicit.Asian.American.Bias),
  mean(historicalIAfric$Implicit.African.American.Bias),
  mean(historicalEAfric$Explicit.African.American.Bias),
  mean(historicalIGend$Implicit.Gender.Career.Bias),
  mean(historicalEGend$Explicit.Gender.Career.Bias)
  ))

# historical means compared to the baseline
historicalMean.Abs <- abs((historicalMean - startingPoint) / startingPoint)

setwd("..")
```

### Coder Agreement
```{r Kappa - Methods & Counterfact}

# Check coder agreement for participant method
Method <- datMerged[, c("OT.Type", "TS.Type")]

agree(Method)
kappa2(Method)
# Kappa = 0.965

# Coder agreement for complexity of method used 
Complexity <- datMerged[, c("OT.Complexity", "TS.Complexity")]

agree(Complexity)
kappa2(Complexity)

# Kappa = 0.721

```

```{r Demographics - Descriptives}

#Team size
psych::describe(datDemoMerged$team_size)
# 63 teams submitted team size information.
# ranged from 1-7 members (Md = 1, SD = 1.28)

summarySize <- plyr::ddply(datDemoMerged, c("team_size"), summarise,
                        N = length(value),
                        Percent = N / nrow(datDemoMerged)
                        )

#   team_size  N    Percent
# 1         1 39 0.61904762
# 2         2 13 0.20634921
# 3         3  3 0.04761905
# 4         4  5 0.07936508
# 5         5  2 0.03174603
# 6         7  1 0.01587302

# Leader Age
describe(datDemoMerged$age)
# 55 participants provided age information, which ranged from 21-63 (M = 38.65. Md = 38, SD = 9.47)

# country of origin
datCountry <- filter(datDemoMerged, !is.na(country))

for(i in 1:nrow(datCountry)){
  if (datCountry$country[i] %in% c("UK", "the UK")) {
    datCountry$country[i] <- "United Kingdom"
  } else if (datCountry$country[i] %in% c("US", "USA")) {
    datCountry$country[i] <- "United States"
  } else if (datCountry$country[i] == "The Netherlands") {
    datCountry$country[i] <- "Netherlands"
  }
}

summaryCountry <- plyr::ddply(datCountry, c("country"), summarise,
                        N = length(value),
                        Percent = N / nrow(datCountry)
                        )
# 
# country  N    Percent
# 1       Australia  2 0.03278689
# 2         Belarus  1 0.01639344
# 3         Belgium  1 0.01639344
# 4          Canada  7 0.11475410
# 5          France  1 0.01639344
# 6         Germany  1 0.01639344
# 7          Greece  1 0.01639344
# 8            Iraq  1 0.01639344
# 9     Netherlands  4 0.06557377
# 10         Norway  1 0.01639344
# 11         Poland  2 0.03278689
# 12       Portugal  2 0.03278689
# 13      Singapore  1 0.01639344
# 14          Spain  1 0.01639344
# 15    Switzerland  1 0.01639344
# 16 United Kingdom  9 0.14754098
# 17  United States 25 0.40983607

# Participants reside in 17 different countries, with the most common being US (25), followed by UK (9), then Canada (7)


# Leader gender

datGender <- filter(datDemoMerged, !is.na(datDemoMerged$leader_gender))
summaryGender <- plyr::ddply(datGender, c("leader_gender"), summarise,
                        N = length(value),
                        Percent = N / nrow(datCountry)
                        )

# 1 = Male, 2 = Female

# leader_gender  N   Percent
# 1             1 48 0.7868852
# 2             2 13 0.2131148

# 78.7% male team leaders

# Expertise
datExpert <- filter(datDemoMerged, !is.na(leader_expert))
expertise <- unique(datExpert$leader_expert)

# summarized as:

# Domain                  N   Percent
# Psychology	            37	67.30%
# Economics	              7	  12.70%
# Computer Science	      5	  9.10%
# Forecasting	            2	  3.60%
# Sociology	              2	  3.60%
# Biomedical Engineering	1	  1.80%
# Political Science	      1	  1.80%



```

```{r Descriptives - Number of Parameters}

# Look at the number of parameters each team indicated they considered for each of their forecasts (in addition to COVID-19)
test <- datDifWider
test$numpred_4.x <- as.numeric(test$numpred_4.x)
test$covidcondyn <- as.numeric(test$covidcondyn)

# exclude all rows where 
test <- filter(test, !is.na(numpred_4.x))

for (i in 1:nrow(test)) {
  
  # Exclude rows with high $ of predictors that are not data-driven
  if (test$numpred_4.x[i] > 12 & test$DataDriven[i] == 0) {
    test$numpred_4.x[i] <- NA
  }
  
  # add 1 to the number of parameters considered if they indicated 0 parameters but considered covid as a conditional
  if (test$covidcondyn[i] == 1 & (test$numpred_4.x[i] == 0 | is.na(test$numpred_4.x[i]))) {
    test$numpred_4.x[i] <- 1
  }
}

test <- filter(test, !is.na(numpred_4.x))
test <- filter(test, numpred_4.x > 0)

describe(test$numpred_4.x)

# Number of predictors teams considered
summaryTest1 <- plyr::ddply(test, c("numpred_4.x"), summarise,
                        N = length(Month.2),
                        Percent = N / nrow(test)
                        )

# numpred_4.x  N     Percent
# 1            1 35 0.321100917
# 2            2 23 0.211009174
# 3            3 19 0.174311927
# 4            4  5 0.045871560
# 5            5  4 0.036697248
# 6            6  5 0.045871560
# 7            7  5 0.045871560
# 8            8  7 0.064220183
# 9            9  3 0.027522936
# 10          10  1 0.009174312
# 11          12  1 0.009174312
# 12          41  1 0.009174312

# Whether teams considered COVID as a conditional
summaryTest2 <- plyr::ddply(datDifWider, c("covidcondyn"), summarise,
                        N = length(Month.2),
                        Percent = N / nrow(datDifWider)
                        )

# covidcondyn   N    Percent
# 1           1  74 0.20498615
# 2           2 271 0.75069252
# 3          NA  16 0.04432133




```

# H1 - Do expert forecasts for each domain differ significantly from the baseline. If yes, what trend do they predict?
```{r Summaries by Domain}

# Exclude rows that could not be coded due to lack of data on type of method used

datDif <- filter(datDif, TypeMerged != "")

# Create filtered data frames for each topic
datLifeSat <- filter(datDif, Issue == "lifesat")
datPosAffect <- filter(datDif, Issue == "posaffect")
datNegAffect <-filter(datDif, Issue == "negaffect")
datIdeolDem <- filter(datDif, Issue == "ideoldem")
datIdeolRep <- filter(datDif, Issue == "ideolrep")
datPolar <- filter(datDif, Issue == "polar")
datIAsian <-filter(datDif, Issue == "iasian")
datEAsian <-filter(datDif, Issue == "easian")
datIAfric <-filter(datDif, Issue == "iafric")
datEAfric <-filter(datDif, Issue == "eafric")
datIGend <-filter(datDif, Issue == "igend")
datEGend <-filter(datDif, Issue == "egend")

#Remove outliers 
datPosAffect <- filter(datPosAffect, datPosAffect$value < 0)
datNegAffect <- filter(datNegAffect, datNegAffect$value > 0)

# Summarize the data for each topic - creates a breakdown that looks that the N, mean, SD, and SE of each domain by Method used and Month as well as an aggregated summary that does differentiate between methods used

# Life Satisfaction Summary
summaryLifeSat <- plyr::ddply(datLifeSat, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryLifeSat$Method <- summaryLifeSat$TypeMerged

#Aggregated
summaryLifeSat2 <- plyr::ddply(datLifeSat, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Positive Affect Summary
summaryPosAffect <- plyr::ddply(datPosAffect, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryPosAffect$Method <- summaryPosAffect$TypeMerged

#Aggregated
summaryPosAffect2 <- plyr::ddply(datPosAffect, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Negative Affect Summary
summaryNegAffect <- plyr::ddply(datNegAffect, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryNegAffect$Method <- summaryNegAffect$TypeMerged

#Aggregated
summaryNegAffect2 <- plyr::ddply(datNegAffect, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Ideology - Republican Summary
summaryIdeolRep <- plyr::ddply(datIdeolRep, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryIdeolRep$Method <- summaryIdeolRep$TypeMerged

#Aggregated
summaryIdeolRep2 <- plyr::ddply(datIdeolRep, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Ideology - Democrat Summary
summaryIdeolDem <- plyr::ddply(datIdeolDem, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryIdeolDem$Method <- summaryIdeolDem$TypeMerged

#Aggregated
summaryIdeolDem2 <- plyr::ddply(datIdeolDem, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Polarization Summary
summaryPolar <- plyr::ddply(datPolar, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryPolar$Method <- summaryPolar$TypeMerged

#Aggregated
summaryPolar2 <- plyr::ddply(datPolar, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary Implicit Asian-American Bias
summaryIAsian <- plyr::ddply(datIAsian, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryIAsian$Method <- summaryIAsian$TypeMerged

#Aggregated
summaryIAsian2 <- plyr::ddply(datIAsian, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary Explicit Asian-American Bias
summaryEAsian <- plyr::ddply(datEAsian, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryEAsian$Method <- summaryEAsian$TypeMerged

#Aggregated
summaryEAsian2 <- plyr::ddply(datEAsian, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary Implicit African-American Bias
summaryIAfric <- plyr::ddply(datIAfric, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryIAfric$Method <- summaryIAfric$TypeMerged

#Aggregated
summaryIAfric2 <- plyr::ddply(datIAfric, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary Explicit African-American Bias
summaryEAfric <- plyr::ddply(datEAfric, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryEAfric$Method <- summaryEAfric$TypeMerged

#Aggregated
summaryEAfric2 <- plyr::ddply(datEAfric, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary Implicit Gender-Career Bias
summaryIGend <- plyr::ddply(datIGend, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryIGend$Method <- summaryIGend$TypeMerged

#Aggregated
summaryIGend2 <- plyr::ddply(datIGend, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

# Summary EXplict Gender-Career Bias
summaryEGend <- plyr::ddply(datEGend, c("TypeMerged", "Month"), summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )
summaryEGend$Method <- summaryEGend$TypeMerged

#Aggregated
summaryEGend2 <- plyr::ddply(datEGend, "Month", summarise,
                        N = length(value),
                        mean = mean(value),
                        sd = sd(value),
                        se = sd / sqrt(N)
                        )

```


```{r Overall Trends - Graphs}

setwd("./OverallTrend")


datTemp <- datDif
for (i in 1:nrow(datTemp)) {
  if (datTemp$Issue[i] == "lifesat") {
    datTemp$Issue[i] <- uniqueIssues2[1]
  } else if (datTemp$Issue[i] == "posaffect") {
    datTemp$Issue[i] <- uniqueIssues2[2]
  } else if (datTemp$Issue[i] == "negaffect") {
    datTemp$Issue[i] <- uniqueIssues2[3]
  } else if (datTemp$Issue[i] == "polar") {
    datTemp$Issue[i] <- uniqueIssues2[4]
  } else if (datTemp$Issue[i] == "iasian") {
    datTemp$Issue[i] <- uniqueIssues2[5]
  } else if (datTemp$Issue[i] == "ideolrep") {
    datTemp$Issue[i] <- uniqueIssues2[6]
  } else if (datTemp$Issue[i] == "ideoldem") {
    datTemp$Issue[i] <- uniqueIssues2[7]
  } else if (datTemp$Issue[i] == "easian") {
    datTemp$Issue[i] <- uniqueIssues2[8]
  } else if (datTemp$Issue[i] == "iafric") {
    datTemp$Issue[i] <- uniqueIssues2[9]
  } else if (datTemp$Issue[i] == "eafric") {
    datTemp$Issue[i] <- uniqueIssues2[10]
  } else if (datTemp$Issue[i] == "igend") {
    datTemp$Issue[i] <- uniqueIssues2[11]
  } else if (datTemp$Issue[i] == "egend") {
    datTemp$Issue[i] <- uniqueIssues2[12]
  }
}

summaryTrend <- ddply(datTemp, c("Issue", "Month"), summarize, 
                      N = length(value),
                      mean = mean(value),
                      sd = sd(value),
                      se = sd / sqrt(N))

TrendMean <- data.frame(
  yIntMean = historicalMean,
  yIntStart = startingPoint,
  Issue = uniqueIssues
)

TrendMean2 <- data.frame(
  yIntMean = historicalMean,
  yIntStart = startingPoint,
  Issue = uniqueIssues2
)

Plot <- ggplot(summaryTrend, aes(x = Month, y = mean, color = factor(Issue))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = lineStyle) + 
  #geom_hline(data = TrendMean, aes(yintercept = yIntMean), linetype = "dashed", size = 1) +
  geom_hline(data = TrendMean2, aes(yintercept = yIntStart), linetype = "dashed", size = 1, color = "red") +
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  #scale_y_continuous(breaks=seq(0, 2, 0.5), limits = c(0, 2.1)) +
  facet_wrap(vars(Issue), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="none") +
  labs(title = "Overall Trends - By Domain") #+

plot(Plot)

file_name <- paste0("OverallTrendsByDomain", date, ".png")
ggsave(file_name, width = 9, height = 9, dpi = 400)

setwd("..")

```

```{r Overall Trends Compared to baseline}

# t-tests to compare whether average monthly forecasts differ from baseline.

# List of Issues
# [1] "lifesat"   "posaffect" "negaffect" "polar"     "iasian"    
# [6] "ideolrep"  "ideoldem"  "easian"    "iafric"    "eafric"
# [11] "igend"     "egend"   

results <- list()
resultsDescriptive <- list()

# Create average score of each participant's forecasts to compare to the baseline for each domain

for (i in 1:length(uniqueIssues)) {
  datSel <- filter(datDifWider, datDifWider$Issue == uniqueIssues[i])
  results[[i]] <- t.test(datSel$Month.mean, alternative = "t", mu = startingPoint[i])
  resultsDescriptive[[i]] <- describe(datSel$Month.mean)
  # predictions for all domains except for 3, 5, 9, 10  differ significantly from the March baseline participants were provided. 3 (negative affect) is marginally significant / lower than the baseline
  
  # Predictions for 1, 8, 11 are all significantly lower than the baseline. 3 marginally lower
  
  # Predictions for 2, 4, 6, 7, 12 are all significantly higher than the baseline
}

# List of Issues
# [1] "lifesat"   "posaffect" "negaffect" "polar"     "iasian"    
# [6] "ideolrep"  "ideoldem"  "easian"    "iafric"    "eafric"
# [11] "igend"     "egend"   


resultsLifeSat <- c(resultsDescriptive[1], results[1])
# Life satisfaction predictions (M = 6.2, SD = 0.52) were significantly lower than the March 2020 baseline (6.46), t(57) = -3.87, p < .001

resultsPosAffect <- c(resultsDescriptive[2], results[2])
# Positive Affect predictions (M = -1.06, SD = 0.22) were significantly higher than the March 2020 baseline (-1.28), t(27) = 6.31, p < .001


resultsNegAffect <- c(resultsDescriptive[3], results[3])
# Negative Affect predictions (M = 1.11, SD = 0.29) were marginally different than the March 2020 baseline (1.21), t(27) = -1.98, p > .058

resultsPolar <- c(resultsDescriptive[4], results[4])
# Polarization predictions (M = 83.5, SD = 3.26) were significantly higher than the March 2020 baseline (77), t(31) = 3.48, p < .002

resultsIAsian <- c(resultsDescriptive[5], results[5])
# Implicit Asian-American Bias predictions (M = 0.41, SD = 0.05) were not significantly different than the March 2020 baseline (0.411), t(29) = -0.48, p > .05

resultsIdeolRep <- c(resultsDescriptive[6], results[6])
# Ideology - Republican predictions (M = 37.42, SD = 3.24) were significantly higher than the March 2020 baseline (35.7), t(33) = 3.09, p < .01

resultsIdeolDem <- c(resultsDescriptive[7], results[7])
# Polarization predictions (M = 44.87, SD = 2.41) were significantly higher than the March 2020 baseline (43.75), t(33) = 2.708, p < .02

resultsEAsian <- c(resultsDescriptive[8], results[8])
# Explicit Asian-American Bias predictions (M = 0.04, SD = 0.1) were significantly lower than the March 2020 baseline (0.119), t(25) = -4.13, p < .001

resultsIAfric <- c(resultsDescriptive[9], results[9])
# Implicit African-American Bias predictions (M = 0.32, SD = 0.01) were not significantly different than the March 2020 baseline (0.32), t(24) = -1.25, p > .05

resultsEAfric <- c(resultsDescriptive[10], results[10])
# Explicit African-American Bias predictions (M = -0.06, SD = 0.05) were not significantly different than the March 2020 baseline (-0.07), t(22) = 0.895, p > .05

resultsIGend <- c(resultsDescriptive[11], results[11])
# Implicit Gender-Career Bias predictions (M = 0.36, SD = 0.02) were significantly lower than the March 2020 baseline (0.3745), t(21) = -3.25, p < .01

resultsEGend <- c(resultsDescriptive[12], results[12])
# Explicit Gender-Career Bias predictions (M = 0.82, SD = 0.04) were significantly higher than the March 2020 baseline (0.791), t(20) = 2.89, p < .01



groupByDomain <- datDifWider %>% group_by(Issue.Factor) %>% summary (
  M = mean(Month.mean),
  SD = sd(Month.mean),
  
)

names(groupByDomain)[names(groupByDomain) == "Issue.Factor"] <- "Domain"

toMerge <- data.frame(Domain = uniqueIssues,
                      baseline = startingPoint,
                      DF = c(57, 26, 26, 31, 29, 32, 32, 27, 24, 22, 21, 20),
                      t = c(-3.867, 6.172, -1.883, 11.299, -1.072, 2.89, 2.896, -2.186, -1.254, 0.895, -3.253, 2.89),
                      p_value = c("<.001", "<.001", ">.05", "<.001", ">.05", "<.01", "<.01", ".0377", ">.05", ">.05", "<.01", "<.01")
)


```


# H2 - How do forecasts generated via different forecasting methods (Intuition/Theory, Data-Driven, Hybrid) differ from each other? Specifically, are some of the forecast methods showing more extreme patterns than others?

```{r Aggregate Trends - Absolute Differences Graph}
# Look just at main effect analysis + footnote about life satisfaction

# TO DO: Summarize the absolute difference from the baseline by method used across all domains

# Compared all methods by absolute score on a single graph

# Summarize the absolute difference from the baseline by method used across all domains
summaryDif <- plyr::ddply(datDif, c( "TypeMerged" , "Month"), summarise,
                        N = length(Difference.Abs),
                        mean = mean(Difference.Abs),
                        sd = sd(Difference.Abs),
                        se = sd / sqrt(N)
                        )

# create column with consistent name used in other graphs
summaryDif$Method <- summaryDif$TypeMerged

# Create labels for graph based on method used
textDif1 <- data.frame(
  label = c("N = 137", "N = 151", "N = 71"),
  Method = c("Data-Driven", "Intuition/Theory", "Mixed")
)

# Plot 3 graphs - 1 for each method  
Plot <- ggplot(summaryDif, aes(x = Month, y = mean, colour = factor(Method))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = lineStyle) + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.10, 0.25, 0.03), limits = c(0.10, 0.28)) +
  facet_wrap(vars(Method), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "Extremity in responses by method used") +
  geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)
# setwd("./Graphs/AbsoluteDifference")
# file_name <- paste0("Combined_Differences_Methods_", date, ".png")
# ggsave(file_name, width = 9, height = 9, dpi = 400)

```

```{r Aggregate Trends - Descriptives}

# Get list of descriptives for each of the methods used
tempList <- list()

for (i in 1:length(Methods)) {
  dat <- filter(datDif, datDif$TypeMerged == Methods[i])
  tempList[[i]] <- describe(dat$Difference.Abs)
}

# Intuition/Theory
#    vars    n mean   sd median trimmed  mad min  max range skew kurtosis   se
# X1    1 1812 0.21 0.41   0.07    0.12 0.09   0 2.69  2.69 3.83    15.85 0.01

# Data-Driven
#    vars    n mean   sd median trimmed  mad min  max range skew kurtosis   se
# X1    1 1644 0.19 0.35   0.06    0.09 0.07   0 2.22  2.22 2.82     7.43 0.01

# Mixed
#    vars   n mean   sd median trimmed  mad min  max range skew kurtosis   se
# X1    1 852 0.18 0.36   0.05    0.08 0.06   0 2.12  2.12  3.4    11.76 0.01

```
  
```{r Aggregate Trends - Absolute Differences ANOVA}

# ANOVA - Absolute Difference ~ Method used

analysis.Abs1 <-lmer(Difference.Abs ~ Type.Final.Factor * M0 +(1|team_name),data=datDif)


anova.Abs1 <- car::Anova(analysis.Abs1,type="III")

# Analysis of Deviance Table (Type III Wald chisquare tests)
# 
# Response: Difference.Abs
#                        Chisq Df Pr(>Chisq)    
# (Intercept)          20.2828  1 0.00000668 ***
# Type.Final.Factor    15.5456  2   0.000421 ***
# M0                    0.0149  1   0.902962    
# Type.Final.Factor:M0  0.9729  2   0.614803 

# Main effect of Method used, but no effect of Month and no interaction of Month * Method used, 

summary(analysis.Abs1)

# fixed effect of mixed method

# Linear mixed model fit by REML ['lmerMod']
# Formula: Difference.Abs ~ Type.Final.Factor * M0 + (1 | team_name)
#    Data: datDif
# 
# REML criterion at convergence: 2720.6
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -2.0221 -0.4849 -0.1997  0.0605  6.3537 
# 
# Random effects:
#  Groups    Name        Variance Std.Dev.
#  team_name (Intercept) 0.02035  0.1427  
#  Residual              0.10465  0.3235  
# Number of obs: 4308, groups:  team_name, 86
# 
# Fixed effects:
#                                        Estimate Std. Error t value
# (Intercept)                           0.1456041  0.0323302   4.504
# Type.Final.FactorIntuition/Theory     0.0435317  0.0395964   1.099
# Type.Final.FactorMixed               -0.0908401  0.0399434  -2.274
# M0                                   -0.0002818  0.0023112  -0.122
# Type.Final.FactorIntuition/Theory:M0  0.0021247  0.0031918   0.666
# Type.Final.FactorMixed:M0             0.0037229  0.0039558   0.941
# 
# Correlation of Fixed Effects:
#             (Intr) Ty.F.FI/T Ty.F.FM M0     T.F.FI/T:
# Typ.Fn.FI/T -0.779                                   
# Typ.Fnl.FcM -0.676  0.624                            
# M0          -0.393  0.321     0.318                  
# T.F.FI/T:M0  0.285 -0.443    -0.230  -0.724          
# Typ.F.FM:M0  0.230 -0.188    -0.545  -0.584  0.423 
# 
# jtools::summ(analysis.Abs1)


# MODEL INFO:
# Observations: 4308
# Dependent Variable: Difference.Abs
# Type: Mixed effects linear regression 
# 
# MODEL FIT:
# AIC = 2736.56, BIC = 2787.51
# Pseudo-R² (fixed effects) = 0.02
# Pseudo-R² (total) = 0.18 
# 
# FIXED EFFECTS:
# 
#                                               Est.   S.E.   t val.      d.f.      p
# 
# (Intercept)                                   0.15   0.03     4.49    173.90   0.00
# Type.Final.FactorIntuition/Theory             0.04   0.04     1.09    247.44   0.27
# Type.Final.FactorMixed                       -0.09   0.04    -2.26    567.91   0.02
# M0                                           -0.00   0.00    -0.12   4218.88   0.90
# Type.Final.FactorIntuition/Theory:M0          0.00   0.00     0.67   4218.88   0.51
# Type.Final.FactorMixed:M0                     0.00   0.00     0.94   4218.88   0.35
# 
# 
# p values calculated using Kenward-Roger standard errors and d.f.
# 
# RANDOM EFFECTS:
# 
#    Group      Parameter    Std. Dev. 
# 
#  team_name   (Intercept)     0.14    
#  Residual                    0.32    
# 
# 
# Grouping variables:
# 
#    Group     # groups   ICC  
# 
#  team_name      86      0.16 
# 
```

```{r Aggregate Trends - Absolute Differences emmeans}

#Unique Issues order
#  [1] "lifesat"   "posaffect" "negaffect" "polar"     "iasian"    
#  [6]"ideolrep"  "ideoldem"  "easian"    "iafric"    "eafric"   
#  [11] "igend"     "egend"    

# Compare estimated marginal means to investigate whether predictions differ significantly in the degree of variance


# Aggregated - Basic Methods

emmeans::emmeans(analysis.Abs1, ~ Type.Final.Factor, pbkrtest.limit = 4308)

#  Type.Final.Factor emmean     SE  df lower.CL upper.CL
#  Data-Driven       0.1441 0.0299 125   0.0850    0.203
#  Intuition/Theory  0.1993 0.0218 116   0.1562    0.242
#  Mixed             0.0737 0.0242 192   0.0259    0.121
# 
# Degrees-of-freedom method: kenward-roger 
# Confidence level used: 0.95 

emmeans::contrast(emmeans(analysis.Abs1, pairwise ~ Type.Final.Factor, pbkrtest.limit = 4308), lmerTest.limit = 4308)

# $emmeans
#  contrast                  estimate     SE  df t.ratio p.value
#  (Data-Driven) effect       0.00505 0.0213 187  0.237  0.8128 
#  (Intuition/Theory) effect  0.06027 0.0179 198  3.361  0.0014 
#  Mixed effect              -0.06532 0.0166 558 -3.937  0.0003 
# 
# Degrees-of-freedom method: kenward-roger 
# P value adjustment: fdr method for 3 tests 
# 
# $contrasts
#  contrast                                    estimate     SE  df t.ratio p.value
#  ((Data-Driven) - (Intuition/Theory)) effect  -0.1021 0.0258 245 -3.957  0.0003 
#  ((Data-Driven) - Mixed) effect                0.0235 0.0112 292  2.088  0.0377 
#  ((Intuition/Theory) - Mixed) effect           0.0787 0.0291 173  2.708  0.0112 
# 
# Degrees-of-freedom method: kenward-roger 
# P value adjustment: fdr method for 3 tests 

# All methods were significantly different from each other: Data-Driven - Intuition/Theory (p = .0002). Data-Driven - Mixed Method (p < .036). Intuition - Mixed Method (p < .01).


```

## H2 - Life Satisfaction

```{r Life Satisfaction - Plot}

textLifeSat <- data.frame(
  label = c("N = 26", "N = 14", "N = 18"),
  Method = c("Intuition/Theory", "Data-Driven", "Mixed")
)

lifeSatPlot <- ggplot(datLifeSat, aes(x = Month, y = value, colour = Method)) + 
  theme_minimal(base_size = 14) +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge") +
  geom_smooth(method = lineStyle) + 
  # geom_hline(yintercept = historicalMean[1], linetype = "dashed") +
  geom_hline(yintercept = startingPoint[1], linetype = "dotdash", color = "red") +
  xAxis +
  scale_y_continuous(breaks=seq(2.4, 7, 0.5), limits = c(2.4, 7.5)) +
  geom_point(position=position_jitter(width=1, height=.4), color = "black", alpha = 0.25, size = 0.5) +
  facet_wrap(vars(Method), scales = "free", nrow = 1, ncol = 3) +
  #geom_errorbar(aes(ymin=mean-se, ymax=mean+se), data = summaryLifeSat) +
  theme(legend.position="bottom") +
  labs(title = "Life Satisfaction Predictions by Method") +
  geom_text (data = textLifeSat, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -1)
  

#plot_grid()

plot(lifeSatPlot)
# setwd("./Graphs/ByIssue")
# file_name <- paste0("LifeSat_", date, ".png")
# ggsave(file_name)

```

```{r Life Satisfaction - ANOVA}

analysis.lifesat <-lmer(value~Type.Final.Factor * M0 +(1|team_name),data=datLifeSat)


car::Anova(analysis.lifesat,type="III")
# 
# Analysis of Deviance Table (Type III Wald chisquare tests)
# 
# Response: value
#                          Chisq Df          Pr(>Chisq)    
# (Intercept)          2044.3792  1 <0.0000000000000002 ***
# Type.Final.Factor       4.1439  2              0.1259    
# M0                      0.9506  1              0.3296    
# Type.Final.Factor:M0    3.4625  2              0.1771   
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

# No significant main effect or interaction for life satisfaction

emmeans::emmeans(lifesat.analysis, ~ Type.Final.Factor)

emmeans::contrast(emmeans(lifesat.analysis, pairwise ~ Type.Final.Factor))
```

# H3 - To what degree do data-driven forecasting approaches differ from each other? Specifically, are forecasts made using complex statistical models significantly different from forecasts made using naïve and other simpler approaches (e.g., mean regression, average of prior data points)?

```{r Method Complexity - Absolute Differences Graph}

# Compared all methods by absolute score on a single graph

summaryCom <- plyr::ddply(datComplexData, c( "Complexity.Final.Factored" , "Month"), summarize,
                        N = length(Difference.Abs),
                        mean = mean(Difference.Abs),
                        sd = sd(Difference.Abs),
                        se = sd / sqrt(N)
                        )
summaryCom$Method <- summaryCom$Complexity.Final.Factored

textDif1 <- data.frame(
  label = c("N = 49", "N = 87", "N = 65"),
  Method = c("Naive", "Moderate", "Complex")
)

yTemp <- c(historicalMean.Abs[10], historicalMean.Abs[8], historicalMean.Abs[12], historicalMean.Abs[9], historicalMean.Abs[5], historicalMean.Abs[6], historicalMean.Abs[7], historicalMean.Abs[11], historicalMean.Abs[1], historicalMean.Abs[3], historicalMean.Abs[4], historicalMean.Abs[2])
yInt <- mean(yTemp)




Plot <- ggplot(summaryCom, aes(x = Month, y = mean, colour = factor(Method))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = lineStyle) + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.10, 0.22, 0.04), limits = c(0.10, 0.22)) +
  facet_wrap(vars(Method), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "Extremity of responses by Complexity of Method used") +
  geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)
# setwd("./Graphs/AbsoluteDifference")
 file_name <- paste0("Combined_Differences_Methods_", date, ".png")
 ggsave(file_name, width = 9, height = 9, dpi = 400)

```


```{r Descriptives - Complexity}
datDif$Complexity.Factor <- factor(datDif$Complexity.Final, levels = c(1, 2, 3), labels = c("Naive", "Moderate", "Complex"))

# Naive    Moderate   Complex 
Complexity_List <- unique(datDif$Complexity.Factor)
Complexity_List <- Complexity_List[c(1,2,4)]
CompList <- list()

for (i in 1:length(Complexity_List)) {
  dat <- filter(datDif, datDif$Complexity.Factor == Complexity_List[i])
  CompList[[i]] <- describe(dat$Difference.Abs)
}

```


```{r Complexity - ANOVA}

datComp <- datDif %>% subset(!is.na(Complexity.Factor))

analysis.Comp <-lmer(Difference.Abs~Complexity.Factor*M0 +(1|team_name),data=datDif)

car::Anova(analysis.Comp,type="III")

# Analysis of Deviance Table (Type III Wald chisquare tests)
# 
# Response: Difference.Abs
#                        Chisq Df          Pr(>Chisq)    
# (Intercept)          59.2092  1 0.00000000000001418 ***
# Complexity.Factor    14.3902  2           0.0007503 ***
# M0                    0.6144  1           0.4331355    
# Complexity.Factor:M0  0.1792  2           0.9142958

# Main effect of complexity but not of Month. No interaction between month & complexity


```

```{r Complexity - emmeans}

emmeans::emmeans(analysis.Comp, ~ Complexity.Factor, pbkrtest.limit = 4224)

#  Complexity.Factor emmean     SE  df lower.CL upper.CL
#  Naive              0.181 0.0199 102   0.1415    0.220
#  Moderate           0.042 0.0284 207  -0.0139    0.098
#  Complex            0.155 0.0315 161   0.0926    0.217
# 
# Degrees-of-freedom method: kenward-roger 
# Confidence level used: 0.95 

emmeans::contrast(emmeans(analysis.Comp, pairwise ~ Complexity.Factor, pbkrtest.limit = 4224), lmerTest.limit = 4224)

# $emmeans
#  contrast        estimate     SE  df t.ratio p.value
#  Naive effect      0.0550 0.0181 230  3.036  0.0040 
#  Moderate effect  -0.0839 0.0188 578 -4.454  <.0001 
#  Complex effect    0.0289 0.0218 267  1.329  0.1850 
# 
# Degrees-of-freedom method: kenward-roger 
# P value adjustment: fdr method for 3 tests 
# 
# $contrasts
#  contrast                    estimate     SE  df t.ratio p.value
#  (Naive - Moderate) effect    0.12153 0.0301 532  4.036  0.0001 
#  (Naive - Complex) effect     0.00867 0.0118 208  0.736  0.4625 
#  (Moderate - Complex) effect -0.13021 0.0276 568 -4.723  <.0001 
# 
# Degrees-of-freedom method: kenward-roger 
# P value adjustment: fdr method for 3 tests  

```

# H4 - How do self-reported subject expertise and confidence influence participant forecasts?

```{r t.tests}


desc.Con <- describe(datDifWider$confidence)
#    vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se
# X1    1 361 3.31 1.45      3    3.34 1.48   1   6     5 -0.07    -1.06 0.08


t.test.confidence <- t.test(datDifWider$confidence, alternative = "t", mu = 4)
# participants considered themselves less confident than average in their predictions

# data:  datDifWider$confidence
# t = -9.0094, df = 360, p-value < 0.00000000000000022
# alternative hypothesis: true mean is not equal to 4
# 95 percent confidence interval:
#  3.163065 3.462974
# sample estimates:
# mean of x 
#  3.313019 

# 1, 2, 4, 5, 6, 9, 10

desc.SubExp <- describe(datDifWider$subexpert)
#    vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
# X1    1 361 3.11 1.71      3    2.99 1.48   1   7     6  0.3    -0.97 0.09

t.test.subexpert <- t.test(datDifWider$subexpert, alternative = "t", mu = 4)
# participants considered themselves to be below average in expertise in the domains they forecasted

# data:  datDifWider$subexpert
# t = -9.8852, df = 360, p-value < 0.00000000000000022
# alternative hypothesis: true mean is not equal to 4
# 95 percent confidence interval:
#  2.933905 3.287702
# sample estimates:
# mean of x 
#  3.110803
```

```{r ANOVA - Confidence}

# Confidence
analysis.Conf <-lmer(Difference.Abs~confidence +(1|team_name),data=datDif)

car::Anova(analysis.Conf,type="III")

# Response: Difference.Abs
#                 Chisq Df        Pr(>Chisq)    
# (Intercept)   49.3600  1 0.000000000002131 ***
# confidence    12.6402  1         0.0003775 ***
# M0             1.8815  1         0.1701646    
# confidence:M0  1.1773  1         0.2779044

# main effect of confidence, but no effect of Month and no interaction between confidence and month


```



```{r correlation - confidence}

emmeans::emmeans(analysis.Conf, ~ confidence, pbkrtest.limit = 4308)

#  confidence emmean     SE   df lower.CL upper.CL
#        3.33  0.156 0.0178 83.8    0.121    0.192
# 
# Degrees-of-freedom method: kenward-roger 
# Confidence level used: 0.95 

emmeans::contrast(emmeans(analysis.Comp, pairwise ~ Complexity.Factor, pbkrtest.limit = 4224), lmerTest.limit = 4224)

analysis.Conf2 <-lmer(Month.mean~confidence +(1|team_name),data=datDifWider.Abs)

sjPlot::plot_model(analysis.Conf, type = "eff", title = "Predicted extremity of responses based on confidence in prediction", axis.title = c("Participant confidence", "Absolute difference from the baseline"))

# As confidence increases, extremity of forecast decreases

```


```{r ANOVA - Expertise}

analysis.Exp <-lmer(Difference.Abs~subexpert * M0 +(1|team_name),data=datDif)

car::Anova(analysis.Exp,type="III")

# Analysis of Deviance Table (Type III Wald chisquare tests)
# 
# Response: Difference.Abs
#                Chisq Df   Pr(>Chisq)    
# (Intercept)  28.3137  1 0.0000001032 ***
# subexpert     0.6519  1       0.4194    
# M0            0.0475  1       0.8275    
# subexpert:M0  0.0704  1       0.7907

# No effect or interaction of expertise / Month
```



---
title: "Wave 1+2 Analyses"
author: "Oliver Twardus"
date: "2/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
```

```{r Global Variables}

# indicates the linetype used in all graphs
lineStyle <- "loess"


# xAxis <- scale_x_continuous(breaks=seq(2, 19, 2))
# xAxis2 <- scale_x_continuous(breaks=seq(-11, 13, 4))


# list of domains
domains <- c("lifesat", "posaffect", "negaffect", "ideoldem",  "ideolrep",  "polar", "iasian", "easian", "iafric", "eafric", "igend", "egend")

```

```{r historical data}

# import 46 months of historical values up to October 2020 
dat_hist <- read.csv("historical_data.csv", stringsAsFactors = FALSE)

# Create a list of trends for each domain, ordered in the same manner as domains variable up above 
hist_trend <- list()

for (i in 1:length(domains)) {
  
  trend <- dat_hist[40, domains[i]] - dat_hist[1, domains[i]]
  hist_trend[[i]] <- trend
  
}
```



```{r Import Data}

# filters by completion time, so that prolific sample excludes predictions that took less than 50 seconds to make
dat <- read.csv("Wave1+2data_2021-06-30.csv", stringsAsFactors = FALSE)

# data set below does not filter lay sample by completion time
# dat <- read.csv("Wave1+2data_coded_2021-05-18.csv", stringsAsFactors = FALSE)

# list of notable columns and what they mean:
# * some columns are omitted because they will be removed / are redundant

# phase - value of 1 indicates submission was received during phase 1 (June 2020), value of 2 indicates submission was received during phase 2 (November 2020)

# isExpert - indicates whether submission is by an academic (1) or layperson (0)
dat$isExpert.factor <- factor(dat$isExpert, levels = c(0,1), labels = c("Prolific", "Academic"))

# revised - indicates whether a team submitted to both phase 1 & 2 of the tournament (i.e. submitted in June and then sent a revised submission in November)

# domain - indicates which domain the forecast is for. Shorthand is used here with the following terms referring to each domain:
# lifesat = Life Satisfaction
# posaffect = Positive Affect
# negaffect = Negative Affect
# ideoldem = Political Ideology - Democrat
# ideolrep = Political Ideology - Republican
# polar = Political Polarization
# iasian = Implicit Asian-American Bias
# easian = Explicit Asian-American Bias
# iafric = Implicit African-American Bias
# eafric = Explicit African-American Bias
# igend = Implicit Gender-Career Bias
# egend = Explicit Gender-Career Bias

# Month.1 - Month.18 columns list participant predictions for a given domain. 
#   All phase 1 (June) predictions range from Month.1 - Month.12
#   All phase 2 (November) predictions range from Month.7 - Month.18

# mean_error - output of forecast package's accuracy() function - displays the mean error (ME) of Month.1 - Month.6 predictions compared to the objective data
# root_mean_sqr_error - displays the root mean square error (RMSE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_error - displays the root mean absolute error (MAE) of Month.1 - Month.6 predictions compared to the objective data
# mean_percent_error - displays the mean percent error (MPE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_percent_error - displays the mean absolute percent error (MAPE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_scaled_error_1 - MASE computed using custom computeMASE function
# mean_abs_scaled_error_2 - MASE computed using Metrics::mase function

# RMSE_cutoff - whether the prediction's RMSE is less than or greater than a naive forecast for the same time period
dat$RMSE_cutoff_Naive_linear.factor <- factor(dat$RMSE_cutoff_Naive_linear, levels = c(0, 1), labels = c("below cutoff", "above cutoff"))
dat$RMSE_cutoff_Naive_rwf.factor <- factor(dat$RMSE_cutoff_Naive_rwf, levels = c(0, 1), labels = c("below cutoff", "above cutoff"))

# confidence - indicates on scale of 1-7 how confident participants were in their predictions
# subexpert - indicates on scale of 1-7 the participant's self-reported expertise in the domain they are predicting
# pub - the number of publications the team has made on the predicted domain

# model, theory, parameters - all contain participant written responses regarding what model they used, what theory they relied on, and what conditionals they considered

# numpred - number of conditionals (beyond the domain predicted) that participants considered in their prediction
# covidcondyn - whether covid-19 was considered as a conditional in their forecast
# datatrain - whether participants used the forecast data that was provided to them
# counterfact & othercounter - written response indicating the counterfactual participants considered
# counter_imp & othercountim - how important they consider their counterfactual to be

# Method - indicates forecasting method used to generate forecast - either Intuition/Theory, Data-Driven, Mixed, Simulation, or Objective - latter category is used to indicate the objective data for each domain for Months 1-6
# Method.coded - coded 1-4 scale with 1 = Intuition/Theory, 2 = Data-Driven, 3 = Mixed, 4 = Objective

dat$Method.coded.factor <- factor(dat$Method.coded, levels = c(1:4), labels = c("Intuition/Theory", "Data-Driven", "Mixed", "Objective"))

# Method.complex - ONLY PHASE 1, coded 1-3 scale indicating whether the Data-driven or Mixed method used is simple (e.g. regression to the mean), moderate (e.g. auto-regression w time lag, univariate time series), or complex (e.g. ARIMA, dynamic econometric model)

dat$Method.complex.factor <- factor(dat$Method.complex, levels = c(1:3), labels = c("simple", "moderate", "complex"))

# team_size.coded - self-reported measure indicating number of team-members in the team
# team_expertise - written response of team's general expertise

# FOLLOWING VARIABLES ARE EXCLUSIVE TO LAY SAMPLE because it consists entirely of individuals whereas academic sample consists of teams
# Age (num)
# Sex (1 = Male, 2 = Female, 3 = Prefer not to say)
dat$Sex.factor <- factor(dat$Sex, levels = c(1:3), labels = c("Male", "Female", "Prefer not to say")) 

# Genderident (1 = trans/woman, 2= trans/man, 3= genderqueer, 4 = Prefer not to say, 5 = other)
dat$Genderident.factor <- factor(dat$Genderident, levels = c(1:5), labels = c("trans/woman", "trans/man", "genderqueer", "Prefer not to say", "other"))

# education (1-8 = less than highschool, high school, some college, Vocation or technical school, Bachelor's, Master's, Doctorate, Professional degree)
dat$education.factor <- factor(dat$Education, levels = c(1:8), labels = c("less than highschool", "high school", "some college", "Vocation or technical school", "Bachelor's", "Master's", "Doctorate", "Professional degree"))
# occupation (written response)

# Ethnicity
dat$Ethnicity.factor <- factor(dat$Ethnicity, levels = c(1:9), labels = c("Aboriginal/Native", "Asian", "Black", "White", "Middle Eastern", "Hispanic", "East Indian", "Mixed Race", "Other/Not Listed"))

# Religion
dat$Religion.factor <- factor(dat$Religion, levels = c(1:10), labels = c("Buddhist", "Christian - Catholic", "Christian - Protestant", "Christian - Other", "Hindu", "Jewish", "Muslim", "Sikh", "Other", "Non-Religious"))

# Income
dat$Income.factor <- factor(dat$Income, levels = c(1:8), labels = c("Under $15,000", "$15,001 - $25,000", "$25,001 - $35,000", "$35,001 - $50,000", "$50,001 - $75,000", "$75,001 - $100,000", "$100,001 - $150,000", "Over $150,000"))

# Residential Area
dat$Residential.Area.factor <- factor(dat$Residential.Area, levels = c(1:3), labels = c("Urban", "Suburban", "Rural"))

# Whether the team is multi-disciplinary (1) or mono (0)
dat$multi_dis.factor <- factor(dat$is_multidisciplinary, levels = c(0, 1), labels = c("Single domain expertise", "Multi domain expertise"))

```

```{r Data - long format}


# dat_long <- read.csv("Wave1+2data_coded_long_2021-05-18.csv", stringsAsFactors = FALSE)

# create long format of dat, with a few added columns:

# Month - specific Month being forecasted, from 1 (May 2020) to 18 (May 2021)
# value - value predicted for the given Month
# value.dif - value predicted minus the objective value for that domain/Month - currently only present for Months 1-6 until we get the full data from our Konstantyn

# set dataframe to long format
dat_long <- pivot_longer(dat, cols = starts_with("Month"), names_to = "Month", names_prefix = "Month.")
dat_long$Month <- as.numeric(dat_long$Month)

# exclude rows without values in the "value" column
dat_long <- filter(dat_long, !is.na(value))


# add column to store difference values as change compared to objective results for that given month/domain
dat_long$value.dif <- as.numeric(NA)

# for each of the 12 domains, get pre
for (i in 1:length(domains)) {
  
  # Retrieve row with correct historical value for the domain
  hist <- dat[which(dat$domain == domains[i] & dat$Method == "Objective"), ]
  
  for (n in 1:6) {
    # retrieve all rows from dat_long that match the domain + Month for Months 1-6 and calculate the correct
    dat_long[which(dat_long$domain == domains[i] & dat_long$Month == n), "value.dif" ] <- dat_long[which(dat_long$domain == domains[i] & dat_long$Month == n), "value" ] - hist[1, paste0("Month.", n)]
  }
  
  
}

# create subsetted version that only includes
# dat_long <- dat_long %>% subset(flag_lay_response == 0 | is.na(flag_lay_response))

```

```{r Import Team member Demographic info}

# contains demographics info from participants who responded to the survey. Team names have been corrected to match those in the dat_exp dataframe


dat_demo <- read.csv("Wave1+2demographics_2021-05-19.csv", stringsAsFactors = FALSE)

# demo_1 - participant name
# demo_2 - participant email
# education - 1-5 indicating current role: undergrad, grad, postdoc/fellow, Professor, Other (with text entry)
# educaton2 - 1-5 indicating how much education they have: some uni/college, bachelors, masters, PhD, Other
# gender - 1 = Male, 2 = Female
# org - what kind of organization they're affiliated with - 1 = college/university, 2 = government, 3 = Private Company, 4 = self-employed, 5 = other
# expertise 1 & 2 - written responses on areas of expertise 
# prevtournament - Whether they participated in a previous forecasting tournament 1 = Yes, 2 = No
# prevtour_list - written response of previous tournaments

# creating factor columns for the following variables:

# Academic sample - academic position
dat_demo$position.factor <- factor(dat_demo$education, levels = c(1:5), labels = c("Undergrad", "Grad", "Postdoc/fellow", "Professor", "Other"))

# Academic sample - education attained
dat_demo$education.factor <- factor(dat_demo$education, levels = c(1:5), labels = c("some uni/college", "bachelors", "masters", "PhD", "Other"))

# Academic sample - sex
dat_demo$sex_acad.factor <- factor(dat_demo$gender, levels = c(1:3), labels = c("Male", "Female", "Other"))

# Academic sample - organization/affiliation
dat_demo$org.factor <- factor(dat_demo$org, levels = c(1:5), labels = c("College/University", "Government", "Private Company", "Self-Employed", "Other"))


# data set to use for graphs/analyses - excludes all lay responses that were flagged for misunderstanding task/not answering correctly.


```

```{r Academic sample descriptives}

#datasets that are filtered by phase (1 = May, 2 = November)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)

# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)


# dataset that only includes academic predictions
academic_only <- filter(dat, isExpert == 1)

# Number of predictions by project phase + group
num_forecast <- dat %>% group_by(phase, isExpert.factor) %>% 
  dplyr::summarise(
  N = length(isExpert.factor),
  Percent =  N / nrow(dat)
)

#   phase isExpert.factor     N Percent
#   
# 1     1 Prolific         2330  0.750 
# 2     1 Academic          361  0.116 
# 3     1 NA                 36  0.0116
# 4     2 Academic          381  0.123

# 742 predictions total, 361 during phase 1, 381 during phase 2. NA refers to forecasts that are either historical data or generated via naive methods for analytical purposes.

# Number of teams per phase
team_num <- academic_only %>% group_by(phase) %>% 
  dplyr::summarise(
  numberOfTeams = length(unique(team_name))
)

# Number of teams total
team_num_total <- length(unique(academic_only$team_name))

# 122 teams total, 87 teams participated during phase 1 (88th team is NA because I didn't filter out lay sample), 72 during phase 2 

# Filter so that only one row per team is retained
unique_teams <- academic_only[!duplicated(academic_only$team_name),]


describe(unique_teams$team_size.coded)

#    vars   n mean   sd median trimmed mad min max range skew kurtosis   se
# X1    1 105 1.66 1.16      1     1.4   0   1   7     6 2.04     4.32 0.11

# team size ranged from 1-7, n = 100, Md = 1, M = 1.67
# 1 was the most common team size (65%)

# Summarize spread of teams size (does not exclude NAs)
summarySize <- plyr::ddply(unique_teams, c("team_size.coded"), summarize,
                        N = length(team_size.coded),
                        Percent = N / nrow(unique_teams)
                        )

#   team_size.coded  N               Percent
# 1         1 70 0.5737704918032786594
# 2         2 16 0.1311475409836065642
# 3         3 10 0.0819672131147540922
# 4         4  5 0.0409836065573770461
# 5         5  3 0.0245901639344262291
# 6         7  1 0.0081967213114754103
# 7        NA 17 0.1393442622950819554

# Filter data set by project wave
phase1_team <- filter(unique_teams, team_name %in% phase1$team_name)


# distribution of team size for phase 1
summarySize1 <- plyr::ddply(phase1_team, c("team_size.coded"), summarize,
                        N = length(team_size.coded),
                        Percent = N / nrow(phase1_team)
                        )

#   team_size.coded  N              Percent
# 1         1 48 0.551724137931034475
# 2         2 12 0.137931034482758619
# 3         3  5 0.057471264367816091
# 4         4  4 0.045977011494252873
# 5         5  2 0.022988505747126436
# 6         7  1 0.011494252873563218
# 7        NA 15 0.172413793103448287


phase2_team <- filter(unique_teams, team_name %in% phase2$team_name)

# distribution of team size for phase 2
summarySize2 <- plyr::ddply(phase2_team, c("team_size.coded"), summarize,
                        N = length(team_size.coded),
                        Percent = N / nrow(phase2_team)
                        )

#   team_size.coded  N              Percent
# 1         1 44 0.611111111111111160
# 2         2 11 0.152777777777777790
# 3         3  9 0.125000000000000000
# 4         4  2 0.027777777777777776
# 5         5  3 0.041666666666666664
# 6         7  1 0.013888888888888888
# 7        NA  2 0.027777777777777776


# Number of predictions below/above RMSE cutoff

# overall
naive_RMSE_all <- phase1_exp %>% group_by(RMSE_cutoff_Naive_linear.factor) %>% 
  dplyr::summarise(
  N = length(RMSE_cutoff_Naive_linear.factor),
  Percent = N / nrow(phase1_exp)
)

#   RMSE_cutoff.factor     N Percent
# 
# 1 below cutoff          93   0.258
# 2 above cutoff         268   0.742

# 74.2% of predictions were above the RMSE cutoff

# Per domain
naive_RMSE_domain <- phase1_exp %>% group_by(domain, RMSE_cutoff_Naive_linear.factor) %>% 
  dplyr::summarise(
  N = length(RMSE_cutoff_Naive_linear.factor)
)

naive_RMSE_domain$Percent <- NA

for (i in 1:nrow(naive_RMSE_domain)) {
  filter <- filter(phase1_exp, domain == naive_RMSE_domain$domain[i])
  naive_RMSE_domain$Percent[i] <- naive_RMSE_domain$N[i] / nrow(filter)
}
  
# Implicit Asian bias, explicit African American, and positive affect were all 100% above the cutoff
# More than 60% of predictions for implicit gender, ideology-republican, and ideology-democrat were below the cutoff

# look at multi-disciplinarity

multidisciplinarity <- phase1_exp %>% group_by(is_multidisciplinary) %>% 
  dplyr::summarise(
  N = length(is_multidisciplinary),
  Percent = N / nrow(phase1_exp)
)

#   is_multidisciplinary     N Percent
#                 
# 1                    0   302  0.837 
# 2                    1    20  0.0554
# 3                   NA    39  0.108 


```

```{r Prolific Descriptives}

# List of descriptives for prolific sample

# filter sample to only include unflagged Prolific responses
dat_lay_demo <- subset(dat, isExpert == 0 & flag_lay_response == 0)

# time spent on upload task
time_spent_desc_up <- describe(dat_lay_demo$time_upload)

#    vars    n   mean     sd median trimmed   mad min     max   range skew kurtosis   se
# X1    1 2226 126.69 200.94   75.1   87.48 68.64   0 3434.49 3434.49 6.47    75.26 4.26

age_stats <- describe(dat_lay_demo$Age)
#    vars    n  mean    sd median trimmed mad min max range skew kurtosis   se
# X1    1 2200 29.94 10.18     28    28.5 8.9  18  78    60 1.33     1.95 0.22


#Education
prolific_edu <- dat_lay_demo %>% group_by(education.factor) %>% 
  dplyr::summarise(
  N = length(education.factor),
  Percent =  N / nrow(dat_lay_demo)
)
#   education.factor                 N Percent
#   
# 1 less than highschool             5 0.00340
# 2 high school                    114 0.0776 
# 3 some college                   341 0.232  
# 4 Vocation or technical school    59 0.0401 
# 5 Bachelor's                     582 0.396  
# 6 Master's                       226 0.154  
# 7 Doctorate                       24 0.0163 
# 8 Professional degree             41 0.0279 
# 9 NA                              78 0.0531

# Ethnicity
prolific_eth <- dat_lay_demo %>% group_by(Ethnicity.factor) %>% 
  dplyr::summarise(
  N = length(Ethnicity.factor),
  Percent =  N / nrow(dat_lay_demo)
)

#    Ethnicity.factor      N Percent
#    
#  1 Aboriginal/Native    10 0.00680
#  2 Asian               237 0.161  
#  3 Black               131 0.0891 
#  4 White               828 0.563  
#  5 Middle Eastern       10 0.00680
#  6 Hispanic            103 0.0701 
#  7 East Indian          11 0.00748
#  8 Mixed Race           48 0.0327 
#  9 Other/Not Listed     11 0.00748
# 10 NA                   81 0.0551

# Religion
prolific_rel <- dat_lay_demo %>% group_by(Religion.factor) %>% 
  dplyr::summarise(
  N = length(Religion.factor),
  Percent =  N / nrow(dat_lay_demo)
)

#    Religion.factor            N  Percent
#    
#  1 Buddhist                  29 0.0197 
#  2 Christian - Catholic     199 0.135  
#  3 Christian - Protestant   214 0.146  
#  4 Christian - Other        131 0.0891 
#  5 Hindu                     27 0.0184 
#  6 Jewish                    36 0.0245 
#  7 Muslim                    57 0.0388 
#  8 Sikh                       2 0.00136
#  9 Other                     57 0.0388 
# 10 Non-Religious            638 0.434  
# 11 NA                        80 0.0544


# Politics
prolific_pol <- dat_lay_demo %>% group_by(Politics_1) %>% 
  dplyr::summarise(
  N = length(Politics_1),
  Percent =  N / nrow(dat_lay_demo)
)

#   Politics_1     N Percent
# 
# 1          1   343  0.233 
# 2          2   313  0.213 
# 3          3   192  0.131 
# 4          4   300  0.204 
# 5          5   128  0.0871
# 6          6    84  0.0571
# 7          7    32  0.0218
# 8         NA    78  0.0531

# Residential Area
prolific_res <- dat_lay_demo %>% group_by(Residential.Area.factor) %>% 
  dplyr::summarise(
  N = length(Residential.Area.factor),
  Percent =  N / nrow(dat_lay_demo)
)

#   Residential.Area.factor     N Percent
#   
# 1 Urban                     452  0.307 
# 2 Suburban                  791  0.538 
# 3 Rural                     147  0.1   
# 4 NA                         80  0.0544

# Income
prolific_inc <- dat_lay_demo %>% group_by(Income.factor) %>% 
  dplyr::summarise(
  N = length(Income.factor),
  Percent =  N / nrow(dat_lay_demo)
)

#   Income.factor           N Percent
# 
# 1 Under $15,000          92  0.0626
# 2 $15,001 - $25,000     106  0.0721
# 3 $25,001 - $35,000     129  0.0878
# 4 $35,001 - $50,000     179  0.122 
# 5 $50,001 - $75,000     292  0.199 
# 6 $75,001 - $100,000    227  0.154 
# 7 $100,001 - $150,000   189  0.129 
# 8 Over $150,000         165  0.112 
# 9 NA                     91  0.0619

```

```{r life satisfaction}

lifesat <- dat_long %>% subset(domain == "lifesat" & phase == 1 & !is.na(isExpert.factor))

lifesat1 <- lifesat %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(lifesat1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(5.8, 6.4, 0.1), limits = c(5.8, 6.4)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "life satisfaction academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.lifesat <-lmer(value~isExpert+(1|ResponseId),data=lifesat)
anova.lifesat <- car::Anova(analysis.lifesat,type="III")


```

```{r positive affect}

posaffect <- dat_long %>% subset(domain == "posaffect" & phase == 1 & !is.na(isExpert.factor))

posaffect1 <- posaffect %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(posaffect1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(-1.15, -0.4, 0.1), limits = c(-1.15, -0.4)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "positive affect academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.posaffect <-lmer(value~isExpert+(1|ResponseId),data=posaffect)
anova.posaffect <- car::Anova(analysis.posaffect,type="III")

```

```{r negative affect}

negaffect <- dat_long %>% subset(domain == "negaffect" & phase == 1 & !is.na(isExpert.factor))

negaffect1 <- negaffect %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(negaffect1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.85, 1.25, 0.1), limits = c(0.85, 1.25)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "negative affect academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.negaffect <-lmer(value~isExpert+(1|ResponseId),data=negaffect)
anova.negaffect <- car::Anova(analysis.negaffect,type="III")

```

```{r ideology - democrat}

ideoldem <- dat_long %>% subset(domain == "ideoldem" & phase == 1 & !is.na(isExpert.factor))

ideoldem1 <- ideoldem %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(ideoldem1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(43, 47, 1), limits = c(43, 47)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "ideology - democrat academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.ideoldem <-lmer(value~isExpert+(1|ResponseId),data=ideoldem)
anova.ideoldem <- car::Anova(analysis.ideoldem,type="III")

```

```{r ideology - republican}

ideolrep <- dat_long %>% subset(domain == "ideolrep" & phase == 1 & !is.na(isExpert.factor))

ideolrep1 <- ideolrep %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(ideolrep1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(35, 39, 1), limits = c(34.5, 39)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "ideology - republican academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.ideolrep <-lmer(value~isExpert+(1|ResponseId),data=ideolrep)
anova.ideolrep <- car::Anova(analysis.ideolrep,type="III")

```

```{r  polarization}

polar <- dat_long %>% subset(domain == "polar" & phase == 1 & !is.na(isExpert.factor))

polar1 <- polar %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(polar1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(73, 85, 2), limits = c(73, 86)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "polarization academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.polar <-lmer(value~isExpert+(1|ResponseId),data=polar)
anova.polar <- car::Anova(analysis.polar,type="III")

```

```{r explicit asian american}

easian <- dat_long %>% subset(domain == "easian" & phase == 1 & !is.na(isExpert.factor))

easian1 <- easian %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(easian1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0, 0.35, 0.07), limits = c(0, 0.35)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit Asian bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.easian <-lmer(value~isExpert.factor+(1|ResponseId),data=easian)
anova.easian <- car::Anova(analysis.easian,type="III")


```

```{r implicit asian american}

iasian <- dat_long %>% subset(domain == "iasian" & phase == 1 & !is.na(isExpert.factor))

iasian1 <- iasian %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(iasian1, aes(x = Month, y = mean, colour = isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.37, 0.43, 0.02), limits = c(0.37, 0.44)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit Asian bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.iasian <-lmer(value~isExpert+(1|ResponseId),data=iasian)
anova.iasian <- car::Anova(analysis.iasian,type="III")

```


```{r explicit african american}

eafric <- dat_long %>% subset(domain == "eafric" & phase == 1 & !is.na(isExpert))
eafric1 <- eafric %>% subset(!is.na(isExpert))

eafric1 <- eafric1 %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)



Plot <- ggplot(eafric1, aes(x = Month, y = mean, colour = isExpert.factor)) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(-0.20, 0.15, 0.07), limits = c(-0.2, 0.15)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit African bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.eafric <-lmer(value~isExpert.factor+(1|ResponseId),data=eafric)
anova.eafric <- car::Anova(analysis.eafric,type="III")


```

```{r implicit african american}

iafric <- dat_long %>% subset(domain == "iafric" & phase == 1 & !is.na(isExpert.factor))

iafric1 <- iafric %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(iafric1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.29, 0.33, 0.01), limits = c(0.288, 0.33)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit African bias academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.iafric <-lmer(value~isExpert+(1|ResponseId),data=iafric)
anova.iafric <- car::Anova(analysis.iafric,type="III")

```

```{r explicit gender-career bias}

egend <- dat_long %>% subset(domain == "egend" & phase == 1 & !is.na(isExpert.factor))

egend1 <- egend %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(egend1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.8, 1.2, 0.1), limits = c(0.78, 1.2)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "explicit gender academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.egend <-lmer(value~isExpert+(1|ResponseId),data=egend)
anova.egend <- car::Anova(analysis.egend,type="III")

```

```{r implicit gender-career bias}

igend <- dat_long %>% subset(domain == "igend" & phase == 1 & !is.na(isExpert.factor))

igend1 <- igend %>% group_by(isExpert.factor, Month) %>% 
  dplyr::summarise(
  N = length(value),
  mean = mean(value),
  sd = sd(value),
  se = sd / sqrt(N)
)

Plot <- ggplot(igend1, aes(x = Month, y = mean, colour = factor(isExpert.factor))) + 
  theme_minimal(base_size = 14) +
  geom_smooth(method = "loess") + 
  geom_point() +
  scale_x_continuous(breaks=seq(1, 13, 3)) + 
  scale_y_continuous(breaks=seq(0.35, 0.4, 0.01), limits = c(0.35, 0.405)) +
  facet_wrap(vars(isExpert.factor), scales = "free", nrow = 3, ncol = 4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
  theme(legend.position="bottom") +
  labs(title = "implicit gender academic vs prolific") #+
  #geom_text (data = textDif1, mapping = aes(x = -Inf, y = -Inf, label = label), hjust   = -0.1, vjust   = -0.5)


plot(Plot)

analysis.igend <-lmer(value~isExpert+(1|ResponseId),data=igend)
anova.igend <- car::Anova(analysis.igend,type="III")

```

```{r differences by team size}

# look at whether team multi-disciplinarity has any impact
analysis.disc <-lmer(root_mean_sqr_error~is_multidisciplinary+(1|ResponseId),data=phase1_exp)
anova.disc <- car::Anova(analysis.disc,type="III")

# no effect of multi-disciplinarity

# look at whether team size has an effect on RMSE
analysis.teams <- lmer(root_mean_sqr_error~team_size.coded+(1|ResponseId), data = phase1_exp)
anova.teams <- car::Anova(analysis.teams,type="III")

# no effect of team size of RMSE

# instead split into 2 groups: solo (team size = 1) and group (team size = 2+)
phase1_exp$team_size.grouped <- ifelse(phase1_exp$team_size.coded > 1, 2, phase1_exp$team_size.coded)

analysis.teams2 <- lmer(root_mean_sqr_error~factor(team_size.grouped)+(1|ResponseId), data = phase1_exp)
anova.teams2 <- car::Anova(analysis.teams2,type="III")

# Still no effect of team size

# look at whether method used has an effect on RMSE
analysis.method <- lmer(root_mean_sqr_error~Method.coded.factor+(1|ResponseId), data = phase1_exp)
anova.teams <- car::Anova(analysis.teams,type="III")

# no effect of method used

```




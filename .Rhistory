means.compare.to.naive$Wave<-factor(means.compare.to.naive$Wave,levels=c("First Tournament","Second Tournament"))
#arrange groups
means.compare.to.naive$Type<-factor(means.compare.to.naive$Type,levels=c("Scientists","Naive Crowd","Historic Mean","Random Walk","Linear Regression"))
#add var for Scientists vs. rest (to define colors)
means.compare.to.naive$Group[means.compare.to.naive$Type=="Scientists"]<-"Estimate"
means.compare.to.naive$Group[means.compare.to.naive$Type!="Scientists"]<-"Non Estimate"
labeling<-c(
eafric = "Exp. Afr.-Am. Bias",
easian = "Exp. Asian-Am. Bias",
egend = "Exp. Gender Bias",
iafric = "Imp. Afr.-Am. Bias",
iasian = "Imp. Asian-Am. Bias",
ideoldem = "Democrat. Support",
ideolrep ="Republic. Support",
igend = "Imp. Gender Bias",
lifesat = "Life Satisfaction",
negaffect = "Negative Affect",
polar = "Polarization",
posaffect = "Positive Affect")
#plot
means.compare.to.naive %>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Inaccuracy - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
#subplots for presentation
#scientists
means.compare.to.naive %>%  subset(Type=="Scientists")%>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Inaccuracy - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
#scientists & lay crowd
means.compare.to.naive %>%  subset(Type=="Scientists"|Type=="Naive Crowd")%>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Inaccuracy - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
# Chunk 10
#to examine difference in inaccuracy from benchmark vs. domain estimates from scientists in the LME, we can do the following:
#1. create ratio of  benchmark inaccuracy to forecasting inaccuracy -  score above 1 means forecast is more accurate compared to the benchmark
#2 run an intercept model, to see if intercept is sig different from 1
##Tournament 1 - phase1_exp
phase1_exp_wbench<-phase1_exp %>% left_join(pivot_wider(sim.w1 %>% select(domain,response, source),
names_from="source",values_from="response"))
phase1_exp_wbench$MASE_ratio1<- phase1_exp_wbench$'Benchmark 1'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$MASE_ratio2<- phase1_exp_wbench$'Benchmark 2'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$MASE_ratio3<- phase1_exp_wbench$'Benchmark 3'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$domain <- factor(phase1_exp_wbench$domain,      # Reordering group factor levels
levels = c("ideolrep","ideoldem","polar",
"lifesat","negaffect","posaffect",
"iafric","iasian","igend",
"eafric","easian","egend" ))
#skewness test suggests that sqrt is the most reasonable transofmration across the three metrics (esp. the first one) hence we will use it.
(emmeans(lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
(emmeans(lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
(emmeans(lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
#get pvalues
test(emmeans(lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
test(emmeans(lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
test(emmeans(lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
model.phase1.hist.mean.ratio<-  lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.hist.mean.ratio, test.statistic = "F")
test(emmeans(model.phase1.hist.mean.ratio,~domain, type="response"))
plot.t1.hist.mean<-plot(emmeans(model.phase1.hist.mean.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Historical Mean")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="Tournament 1")
model.phase1.randwalk.ratio<-  lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.randwalk.ratio, test.statistic = "F")
test(emmeans(model.phase1.randwalk.ratio,~domain, type="response"))
plot.t1.randwalk<-plot(emmeans(model.phase1.randwalk.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Random Walk")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")
model.phase1.linreg.ratio<-  lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.linreg.ratio, test.statistic = "F")
test(emmeans(model.phase1.linreg.ratio,~domain, type="response"))
plot.t1.linreg<-plot(emmeans(model.phase1.linreg.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Linear Regression")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")
#Tournament 2
phase2_exp_wbench<-dat_phase2 %>% left_join(pivot_wider(sim.w2 %>% select(domain,response, source),
names_from="source",values_from="response"))
phase2_exp_wbench$domain <- factor(phase2_exp_wbench$domain,      # Reordering group factor levels
levels = c("ideolrep","ideoldem","polar",
"lifesat","negaffect","posaffect",
"iafric","iasian","igend",
"eafric","easian","egend" ))
phase2_exp_wbench$MASE_ratio1<- phase2_exp_wbench$'Benchmark 1'/phase2_exp_wbench$MASE1_w2
phase2_exp_wbench$MASE_ratio2<- phase2_exp_wbench$'Benchmark 2'/phase2_exp_wbench$MASE1_w2
phase2_exp_wbench$MASE_ratio3<- phase2_exp_wbench$'Benchmark 3'/phase2_exp_wbench$MASE1_w2
#here we use logs, because skewness suggests that sqrt is not enough and logs do a good job across all three markers
print(emmeans(lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
print(emmeans(lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
print(emmeans(lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
model.phase2.hist.mean.ratio<-  lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.hist.mean.ratio, test.statistic = "F")
test(emmeans(model.phase2.hist.mean.ratio,~domain, type="response"))
plot.t2.hist.mean<-plot(emmeans(model.phase2.hist.mean.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="Tournament 2")+theme(axis.text.y=element_blank())
model.phase2.randwalk.ratio<-  lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.randwalk.ratio, test.statistic = "F")
test(emmeans(model.phase2.randwalk.ratio,~domain, type="response"))
plot.t2.randwalk<-plot(emmeans(model.phase2.randwalk.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")+theme(axis.text.y=element_blank())
model.phase2.linreg.ratio<-  lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.linreg.ratio, test.statistic = "F")
test(emmeans(model.phase2.linreg.ratio,~domain, type="response"))
plot.t2.linreg<-plot(emmeans(model.phase2.linreg.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")+theme(axis.text.y=element_blank())
#combine all graphs
figsuppl1<-ggarrange(plot.t1.hist.mean,plot.t2.hist.mean,
plot.t1.randwalk,plot.t2.randwalk,
plot.t1.linreg, plot.t2.linreg,  ncol=2, nrow=3,widths=c(1.3,1))
# Chunk 11
#get ranking of median scores among academics in May and November
median.MASE.t1$Wave<-"First Tournament\nMay"
median.MASE.t2$Wave<-"Second Tournament\nNov"
median.ranks<-bind_rows(median.MASE.t1,median.MASE.t2)
median.ranks$MASE<-round(median.ranks$MASE_med,2) #two decimals
median.ranks$Domain[median.ranks$domain=="eafric"]<-"Exp. Afr.-Am. Bias"
median.ranks$Domain[median.ranks$domain=="easian"]<-"Exp. Asian-Am. Bias"
median.ranks$Domain[median.ranks$domain=="egend"]<-"Exp. Gender Bias"
median.ranks$Domain[median.ranks$domain=="iafric"]<-"Imp. Afr.-Am. Bias"
median.ranks$Domain[median.ranks$domain=="iasian"]<-"Imp. Asian-Am. Bias"
median.ranks$Domain[median.ranks$domain=="ideoldem"]<-"Democrat. Support"
median.ranks$Domain[median.ranks$domain=="ideolrep"]<-"Republic. Support"
median.ranks$Domain[median.ranks$domain=="igend"]<-"Imp. Gender Bias"
median.ranks$Domain[median.ranks$domain=="lifesat"]<-"Life Satisfaction"
median.ranks$Domain[median.ranks$domain=="polar"]<-"Polarization"
median.ranks$Domain[median.ranks$domain=="negaffect"]<-"Negative Affect"
median.ranks$Domain[median.ranks$domain=="posaffect"]<-"Positive Affect"
newggslopegraph(dataframe = median.ranks,
Times = Wave,
Measurement = MASE,
Grouping = Domain,
WiderLabels=T,
Title = "Which domains are harder to predict?",
SubTitle = "higher scores - more inaccurate",
Caption = "Ranking based on median MASE scores per domain",
ThemeChoice="tufte")+scale_color_d3(palette = "category20")
# Chunk 12: ranking in phase 1 and complexity
#For complexity,we used permutation_entropy, which is Ra substitution the Shannon entropy with a monoparametric entropy.
rank_complex_w1<-median.MASE.t1%>%left_join(complexity)
rank_complex_w2<-median.MASE.t2%>%left_join(complexity)
correlation::correlation(rank_complex_w1%>%
select(MASE_med,sd_hist_w1,mad_hist_w1,perp_entropy_hist_w1,sd_w1,mad_w1,perp_entropy_w1), p_adjust="none", ranktransform=T)
correlation::correlation(rank_complex_w2%>%
select(MASE_med,sd_hist_w2,mad_hist_w2,perp_entropy_hist_w2,sd_w2,mad_w2,perp_entropy_w2), p_adjust="none", ranktransform=T)
# Chunk 13
#analyses of phase 1  - MASE overall
#For models evaluating overall accuracy of the forecasted model, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain as predictors, with MASE scores nested within teams.
#first, what is the percentage using different method?
prop.table(table(phase1_exp$Method.code))
perc.by.domain.phase1<-phase1_exp %>%
group_by(domain,Method.code) %>%
summarise(n = n()) %>%
mutate(perc = round(n / sum(n)*100),2) %>%
ggplot(aes(x = "", y = perc, fill = Method.code)) +
geom_col(color = "black") +
geom_label(aes(label = perc),
color = "white",
position = position_stack(vjust = 0.5),
show.legend = FALSE) +scale_fill_jama()+labs(fill="")+
coord_polar(theta = "y")+theme_void()+facet_wrap(~domain, nrow = 4, labeller=labeller(domain=labels))+theme(legend.position="bottom")
#recorder levels of the domains
dat_long$domain <- factor(dat_long$domain,      # Reordering group factor levels
levels = c("egend","easian","eafric",
"igend","iasian","iafric",
"posaffect","negaffect","lifesat",
"polar","ideoldem","ideolrep"))
#next run models
model.phase1<-  lmer(log(MASE1_w1)~domain*Method.code+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1,type="III") #sig interaction!
summ(model.phase1, digits=4)
emmeans(model.phase1,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")
data.phase1.MASE<-as.data.frame(emmeans(model.phase1,pairwise ~Method.code|domain, type = "response", adjust = "none")$emmeans)
model.phase1.across.domains<-  lmer(log(MASE1_w1)~Method.code+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1.across.domains,type="III") #sig interaction!
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)
model.phase1.contrast<-  lmer(log(MASE1_w1)~method.contrast+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast,type="III") #sig domain effect,  and sig interaction
summ(model.phase1.contrast, digits=4) #get effect size for the overall model
model.phase1.contrast.by.domain<-  lmer(log(MASE1_w1)~method.contrast*domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast.by.domain, type=3)
emmeans(model.phase1.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
write.csv(emmeans(model.phase1.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
$contrasts,"contrast1.csv")
# EXAMINE ACADEMICS DATA VS. NO DATA AND LAY PEOPLE
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1$method.contrast.layppl[phase1$Method.code=='Intuition/Theory']<-"Sci data-free"
phase1$method.contrast.layppl[phase1$Method.code=='Lay People']<-"lay people"
phase1$method.contrast.layppl[phase1$Method.code=='Data-Driven']<-"Sci data-incl."
phase1$method.contrast.layppl[phase1$Method.code=='Hybrid']<-"Sci data-incl."
model.phase1.contrast.lay<-  lmer(log(MASE1_w1)~method.contrast.layppl+(1|ResponseId), data=phase1)
car::Anova(model.phase1.contrast.lay,type="III") #sig domain effect,  and sig interaction
emmeans(model.phase1.contrast.lay,specs = trt.vs.ctrl ~method.contrast.layppl, adjust = "fdr",type="response" )
#arrange in descending order based on MASE w2 of academics
data.phase1.MASE$domain<-factor(data.phase1.MASE$domain,levels=c("ideolrep","negaffect","ideoldem","polar","iafric","lifesat","eafric","easian","egend","iasian","igend","posaffect"))
data.phase1.MASE %>%
ggplot(aes(x = domain, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase1.MASE.total %>%
ggplot(aes(x = Method.code, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
#phase 2
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
#first, what is the percentage using different method?
prop.table(table(dat_phase2$Method.code))
table(phase2$Method.code)
perc.by.domain.phase2<-dat_phase2 %>%
group_by(domain,Method.code) %>%
summarise(n = n()) %>%
mutate(perc = round(n / sum(n)*100),2) %>%
ggplot(aes(x = "", y = perc, fill = Method.code)) +
geom_col(color = "black") +
geom_label(aes(label = perc),
color = "white",
position = position_stack(vjust = 0.5),
show.legend = FALSE) +scale_fill_jama()+labs(fill="")+
coord_polar(theta = "y")+theme_void()+facet_wrap(~domain, nrow = 4, labeller=labeller(domain=labels))+theme(legend.position="bottom")
#combine plots
cowplot::plot_grid(perc.by.domain.phase1,perc.by.domain.phase2,labels=c("1st Tournament","2nd Tournament"), label_size = 10,
align = "v")
#next run models
data.phase2.model<-  lmer(log(MASE1_w2)~domain*Method.code+(1|ResponseId), data=dat_phase2)
car::Anova(data.phase2.model,type="III") #sig interaction!
data.phase2.MASE<-as.data.frame(emmeans(data.phase2.model, pairwise~Method.code|domain, adjust = "none", type = "response")$emmeans) #backtransformed to the original scale
data.phase2.model.across.domains<-  lmer(log(MASE1_w2)~Method.code+(1|ResponseId), data=dat_phase2)
car::Anova(data.phase2.model.across.domains,type="III") #sig interaction!
data.phase2.MASE.total<-as.data.frame(emmeans(data.phase2.model.across.domains,pairwise ~Method.code, type = "response", adjust = "none")$emmeans)
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
dat_phase2$method.contrast<-ifelse(dat_phase2$Method.code=='Intuition/Theory',0,1)
model.phase2.contrast<-  lmer(log(MASE1_w2)~method.contrast+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast,type="III") #sig domain effect,  and sig interaction
summ(model.phase2.contrast, digits=4) #get effect size for the overall model
model.phase2.contrast.by.domain<-  lmer(log(MASE1_w2)~method.contrast*domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast.by.domain, type=3)
emmeans(model.phase2.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
write.csv(emmeans(model.phase2.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "none",type="response" )
$contrasts,"contrast2.csv")
data.phase1.MASE.total<-as.data.frame(emmeans(model.phase1.across.domains,pairwise ~Method.code, type = "response", adjust = "none")$emmeans)
#arrange in descending order based on MASE w2 of academics
data.phase2.MASE.total$domain<-factor(data.phase2.MASE.total$domain,levels=c("ideolrep","negaffect","ideoldem","polar","iafric","lifesat","eafric","easian","egend","iasian","igend","posaffect"))
data.phase2.MASE %>%
ggplot(aes(x = domain, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase2.MASE.total %>%
ggplot(aes(x = Method.code, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase1.MASE.total$Wave<-"First Tournament"
data.phase2.MASE.total$Wave<-"Second Tournament"
#combine
means.compare.by.method<-bind_rows(data.phase1.MASE.total,data.phase2.MASE.total)
means.compare.by.method$Method[means.compare.by.method$Method.code=="Data-Driven"&
means.compare.by.method$Wave=="First Tournament"]<-"Data-Driven/n51%"
#arrange in descending order based on MASE w2 of academics
means.compare.by.method$Wave<-factor(means.compare.by.method$Wave,levels=c("First Tournament","Second Tournament"))
means.compare.by.method$Method<-c('Data-Driven\n51%','Hybrid\n7%','Intuition/Theory\n42%','Data-Driven\n53%','Hybrid\n8%','Intuition/Theory\n39%')
means.compare.by.method %>%
ggplot(aes(x = Method, y = response, color = Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_hline(yintercept =1, linetype='dashed', color='red',14)+theme(legend.position="none")+scale_color_futurama()+  labs(y="Inaccuracy - MASE (M +/- 95%CI)",x="",shape="",color="")+ facet_wrap(~ Wave, scales = "free_x")
# Chunk 14
#count how many domains per person
phase1_exp<-phase1_exp %>%group_by(team_name) %>%  mutate(n_domains = n())
phase1_exp$Domain_Publications<-ifelse(phase1_exp$pub==1,1,ifelse(phase1_exp$pub==2,0,NA))
#count how many domains per person
dat_phase2<-dat_phase2 %>%group_by(team_name) %>%  mutate(n_domains = n())
dat_phase2$Domain_Publications<-ifelse(dat_phase2$pub==1,1,ifelse(dat_phase2$pub==2,0,NA))
subset1<- phase1_exp %>% ungroup() %>% select(MASE1_w1,domain,Method.code,ResponseId,team_name,covidcondyn,CounterFactual_Presence_Final,Method.complex,parameters_coded,n_domains,multi_dis.factor,team_discipline.coded,team_size.coded,team_gender,team_education,confidence,subexpert,Domain_Publications,previous_tournament.coded,TournamentStart) %>% mutate(inaccuracy = MASE1_w1,phase = "first")
subset2<- dat_phase2 %>% ungroup() %>% select(MASE1_w2,domain,Method.code,ResponseId,team_name,covidcondyn,CounterFactual_Presence_Final,Method.complex,parameters_coded,n_domains,multi_dis.factor,team_discipline.coded,team_size.coded,team_gender,team_education,confidence,subexpert,Domain_Publications,previous_tournament.coded,TournamentStart) %>% mutate(inaccuracy = MASE1_w2,phase = "second")
#combine
both.sets<-bind_rows(subset1,subset2)
both.sets$covidconditional<-ifelse(both.sets$covidcondyn==1,1,0)
both.sets$covidconditional[is.na(both.sets$covidconditional)]<-0
both.sets$Method.complex[is.na(both.sets$Method.complex)]<-1 #simple when no extra info is provided, because the rest {number of parameters et.) suggests no extra factors considered}
both.sets$multi_dis.factor[is.na(both.sets$multi_dis.factor)]<-"Single domain expertise" #(setting is NA to non multidisciplinary)
both.sets$team_discipline.coded[is.na(both.sets$team_discipline.coded)]<-5 #(setting is NA to other)
both.sets$team_discipline.datasci<-ifelse(both.sets$team_discipline.coded==3,1,0)
both.sets$team_discipline.SBsci<-ifelse(both.sets$team_discipline.coded==1,1,ifelse(both.sets$team_discipline.coded==2,1,0))
#analyze comparison of tournament 1 to tournament 2
both.sets.model<-  lmer(log(inaccuracy)~phase+(1|team_name), data=both.sets)
car::Anova(both.sets.model,type="III", test.statistic="F") #sig effect
emmeans(both.sets.model,~phase, type="response")
both.sets.model.cov<-  lmer(log(inaccuracy)~phase+domain+
n_domains+team_discipline.datasci+team_discipline.SBsci+multi_dis.factor+team_size.coded+team_gender+team_education+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(both.sets.model.cov,type="III", test.statistic="F") #sig effect
emmeans(both.sets.model.cov,~phase, type="response")
both.sets.domain.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=both.sets)
car::Anova(both.sets.domain.model,type="III", test.statistic="F") #sig effect
emmeans(both.sets.domain.model,pairwise~domain, type="response")
subset1.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=subset1)
car::Anova(subset1.model,type="III", test.statistic="F") #sig effect
emmeans(subset1.model,~domain, type="response")
subset2.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=subset2)
car::Anova(subset2.model,type="III", test.statistic="F") #sig effect
emmeans(subset2.model,~domain, type="response")
#next run models
model.phase1<-  lmer(log(MASE1_w1)~domain*Method.code+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1,type="III") #sig interaction!
model.phase1.across.domains<-  lmer(log(MASE1_w1)~Method.code+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1.across.domains,type="III") #sig interaction!
model.phase1.across.domains<-  lmer(log(MASE1_w1)~Method.code+domain+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1.across.domains,type="III") #sig interaction!
car::Anova(model.phase1.across.domains,type="III", test.statistic="F")
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
data.phase2.model.across.domains<-  lmer(log(MASE1_w2)~Method.code+domain+(1|ResponseId), data=dat_phase2)
car::Anova(data.phase2.model.across.domains,type="III", test.statistic="F") #sig interaction!
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)
model.phase1.contrast<-  lmer(log(MASE1_w1)~method.contrast+domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast,type="III", test.statistic="F") #sig domain effect,  and sig interaction
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
dat_phase2$method.contrast<-ifelse(dat_phase2$Method.code=='Intuition/Theory',0,1)
model.phase2.contrast<-  lmer(log(MASE1_w2)~method.contrast+domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast,type="III", test.statistic="F") #sig domain effect,  and sig interaction
car::Anova(model.phase2.contrast.by.domain, type=3, test.statistic="F")
car::Anova(model.phase1.contrast.by.domain, type=3, test.statistic="F")
emmeans(model.phase1.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
both.sets$inaccuracy_log<-log(both.sets$inaccuracy)
both.sets$Multidisciplinary<-ifelse(both.sets$multi_dis.factor=="Single domain expertise",0,1)
both.sets$covidconditional[is.na(both.sets$covidconditional)]<-0
both.sets$Method.complex[is.na(both.sets$Method.complex)]<-1 #simple when no extra info is provided, because the rest {number of parameters et.) suggests no extra factors considered}
both.sets$multi_dis.factor[is.na(both.sets$multi_dis.factor)]<-"Single domain expertise" #(setting is NA to non multidisciplinary)
###analyses
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_gender+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets, REML=F)
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T, robust = "HC1")
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_gender+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T, robust = "HC1")
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
plot.COV<-plot_summs(model.bothTournaments.COVs, scale = TRUE, robust = "HC1",n.sd = 2, inner_ci_level = .9,
coefs = c("Statistical Model Complexity" = "Method.complex","N Model Parameters" = "parameters_coded",
"Considered COVID-19" = "covidconditional",
"Considered Counterfactuals"="CounterFactual_Presence_Final",
"Number of Predicted Domains"="n_domains",
"Data Scientists on the Team"="team_discipline.datasci",
"Behav./Soc. Scientists on the Team"="team_discipline.SBsci",
"Multidisciplinary"="Multidisciplinary",
"Team Size"="team_size.coded",
"% non-Male on the Team"="team_gender",
"% without PhD on the Team"="team_education",
"Confidence in Forecast"="confidence",
"Self-report Expertise"="subexpert",
"Team Members Topic Publications"="Domain_Publications",
"Prev. Exp. with\nForecasting Tournaments"="previous_tournament.coded"))
plot.COV$data<-plot.COV$data %>% arrange(estimate) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
mutate(term=factor(term, levels=term))
plot.COV+labs(x="Contribution to Inaccuracy")
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
sqrt(0.314)
partr2.COV<-partR2(model.bothTournaments.COVs,  data=both.sets,
R2_type = "marginal", nboot = 10, CI = 0.95)
summary(partr2.COV) #obtain effect sizes scores for unique predictors (incremental R2)
both.sets$inaccuracy_res<-lmer(inaccuracy_log~domain+(1|team_name), data=both.sets)$resid
model.bothTournaments.COVs$resid
model.bothTournaments.COVs
name(model.bothTournaments.COVs)
both.sets$inaccuracy_res<-resid(lmer(inaccuracy_log~domain+(1|team_name), data=both.sets))
hist(both.sets$inaccuracy_res)
model.bothTournaments.COVs<-lmer(both.sets$inaccuracy_res~parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
model.bothTournaments.COVs<-lmer(inaccuracy_res~parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
model.bothTournaments.COVs<-lmer(inaccuracy_log~parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
plot.COV<-plot_summs(model.bothTournaments.COVs, scale = TRUE, robust = "HC1",n.sd = 2, inner_ci_level = .9,
coefs = c("Statistical Model Complexity" = "Method.complex","N Model Parameters" = "parameters_coded",
"Considered COVID-19" = "covidconditional",
"Considered Counterfactuals"="CounterFactual_Presence_Final",
"Number of Predicted Domains"="n_domains",
"Data Scientists on the Team"="team_discipline.datasci",
"Behav./Soc. Scientists on the Team"="team_discipline.SBsci",
"Multidisciplinary"="Multidisciplinary",
"Team Size"="team_size.coded",
"% without PhD on the Team"="team_education",
"Confidence in Forecast"="confidence",
"Self-report Expertise"="subexpert",
"Team Members Topic Publications"="Domain_Publications",
"Prev. Exp. with\nForecasting Tournaments"="previous_tournament.coded"))
plot.COV$data<-plot.COV$data %>% arrange(estimate) %>%    # First sort by val. This sort the dataframe but NOT the factor levels
mutate(term=factor(term, levels=term))
plot.COV+labs(x="Contribution to Inaccuracy")
export_summs(model.bothTournaments.COVs, scale = TRUE, robust = "HC1",n.sd = 2, to.file = "docx")
export_summs(model.bothTournaments.COVs, scale = TRUE, robust = "HC1",n.sd = 2)
export_summs(model.bothTournaments.COVs, scale = F, robust = "HC1")
partr2.COV<-partR2(model.bothTournaments.COVs,  data=both.sets,
R2_type = "marginal", nboot = 10, CI = 0.95)
summary(partr2.COV) #obtain effect sizes scores for unique predictors (incremental R2)
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
table(both.sets$team_size.coded)
pd <- position_dodge(0.7) # move them .07 to the left and right
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
dat_phase2$Method.code <- relevel(factor(dat_phase2$Method.code), "Intuition/Theory") #use lay people as a reference group
dat_phase2$method.contrast<-ifelse(dat_phase2$Method.code=='Intuition/Theory',0,1)
dat_phase2$compare_to_naive_rwf_MASE2.update<-ifelse(dat_phase2$compare_to_naive_rwf_MASE_w2!="Equal to Naive rwf",dat_phase2$compare_to_naive_rwf_MASE_w2,ifelse(dat_phase2$compare_to_naive_rwf_MASE_w2=="Equal to Naive rwf","Below Naive rwf",NA))
dat_phase2$compare_to_naive_linear_MASE2.update<-ifelse(dat_phase2$compare_to_naive_linear_MASE_w2!="Equal to Naive linear",dat_phase2$compare_to_naive_linear_MASE_w2,ifelse(dat_phase2$compare_to_naive_linear_MASE_w2=="Equal to Naive linear","Below Naive linear",NA))
dat_phase2$Group[dat_phase2$TournamentStart=="May"&dat_phase2$revised == 0]<-"Original May"
dat_phase2$Group[dat_phase2$TournamentStart=="November"&dat_phase2$revised == 0]<-"Original November"
dat_phase2$Group[dat_phase2$TournamentStart=="May"&dat_phase2$revised == 1]<-"Updated May"
dat_phase2$teamS<-as.factor(ifelse(dat_phase2$team_size.coded>=6,3,ifelse(dat_phase2$team_size.coded<6&dat_phase2$team_size.coded>1,2,ifelse(dat_phase2$team_size.coded==1,1,NA))))
dat_phase2$is_multidisciplinary<-ifelse(dat_phase2$discipline=="Multi-disciplinary",1,0)
dat_phase2$objectivexpert<-ifelse(dat_phase2$pub==1,"Expert",ifelse(dat_phase2$pub==2,"Non Expert",NA))
dat_phase2$covidconditional<-ifelse(dat_phase2$covidcondyn==0,"No",ifelse(dat_phase2$covidcondyn==1,"Yes",NA))
#add historical variability data (as extra variable)
dat_phase2<-dat_phase2 %>% left_join(complexity)
#count how many domains per person
dat_phase2<-dat_phase2 %>%group_by(team_name) %>%
mutate(n_domains = n())
## EXAMINE EFFECTS OF new teams at phase 2 vs. OG teams who updated their forecasts: Just ACADEMICS
##revised  - Indicates whether or not the team has a matching submission in both phase 1 & 2 for the same domain
model.phase2.update<-  lmer(log(MASE1_w2)~Group+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.update,type="III") #sig difference between May and Nov, but not between original may and original Nov
summ(model.phase2.update)
emmeans(model.phase2.update,pairwise ~Group, adjust = "none") #nonsig
table(dat_phase2$revised)
table(phase1_exp$revised)
table(phase1_exp$revised,phase1_exp$domain)
179+180
prop.table(table(phase1_exp$revised,phase1_exp$domain))
prop.table(table(phase1_exp$revised,phase1_exp$domain),margin=phase1_exp$domain)
proportions(table(phase1_exp$revised,phase1_exp$domain)
)
proportions(table(phase1_exp$revised),margin =phase1_exp$domain)
proportions(table(phase1_exp$revised,phase1_exp$domain),margin=2)
names(phase1_exp)
phase1_exp$team_Age
phase1_exp$Age
psych::describe(phase1_exp$team_Age)
psych::describe(phase1_exp$team_education)
phase1_exp$team_size.coded
#total percentage in the tournament without a PhD
##multiple % per team without a PhD by number of team members
sum(phase1_exp$team_education*phase1_exp$team_size.coded)
#total percentage in the tournament without a PhD
##multiple % per team without a PhD by number of team members
sum(phase1_exp$team_education/100*phase1_exp$team_size.coded)
#total percentage in the tournament without a PhD
##multiple % per team without a PhD by number of team members
sum(phase1_exp$team_education/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded)
sum(phase1_exp$team_size.coded)
#total percentage in the tournament without a PhD
##multiple % per team without a PhD by number of team members and subtract from 1 and multiple by 100 to get % of forecasts done by PhDs
(1 - sum(phase1_exp$team_education/100*phase1_exp$team_size.coded)/sum(phase1_exp$team_size.coded))*100
#forecasted domains
psych::describe(phase1_exp$n_domains)
psych::describe(dat_phase2$n_domains)
180/356
#did preference for updating vary by method?
model.revised.t1.by.method<-glmer(revised~method.contrast+(1|team_name), data=phase1_exp, family=binomial)
car::Anova(model.revised.t1.by.method,type="III",test.statistic="F")
summ(model.revised.t1.by.method, conf.method="boot", digits=3, center=T)
psych::describe(dat_phase2$team_Age)
(1 - sum(dat_phase2$team_education/100*dat_phase2$team_size.coded)/sum(dat_phase2$team_size.coded))*100
psych::describe(dat_phase2$n_domains)
##supplementary  - examine COVID score inaccuracy as predictor - does inaccuracy in predictions depend on COVID-inaccuracy?
#IMPORTANT: only done in Phase 1
model.t1.COVID<-lmer(inaccuracy_log~domain+MASE1_covid+(1|team_name), data=subset1)
##supplementary  - examine COVID score inaccuracy as predictor - does inaccuracy in predictions depend on COVID-inaccuracy?
#IMPORTANT: only done in Phase 1
model.t1.COVID<-lmer(log(inaccuracy)~domain+MASE1_covid+(1|team_name), data=subset1)
##supplementary  - examine COVID score inaccuracy as predictor - does inaccuracy in predictions depend on COVID-inaccuracy?
#IMPORTANT: only done in Phase 1
model.t1.COVID<-lmer(log(MASE1_w1)~domain+MASE1_covid+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID,type="III",test.statistic="F")
summ(model.t1.COVID, conf.method="boot", digits=3, center=T)
##supplementary  - examine COVID score inaccuracy as predictor - does inaccuracy in predictions depend on COVID-inaccuracy?
#IMPORTANT: only done in Phase 1
model.t1.COVID<-lmer(log(MASE1_w1)~domain+log(MASE1_covid)+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID,type="III",test.statistic="F")
##supplementary  - examine COVID score inaccuracy as predictor - does inaccuracy in predictions depend on COVID-inaccuracy?
#IMPORTANT: only done in Phase 1
phase1_exp$inaccuracy_log<-log(phase1_exp$MASE1_w1)
model.t1.COVID<-lmer(inaccuracy_log~domain+log(MASE1_covid)+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID,type="III",test.statistic="F")
summ(model.t1.COVID, conf.method="boot", digits=3, center=T)
phase1_exp$covidcondyn
#examine if COVID conditional inversely predicts MASE based on COVID MASE
model.t1.COVID.cond<-lmer(inaccuracy_log~domain+as.factor(covidcondyn)*log(MASE1_covid)+(1|team_name), data=phase1_exp)
#examine if COVID conditional inversely predicts MASE based on COVID MASE
model.t1.COVID.cond<-lmer(inaccuracy_log~domain+covidcondyn*log(MASE1_covid)+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID.cond,type="III",test.statistic="F")
#examine if COVID conditional inversely predicts MASE based on COVID MASE
phase1_exp$covidconditional<-ifelse(phase1_exp$covidcondyn==1,1,0)
phase1_exp$covidconditional[is.na(phase1_exp$covidconditional)]<-0
model.t1.COVID.cond<-lmer(inaccuracy_log~domain+covidconditional*log(MASE1_covid)+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID.cond,type="III",test.statistic="F")
summ(model.t1.COVID, conf.method="boot", digits=3, center=T) #no significant effect of COVID predicion in accuracy on MASE in accuracy
phase1_exp$covid.conX<-ifelse(phase1_exp$covidconditional=0,0,phase1_exp$MASE1_covid)
phase1_exp$covid.conX<-ifelse(phase1_exp$covidconditional==0,0,phase1_exp$MASE1_covid)
model.t1.COVID.cond<-lmer(inaccuracy_log~domain+covid.conX+(1|team_name), data=phase1_exp)
car::Anova(model.t1.COVID.cond,type="III",test.statistic="F")
summ(model.t1.COVID, conf.method="boot", digits=3, center=T) #no significant effect of COVID prediction in accuracy on MASE in accuracy
#theory vs. intuition in each phase
table(phase1_exp$Method.code)
#theory vs. intuition in each phase
table(phase1_exp$Method.coded)
#theory vs. intuition in each phase
table(phase1_exp$Method)
#theory vs. intuition in each phase
table(phase1_exp$Method.code)
#theory vs. intuition in each phase
table(phase1_exp$Method.coded)
#theory vs. intuition in each phase
table(phase1_exp$basis)

# Visualize percentage of females in each team for top 10 teams by domain for academics only
phase1 %>%
filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>%                                                                           dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US ) %>%
ggplot(aes(x = domain, y = team_gender)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")
# Visualize education for top 10 teams by domain for academics only
phase1 %>%
filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US ) %>%
ggplot(aes(x = domain, y = team_education)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y=" (M +/- 95%CI)")
# Visualize team age for top 10 teams by domain for academics only
phase1 %>%
filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>%
dplyr::slice_head(n = 10) %>%                                                                           dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US ) %>%
ggplot(aes(x = domain, y = team_Age)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")
# Visualize percentage of non-us team members for 10 teams by domain for academics only
phase1 %>%
filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>%
dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = non_US)) +
stat_summary(fun.data="mean_cl_boot", position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")
## comparison to lay people
## Compare performance to naive RW between academics and lay people across domains.
proportions(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
## Compare performance to naive RW between academics and lay people across domains using chi squared test
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1))
## Compare performance to naive RW by method across domains using chi squared test
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation
## Compare performance to naive linear between academics and lay people across domains
proportions(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
## Compare performance to naive linear between academics and lay people across domains using chi square test.
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1))
## Comparison by method among academics
## Compare performance against Naive RW by method
proportions(xtabs( ~ compare_to_naive_rwf_MASE+Method.code, phase1), "Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1))
#chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))
## Compare performance against Naive RW by method - just for academics
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1_exp))
#chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1_exp, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))
# Compare performance against Naive linear by method
proportions(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1),"Method.code")*100 #
# Compare performance against Naive linear by method using chi square
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1))
# Compare performance against Naive linear by method using chi square just academics
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1_exp)) #just comparison of academics
##PHASE 2
#who won? - identify top performers for each domain using MASE scores in phase 2.
top.1.MASE.t2 <- academic_only  %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain, MASE1_w2) %>%
group_by(team_name) %>%  mutate(n_domains = n()) %>%
group_by(domain) %>%
dplyr::slice_head(n = 1) %>%                                                  dplyr::select(domain,mean_abs_error_w2,n_domains,MASE1_w2,team_name,mean_abs_percent_error_w2,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
# write.csv(top.1.MASE.t2,"top.t2.csv")
#median MASE by domain? - compute median accuracy by domain for phase 2.
median.MASE.t2 <- academic_only  %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain) %>%
group_by(domain) %>%
dplyr::summarize(MASE_med = median(MASE1_w2)) %>%
dplyr::select(domain,MASE_med) %>%
arrange(MASE_med)
#write.csv(median.MASE.t2,"medianMASE.t2.csv")
#examine top 5 - top 5 performers by domain using MASE scores for academics in phase 2.
top.5.MASE.t2 <- academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(team_name) %>%  mutate(n_domains = n()) %>%
group_by(domain) %>%
dplyr::slice_head(n = 5) %>% dplyr::select(team_name,MASE1_w2,domain,n_domains,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
# Visualize top 5 performers as a function of method used.
#### Fig. S8. in manuscript
top.5.MASE.t2 %>%
ggplot(aes(x=domain, y=MASE1_w2, colour=Method.code)) +
geom_point(size=3, position=pd, alpha = .5) +
scale_x_discrete(labels=labels, name="") +
geom_hline(yintercept =1, linetype='dashed', color='red', 14) +                                         theme(legend.position="top") +
scale_colour_aaas(name="Approach") +
ylab("MASE")
# proportion of different methods used across the top 5 performance across all domains.
proportions(xtabs( ~ Method.code,top.5.MASE.t2))*100 #in total
# proportion of different methods used across the top 5 performance by domain
proportions(xtabs( ~ domain+Method.code,top.5.MASE.t2),"domain")*100 #by domain
# Top 5 Performance compared against naive linear and random walk by domain.
#### Fig. S9. in manuscript
top.5.MASE.t2 %>%
ggplot(aes(x=domain, y=MASE1_w2, colour=compare_to_naive_linear_MASE_w2, shape =compare_to_naive_rwf_MASE )) +
geom_point(size=3, position=pd, alpha = .5) +
scale_x_discrete(labels=labels, name="") +
geom_hline(yintercept =1, linetype='dashed', color='red', 14) +                                         theme(legend.position="top")+
scale_colour_d3(name="Compared to\nLinear Model") +
scale_shape_discrete(name="Compared to\nRandom Walk") +
ylab("MASE")
# Top 5 Performance by discipline and domain.
#### Fig. S10. in manuscript
top.5.MASE.t2 %>%
ggplot(aes(x=domain, y=MASE1_w2, colour=discipline)) +
geom_point(size=3, position=pd, alpha = .5) +
scale_x_discrete(labels=labels, name="") +
geom_hline(yintercept =1, linetype='dashed', color='red', 14) +                                         theme(legend.position="top") +
scale_colour_d3(name="Field") +
ylab("MASE")
# Proportion of top 5 performers by discipline across all domains
proportions(xtabs( ~ discipline,top.5.MASE.t2))*100 #in total
# Proportion of top 5 performers by discipline and domain
proportions(xtabs( ~ domain+discipline,top.5.MASE.t2),"domain")*100 #by domain
# Performance of top 5 by prior forecasting experience and domain.
#### Fig. S11. in manuscript
top.5.MASE.t2  %>%
ggplot(aes(x=domain, y=MASE1_w2, colour=as.factor(previous_tournament.coded))) +
geom_point(size=3, position=pd, alpha = .5) +
scale_x_discrete(labels=labels, name="") +
geom_hline(yintercept =1, linetype='dashed', color='red', 14) +                                         theme(legend.position="top") +
scale_colour_d3(name="Prior Forecasting Experience") +
ylab("MASE")
# Proportion of top 5 who had previous tournament experience across all domains
proportions(xtabs( ~ previous_tournament.coded,top.5.MASE.t2))*100 #in total
# Proportion of top 5 who had previous tournament experience - academics only
proportions(xtabs( ~ previous_tournament.coded,academic_only%>% filter(!(phase == 1 & revised == 1))))*100 #baserate of prior experience to compare to top 5
# Proportion of top 5 who had previous tournament experience by domain
proportions(xtabs( ~ domain+previous_tournament.coded,top.5.MASE.t2),"domain")*100 #by domain
# Size of top ten teams by domain
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise) %>%
ggplot(aes(x = domain, y = team_size.coded)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="Size of Top 10 Teams (M +/- 95%CI)")
# Top 10 teams model complexity by domain.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise) %>%
ggplot(aes(x = domain, y = Method.complex)) +
stat_summary(fun.data="mean_cl_boot", position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)")
# Top 5 teams model complexity by domain.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 5) %>% dplyr::select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise) %>%
ggplot(aes(x = domain, y = Method.complex)) +
stat_summary(fun.data="mean_cl_boot",  position=pd) +
theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)") #same as for top 10
# %of females per top 10 winning teams by domain.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_gender)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")
# % of non-Phds per team.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_education)) +
stat_summary(fun.data="mean_cl_boot", position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="% Non_PHD per Team (M +/- 95%CI)")
# Average team age for top 10 teams by domain.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>%   dplyr::select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_Age)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="") +
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")
# % of non us individuals on top 10 teams by domain.
academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%
group_by(domain) %>%
dplyr::slice_head(n = 10) %>% dplyr::select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US) %>%
ggplot(aes(x = domain, y = non_US)) +
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +
scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")
## Comparison by method among academics
# Percentage of academics who performed above, below, or just as well as naive rwf by method type across all domains.
proportions(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,academic_only %>%
filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
# Chi square test of the proportions above while also dropping equal to.
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,subset(academic_only%>% filter(!(phase == 1 & revised == 1)), compare_to_naive_rwf_MASE_w2!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation
# Percentage of academics who performed above, below, or just as well as naive linear by method type across all domains
proportions(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
# Chi square test of proportions above.
chisq.test(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))))
#examine if top 5 in T1 are also among top 5 in t2
top.5.MASE.t1$phase<-"T1"
top.5.MASE.t1$MASE<-top.5.MASE.t1$MASE1_w1
top.5.MASE.t2$phase<-"T2"
top.5.MASE.t2$MASE<-top.5.MASE.t2$MASE1_w2
top.5.MASE<-rbind(top.5.MASE.t1,top.5.MASE.t2)
top.5.MASE%>% dplyr::select(team_name,MASE,domain,phase,model,revised) %>% group_by(domain) %>% count(team_name)
#only in five out of 12 domains one top team from the first tournament appeared among the top five teams of a given domain in the second tournament:
#Compassionate Values for Explicit African American bias; fearfulastra for Explicit Gender-Career bias; FMTeam for Implicit Asian American bias; AbCdEfG for Ideological Support of Democrats; A Woman Scientist for Negative Sentiment; NYHC for political polarization. The remaining top five teams were unique across tournaments.
#examine consistency across domains in each tournament
top5.repeats.t1<-top.5.MASE.t1%>% dplyr::select(team_name,MASE,domain,n_domains) %>% group_by(team_name) %>% count(team_name) %>% arrange(desc(n))
psych::describe(top5.repeats.t1)#14 appear more than once; but M is small = 1.62
top5.repeats.t1.perc<-top5.repeats.t1 %>% left_join(top.5.MASE.t1 %>% dplyr::select(team_name,n_domains) )
top5.repeats.t1.perc$perc<-top5.repeats.t1.perc$n/top5.repeats.t1.perc$n_domains*100
print(top5.repeats.t1.perc) # one team among those who were among the top five in more than 2 domains had a reasonably small number of domains they made predictions about (6), such that in 4 out of 6 = 67% they were in the top five. For the rest, the number of domains they were in the top five were below half of those they made predictions for.
top5.repeats.t2<-top.5.MASE.t2%>% dplyr::select(team_name,MASE,domain,n_domains) %>% group_by(team_name) %>% count(team_name) %>% arrange(desc(n))
psych::describe(top5.repeats.t2)#17 appear more than once; but M is small = 1.67
top5.repeats.t2.perc<-top5.repeats.t2 %>% left_join(top.5.MASE.t2 %>% dplyr::select(team_name,n_domains) )
top5.repeats.t2.perc$perc<-top5.repeats.t2.perc$n/top5.repeats.t2.perc$n_domains*100
print(top5.repeats.t2.perc) # one team among those who were among the top five in more than 2 domains had a reasonably small number of domains they made predictions about (9), such that in 5 out of 9 = 55.56% they were in the top five. For the rest, the number of domains they were in the top five were at/below half of those they made predictions for.
View(phase1)
View(results)
View(t1.academ.sorted)
?sd
# Examine St error across 12 months
t1.academ.sorted %>% mutate(stdeviation = sd(May2020:April2021))
warnings()
# Examine St error across 12 months
t1.academ.sorted %>% mutate(stdeviation = sd(as.numeric(May2020:April2021)))
# Examine St error across 12 months
t1.academ.sorted  %>% mutate_at(May2020:April2021, as.numeric) %>% mutate(stdeviation = sd(May2020:April2021))
# Examine St error across 12 months
t1.academ.sorted  %>% mutate_at("May2020":"April2021", as.numeric) %>% mutate(stdeviation = sd(May2020:April2021))
# Examine St error across 12 months
t1.academ.sorted  %>% mutate_if(is.double, as.numeric) %>% mutate(stdeviation = sd(May2020:April2021))
# Examine St error across 12 months
t1.academ.sorted$stdeviation <- sd(t1.academ.sorted[May2020:April2021])
# Examine St error across 12 months
t1.academ.sorted$stdeviation <- sd(t1.academ.sorted[c("May2020":"April2021")])
# Examine St error across 12 months
t1.academ.sorted  %>% mutate(stdeviation = sd(select(t1.academ.sorted,
May2020:April2021), na.rm = TRUE))
# Examine St error across 12 months
t1.academ.sorted  %>% mutate_if(is.double, as.numeric)%>%
mutate(stdeviation = sd(select(t1.academ.sorted,
May2020:April2021), na.rm = TRUE))
is.double(t1.academ.sorted$May2020)
t1.academ.sorted$May2020<-as.numeric(t1.academ.sorted$May2020)
t1.academ.sorted$June2020<-as.numeric(t1.academ.sorted$June2020)
t1.academ.sorted$July2020<-as.numeric(t1.academ.sorted$July2020)
t1.academ.sorted$August2020<-as.numeric(t1.academ.sorted$August2020)
t1.academ.sorted$Sept2020<-as.numeric(t1.academ.sorted$Sept2020)
t1.academ.sorted$Oct2020<-as.numeric(t1.academ.sorted$Oct2020)
t1.academ.sorted$Nov2020<-as.numeric(t1.academ.sorted$Nov2020)
t1.academ.sorted$Dec2020<-as.numeric(t1.academ.sorted$Dec2020)
t1.academ.sorted$Jan2021<-as.numeric(t1.academ.sorted$Jan2021)
t1.academ.sorted$Feb2021<-as.numeric(t1.academ.sorted$Feb2021)
t1.academ.sorted$March2021<-as.numeric(t1.academ.sorted$March2021)
t1.academ.sorted$April2021<-as.numeric(t1.academ.sorted$April2021)
t1.academ.sorted  %>% mutate(stdeviation = sd(select(t1.academ.sorted,
May2020:April2021), na.rm = TRUE))
# Examine St error across 12 months
t1.academ.sorted$May2020<-numeric(t1.academ.sorted$May2020)
# Examine St error across 12 months
t1.academ.sorted$May2020<-as.numeric(t1.academ.sorted$May2020)
is.numeric(t1.academ.sorted$May2020)
t1.academ.sorted  %>% mutate(stdeviation = sd(select(May2020:April2021), na.rm = TRUE))
names(t1.academ.sorted)
t1.academ.sorted$stdeviation <- sd(t1.academ.sorted[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")])
t1.academ.sorted$stdev <- sd(t1.academ.sorted[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")])
t1.academ.sorted$stdev <- apply(t1.academ.sorted[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd)
View(t1.academ.sorted)
# Create intuitive labels for each month
t1.academ.sorted <- t1.academ.sorted %>% rename(MASE=MASE1_w1,MAE=mean_abs_error_w1,
May2020=Month.1,
June2020=Month.2,
July2020=Month.3,
August2020=Month.4,
Sept2020=Month.5,
Oct2020=Month.6,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
t1.academ.sorted$stdev <- apply(t1.academ.sorted[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd)
# Rank order the performance of all teams for each domain using MASE scores - academics only
t1.academ.sorted <- phase1_exp %>%
arrange(domain, MASE1_w1) %>%
group_by(domain) %>%
mutate(Rank = row_number()) %>%
add_count(name="Nteams") %>%
dplyr::select(team_name, domain, Rank, Nteams, Method.code, Month.1:Month.12,mean_abs_error_w1,MASE1_w1)
# Create intuitive labels for domains
t1.academ.sorted$Domains[t1.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="polar"]<-"Political Polarization"
# Compute average accuracy for each domain - non-academic only
t1.nonacadem.av.sorted <- phase1 %>%
filter(isExpert.factor == 'Prolific') %>%                                                               dplyr::select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>%
summarise(across(where(is.numeric), mean)) %>%
arrange(domain,MASE1_w1) %>%
mutate(team_name="average non-academic")
# Compute median accuracy for each domain - non-academic only
t1.nonacadem.median.sorted<- phase1 %>%
filter(isExpert.factor == 'Prolific') %>%                                                               dplyr::select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,,Method.code) %>%
group_by(domain) %>%
summarise(across(where(is.numeric), median)) %>%
arrange(domain,MASE1_w1) %>%
mutate(team_name="median non-academic")
# Compute best prediction for each of the domains - in other words prediction with the lowest MASE scores - non academics
t1.nonacadem.best.sorted <- phase1 %>%
filter(isExpert.factor == 'Prolific') %>%                                                               dplyr::select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>%
summarise(across(where(is.numeric), min)) %>%
arrange(domain, MASE1_w1) %>%
mutate(team_name = "top non-academic")
# Best predictions for academics by domain
t1.academ.best.sorted <- phase1 %>%
filter(isExpert.factor == 'Academic') %>%                                                               dplyr::select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>%
summarise(across(where(is.numeric), min)) %>%
arrange(domain,MASE1_w1) %>%
mutate(team_name="top academic")
# Combine the two datasets.
t1.top.scores <- rbind(t1.academ.best.sorted, t1.nonacadem.best.sorted) %>%
arrange(domain, MASE1_w1)
#so, only for life satisfaction and polarization, best academic was better than best non-academic. For all other domains, non-academics were in fact better (but note that the sample of non-academic was larger)
#what is the percentage of academics and lay people, respectively, who were below 1 on MASE?
t1.scores <- rbind(t1.academ.sorted, t1.nonacadem.median.sorted)
# write.csv(t1.scores,"wave1.scores.csv")
# Rank order the performance of all teams for each domain using MASE scores - academics only
t2.academ.sorted <- academic_only %>%
filter(!(phase == 1 & revised == 1)) %>%
arrange(domain, MASE1_w2) %>%
group_by(domain) %>%
mutate(Rank = row_number()) %>%
add_count(name="Nteams") %>%
dplyr::select(team_name,domain,Rank,Nteams,Method.code,phase,revised,Month.7:Month.12,mean_abs_error_w2,MASE1_w2)
# Create intuitive labels for each domain
t2.academ.sorted$Domains[t2.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="polar"]<-"Political Polarization"
# write.csv(t2.academ.sorted,"wave2.scores.csv")
# Create intuitive labels for each domain
objective$Domains[objective$domain=="eafric"]<-"Explicit African American Bias"
objective$Domains[objective$domain=="easian"]<-"Explicit Asian American Bias"
objective$Domains[objective$domain=="egend"]<-"Explicit Gender-Career Bias"
objective$Domains[objective$domain=="iafric"]<-"Implicit African American Bias"
objective$Domains[objective$domain=="iasian"]<-"Implicit Asian American Bias"
objective$Domains[objective$domain=="igend"]<-"Implicit Gender-Career Bias"
objective$Domains[objective$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
objective$Domains[objective$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
objective$Domains[objective$domain=="lifesat"]<-"Life Satisfaction"
objective$Domains[objective$domain=="negaffect"]<-"Negative Affect in Social Media"
objective$Domains[objective$domain=="posaffect"]<-"Positive Affect in Social Media"
objective$Domains[objective$domain=="polar"]<-"Political Polarization"
# Create intuitive labels for each month
t1.academ.sorted <- t1.academ.sorted %>% rename(MASE=MASE1_w1,MAE=mean_abs_error_w1,
May2020=Month.1,
June2020=Month.2,
July2020=Month.3,
August2020=Month.4,
Sept2020=Month.5,
Oct2020=Month.6,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
# Create tournament length variable
t1.academ.sorted$Tournament<-"May - 12-months"
t1.academ.sorted$stdev <- apply(t1.academ.sorted[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd)
View(t1.academ.sorted$stdev)
View(t1.academ.sorted)
names(t1.academ.sorted)
describeBy(t1.academ.sorted$stdev,group=domain)
describeBy(t1.academ.sorted$stdev,group=t1.academ.sorted$domain)
t1.academ.sorted %>% group_by(domain) %>%
summarize(median = median(stdev), min = min(stdev), max = max(stdev))
t1.academ.sorted %>% group_by(domain) %>%
dplyr::summarize(median = median(stdev), min = min(stdev), max = max(stdev))
t1.academ.sorted %>% group_by(domain) %>%
dplyr::summarize(medianSD = median(stdev), min = min(stdev), max = max(stdev)) %>% arrange(medianSD)
t1.academ.sorted %>% group_by(domain) %>%
dplyr::summarize(medianSD = median(stdev), min = min(stdev), max = max(stdev)) %>% arrange(medianSD, -1)
?arrange
t1.academ.sorted %>% group_by(domain) %>%
dplyr::summarize(medianSD = median(stdev), min = min(stdev), max = max(stdev)) %>% arrange(desc(medianSD))
# Create intuitive labels
objective <- objective %>% rename(May2020=Month.1,
June2020=Month.2,
July2020=Month.3,
August2020=Month.4,
Sept2020=Month.5,
Oct2020=Month.6,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
objective$Tournament<-"Ground truth marker"
#examine SD
# Examine St error across 12 months
objective$stdev <- apply(objective[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd)
objective
#examine SD
# Examine St error across 12 months
objective$stdev <- apply(objective[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd, narm=T)
#examine SD
# Examine St error across 12 months
objective$stdev <- apply(objective[c("May2020","June2020","July2020",  "August2020",
"Sept2020",    "Oct2020",     "Nov2020",     "Dec2020",
"Jan2021",     "Feb2021",     "March2021",   "April2021")], 1, sd, na.rm=T)
objective
# Read in historical data
historical <- read.csv("historical_data.csv")
historical_tsbl <- as_tsibble(historical, index = Month)
View(historical)
historical_tsbl %>%
pivot_longer(negaffect:polar,names_to="Domain",values_to="Score") %>% mutate(Domain = factor(Domain,      # Reordering group factor levels
levels = c("egend","easian","eafric",
"igend","iasian","iafric",
"posaffect","negaffect","lifesat",
"polar","ideoldem","ideolrep")))
View9historical_tsbl
View(historical_tsbl)
View(historical_tsbl %>%
+   pivot_longer(negaffect:polar,names_to="Domain",values_to="Score") %>% mutate(Domain = factor(Domain,      # Reordering group factor levels
+                          levels = c("egend","easian","eafric",
View(historical_tsbl %>%
+   pivot_longer(negaffect:polar,names_to="Domain",values_to="Score") %>% mutate(Domain = factor(Domain,      # Reordering group factor levels
+                          levels = c("egend","easian","eafric",
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < -13 |Month >-1)
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < -13 & Month >-1)
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < -1 & Month >-13)
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < 0 & Month >-13)
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < 0 & Month >-13) %>% dplyr::summarise_at(vars(negaffect:polar), median, na.rm = TRUE)
#calculate SD in historical data for the last 12 months before the pandemic.
historical %>% filter(Month < 0 & Month >-13) %>% dplyr::summarise_at(vars(negaffect:polar), sd, na.rm = TRUE)

<<<<<<< Updated upstream
Rmisc::CI(MASE_set3c, ci=0.95)
install.packages("Rmisc")
Rmisc::CI(MASE_set3c, ci=0.95)
Rmisc::CI(MASE_set3c$MASE_posAffect3c, ci=0.95)
apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)})
t(apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)}))
as.data.frame(t(apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)})))
set3 = as.data.frame(t(apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)})))
set3
row.names(set3)
data.phase2.update
data.phase2.update$domain
gsub('MASE_','',row.names(set3))
gsub('3c','',gsub('MASE_','',row.names(set3)))
row.names(set3) = gsub('3c','',gsub('MASE_','',row.names(set3)))
set3
set3 = as.data.frame(t(apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)})))
set3$domain = gsub('3c','',gsub('MASE_','',row.names(set3)))
set3
names(set3) = c('upper.CL','emmean','lower.CL','domain')
rbind(data.phase2.update,set3)
rbind(data.phase2.update[,c('domain','emmean','lower.CL','upper.CL')],set3)
data.May<-subset(data.phase2.update,Group=="Original May")
rbind(data.May[,c('domain','emmean','lower.CL','upper.CL')],set3)
data.May$type<-"May participants"
rbind(data.May[,c('domain','emmean','lower.CL','upper.CL')],set3)
rbind(data.May[,c('domain','emmean','lower.CL','upper.CL','type')],set3)
set3$type<-"Regression Benchmark"
data.May<-subset(data.phase2.update,Group=="Original May")
data.May$type<-"May participants"
rbind(data.May[,c('domain','emmean','lower.CL','upper.CL','type')],set3)
library(ggplot2)
library(ggsci)
data.wb3 %>%
ggplot(aes(x = domain, y = emmean, colour = type, fill=type))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)
data.wb3<-rbind(data.May[,c('domain','emmean','lower.CL','upper.CL','type')],set3)
data.wb3 %>%
ggplot(aes(x = domain, y = emmean, colour = type, fill=type))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)
MASE_posaffect3c = naive3c('posaffect')
MASE_negaffect3c = naive3c('negaffect')
MASE_set3c = data.frame(MASE_posaffect3c,MASE_negaffect3c, MASE_eafric3c,
MASE_easian3c,MASE_egend3c,MASE_iafric3c,MASE_iasian3c,MASE_igend3c,MASE_lifesat3c,
MASE_ideoldem3c,MASE_ideolrep3c,MASE_polar3c)
set3 = as.data.frame(t(apply(MASE_set3c, 2, function(x){Rmisc::CI(x, ci=0.95)})))
set3$domain = gsub('3c','',gsub('MASE_','',row.names(set3)))
names(set3) = c('upper.CL','emmean','lower.CL','domain')
set3$type<-"Regression Benchmark"
data.May<-subset(data.phase2.update,Group=="Original May")
data.May$type<-"May participants"
data.wb3<-rbind(data.May[,c('domain','emmean','lower.CL','upper.CL','type')],set3)
library(ggplot2)
library(ggsci)
data.wb3 %>%
ggplot(aes(x = domain, y = emmean, colour = type, fill=type))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)
psych::describe(MASE_set3c)
describe(MASE_set3c)
psych::describe(MASE_set3c)
phase1_exp$MASE1_w1
phase1_exp$domain
names(phase1_exp)
phase1_exp$isExpert
phase1_exp %>% ggplot(aes(x = domain, y = MASE1_w1,colour = Method.code, fill=Method.code))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
View(phase1_exp)
View(phase1_exp[c("MASE1_w1","domain")])
vplotData = data.frame(MASE1_w1 = c(MASE_posaffect3c,MASE_negaffect3c, MASE_eafric3c,
MASE_easian3c,MASE_egend3c,MASE_iafric3c,MASE_iasian3c,MASE_igend3c,MASE_lifesat3c,
MASE_ideoldem3c,MASE_ideolrep3c,MASE_polar3c),
domain = rep(c('posaffect','negaffect', 'eafric',
'easian','egend','iafric','iasian','igend','lifesat',
'ideoldem','ideolrep','polar'), each = 10000))
View(vplotData)
vPlotData$type = 'Regression Benchmark'
vplotData$type = 'Regression Benchmark'
phase1_exp.d<-phase1_exp[c("MASE1_w1","domain")]
phase1_exp.d$type<-"May participants"
data.t1.b<-rbind(phase1_exp.d,vplotData)
View(vplotData)
vplotData<-rbind(phase1_exp.d,vplotData)
vplotData = data.frame(MASE1_w1 = c(MASE_posaffect3c,MASE_negaffect3c, MASE_eafric3c,
MASE_easian3c,MASE_egend3c,MASE_iafric3c,MASE_iasian3c,MASE_igend3c,MASE_lifesat3c,
MASE_ideoldem3c,MASE_ideolrep3c,MASE_polar3c),
domain = rep(c('posaffect','negaffect', 'eafric',
'easian','egend','iafric','iasian','igend','lifesat',
'ideoldem','ideolrep','polar'), each = 10000))
vplotData$type = 'Regression Benchmark'
phase1_exp %>% ggplot(aes(x = domain, y = MASE1_w1,colour = Method.code, fill=Method.code))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
phase1_exp.d<-phase1_exp[c("MASE1_w1","domain")]
phase1_exp.d$type<-"May participants"
combined_phase1<-rbind(phase1_exp.d,vplotData)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
library(Rstats)
library(Hmisc)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd, colors=red)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
?geom_violin
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin(alpha =.7)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin(alpha =.5)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd, size = 2)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
phase1_exp %>% ggplot(aes(x = domain, y = MASE1_w1,colour = Method.code, fill=Method.code))+geom_violin()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
data.wb3 %>%
ggplot(aes(x = domain, y = emmean, colour = type, fill=type))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin(alpha =.5)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd, size = 1.2)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
vplotData = data.frame(MASE1_w1 = c(MASE_posaffect3c,MASE_negaffect3c, MASE_eafric3c,
MASE_easian3c,MASE_egend3c,MASE_iafric3c,MASE_iasian3c,MASE_igend3c,MASE_lifesat3c,
MASE_ideoldem3c,MASE_ideolrep3c,MASE_polar3c),
domain = rep(c('posaffect','negaffect', 'eafric',
'easian','egend','iafric','iasian','igend','lifesat',
'ideoldem','ideolrep','polar'), each = 10000))
vplotData$type = 'Regression Benchmark'
phase1_exp.d<-phase1_exp[c("MASE1_w1","domain")]
phase1_exp.d$type<-"May participants"
combined_phase1<-rbind(phase1_exp.d,vplotData)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin(alpha =.5)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd, size = 1.2)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
psych::describe.by(combined_phase1,group=domain*type)
psych::describe.by(combined_phase1,group=(c"domain","type"))
psych::describe.by(combined_phase1,group=c("domain","type"))
psych::describe.by(combined_phase1$MASE1_w1,group=combined_phase1[c("domain","type")])
data.wb3
model.phase1.base<-  lmer(MASE1_w1~domain+(1|ResponseId), data=phase1_exp)
data.phase1.base<-as.data.frame(emmeans(model.phase1.base,pairwise ~domain, adjust = "none")$emmeans) #nonsig
data.phase1.base
data.May<-as.data.frame(emmeans(model.phase1.base,pairwise ~domain, adjust = "none")$emmeans) #nonsig
data.May$type<-"May participants"
data.wb3<-rbind(data.May[,c('domain','emmean','lower.CL','upper.CL','type')],set3)
data.wb3 %>%
ggplot(aes(x = domain, y = emmean, colour = type, fill=type))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+ theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)") +scale_x_discrete(labels=labels)
combined_phase1 %>% ggplot(aes(x = domain, y = MASE1_w1,colour = type, fill=type))+geom_violin(alpha =.5)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ylim(0,NA)+facet_wrap(~domain, nrow=3, scale="free")+stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2, position=pd, size = 1.2)+
labs(colour = "Sample",fill="Sample", x="",y="MASE (M +/- 95%CI)")
table(phase1_exp$domain)
table(vplotData$domain,vplotData$type)
table(combined_phase1$domain,combined_phase1$type)
summ(model.phase1.base)
6.47-3.03
describe(phase1_exp$domain)
psych::describe(phase1_exp$domain)
phase1_exp
describe(phase1_exp$MASE1_w1)
describeBy(phase1_exp$MASE1_w1,group=phase1_exp$domain)
table(phase1_exp$ResponseId)
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)
options(max.print = 20000, scipen = 1000)
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 )
#datasets that are filtered by phase (1 = May submission, 2 = November submission)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)
objective<-dat %>% filter(Method=="Objective", phase ==1) %>% select(domain:Month.12)
#####download of phase 1 and 2 files########################
t1.academ.sorted<-phase1_exp %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% mutate(Rank = row_number()) %>% add_count(name="Nteams")%>% select(team_name,domain,Rank, Nteams,Method.code, Month.1:Month.12,mean_abs_error_w1,MASE1_w1)
t1.academ.sorted$Domains[t1.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t1.academ.sorted$Domains[t1.academ.sorted$domain=="polar"]<-"Political Polarization"
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>% summarise(across(where(is.numeric), mean)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="average non-academic")
t1.nonacadem.median.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,,Method.code) %>%
group_by(domain) %>% summarise(across(where(is.numeric), median)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="median non-academic")
t1.nonacadem.best.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>% summarise(across(where(is.numeric), min)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="top non-academic")
t1.academ.best.sorted<-phase1 %>% filter(isExpert.factor == 'Academic') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1,Method.code) %>%
group_by(domain) %>% summarise(across(where(is.numeric), min)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="top academic")
t1.top.scores<-rbind(t1.academ.best.sorted,t1.nonacadem.best.sorted)%>% arrange(domain,MASE1_w1)
#so, only for life satisfaction and polarization, best academic was better than best non-academic. For all other domains, non-academics were in fact better (but note that the sample of non-academic was larger)
#what is the percentage of academics and lay people, respectively, who were below 1 on MASE?
t1.scores<-rbind(t1.academ.sorted,t1.nonacadem.median.sorted)
write.csv(t1.scores,"wave1.scores.csv")
t2.academ.sorted<-academic_only %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% mutate(Rank = row_number()) %>% add_count(name="Nteams") %>% select(team_name,domain,Rank,Nteams,Method.code,phase,revised,Month.7:Month.12,mean_abs_error_w2,MASE1_w2)
t2.academ.sorted$Domains[t2.academ.sorted$domain=="eafric"]<-"Explicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="easian"]<-"Explicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="egend"]<-"Explicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iafric"]<-"Implicit African American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="iasian"]<-"Implicit Asian American Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="igend"]<-"Implicit Gender-Career Bias"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="lifesat"]<-"Life Satisfaction"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="negaffect"]<-"Negative Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="posaffect"]<-"Positive Affect in Social Media"
t2.academ.sorted$Domains[t2.academ.sorted$domain=="polar"]<-"Political Polarization"
write.csv(t2.academ.sorted,"wave2.scores.csv")
objective$Domains[objective$domain=="eafric"]<-"Explicit African American Bias"
objective$Domains[objective$domain=="easian"]<-"Explicit Asian American Bias"
objective$Domains[objective$domain=="egend"]<-"Explicit Gender-Career Bias"
objective$Domains[objective$domain=="iafric"]<-"Implicit African American Bias"
objective$Domains[objective$domain=="iasian"]<-"Implicit Asian American Bias"
objective$Domains[objective$domain=="igend"]<-"Implicit Gender-Career Bias"
objective$Domains[objective$domain=="ideoldem"]<-"Ideological Preferences for Democrats"
objective$Domains[objective$domain=="ideolrep"]<-"Ideological Preferences for Republicans"
objective$Domains[objective$domain=="lifesat"]<-"Life Satisfaction"
objective$Domains[objective$domain=="negaffect"]<-"Negative Affect in Social Media"
objective$Domains[objective$domain=="posaffect"]<-"Positive Affect in Social Media"
objective$Domains[objective$domain=="polar"]<-"Political Polarization"
t1.academ.sorted<-t1.academ.sorted %>% rename(MASE=MASE1_w1,MAE=mean_abs_error_w1,
May2020=Month.1,
June2020=Month.2,
July2020=Month.3,
August2020=Month.4,
Sept2020=Month.5,
Oct2020=Month.6,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
t1.academ.sorted$Tournament<-"May - 12-months"
t2.academ.sorted<-t2.academ.sorted %>% rename(MASE=MASE1_w2,MAE=mean_abs_error_w2,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
t2.academ.sorted$Tournament<-"November - 6-months"
objective<-objective %>% rename(May2020=Month.1,
June2020=Month.2,
July2020=Month.3,
August2020=Month.4,
Sept2020=Month.5,
Oct2020=Month.6,
Nov2020=Month.7,
Dec2020=Month.8,
Jan2021=Month.9,
Feb2021=Month.10,
March2021=Month.11,
April2021=Month.12)
objective$Tournament<-"Ground truth marker"
results<-rbind(t1.academ.sorted,t2.academ.sorted,objective) %>% ungroup() %>% select(-domain,-Method.code, -(phase:revised))
results<-results %>% arrange(Tournament) %>% relocate(where(is.numeric), .after = where(is.character))
write.csv(results,"final.results.csv")
pd <- position_dodge(0.7) # move them .07 to the left and right
labels<-c(
eafric = "Exp. African\n-Am. Bias",
easian = "Exp. Asian\n-Am. Bias",
egend = "Exp. \nGender Bias",
iafric = "Imp. African\n-Am. Bias",
iasian = "Imp. Asian\n-Am. Bias",
ideoldem = "Dem.\nSupport",
ideolrep ="Rep.\nSupport",
igend = "Imp.\nGender Bias",
lifesat = "Life\nSatisfaction",
negaffect = "Negative\nAffect",
polar = "Polit.\nPolarization",
posaffect = "Positive\nAffect")
#T1
##########################################################
#who won?
top.1.MASE.t1<-phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 1) %>% select(team_name,mean_abs_error_w1,MASE1_w1,Month.1:Month.12,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise) %>% arrange(MASE1_w1)
write.csv(top.1.MASE.t1,"top.t1.csv")
#examine top 5
top.5.MASE.t1<-phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w1,domain,compare_to_naive_linear_MASE,compare_to_naive_rwf_MASE,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)
top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=Method.code)) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_aaas(name="Approach")+ylab("MASE")
proportions(xtabs( ~ Method.code,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ domain+Method.code,top.5.MASE.t1),"domain")*100 #by domain
top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=compare_to_naive_linear_MASE, shape =compare_to_naive_rwf_MASE )) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Compared to\nLinear Model")+scale_shape_discrete(name="Compared to\nRandom Walk")+ylab("MASE")
top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=discipline)) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Field")+ylab("MASE")
proportions(xtabs( ~ discipline,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ domain+discipline,top.5.MASE.t1),"domain")*100 #by domain
top.5.MASE.t1 %>%  ggplot(aes(x=domain, y=MASE1_w1, colour=as.factor(previous_tournament.coded))) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Prior Forecasting Experience")+ylab("MASE")
proportions(xtabs( ~ previous_tournament.coded,top.5.MASE.t1))*100 #in total
proportions(xtabs( ~ previous_tournament.coded,phase1 %>% filter(isExpert.factor == 'Academic') ))*100 #baserate of prior experience to compare to top 5
proportions(xtabs( ~ domain+previous_tournament.coded,top.5.MASE.t1),"domain")*100 #by domain
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
ggplot(aes(x = domain, y = team_size.coded))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Size of Top 10 Teams (M +/- 95%CI)")
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)")
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_gender))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_education))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y=" (M +/- 95%CI)")
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_Age))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")
phase1 %>% filter(isExpert.factor == 'Academic')  %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = non_US))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")
##comparison to lay people
proportions(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+isExpert.factor,phase1))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation
proportions(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1),"isExpert.factor")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+isExpert.factor,phase1))
##comparison by method among academics
proportions(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,phase1_exp))
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE+Method.code,subset(phase1_exp, compare_to_naive_rwf_MASE!="Equal to Naive rwf")))
proportions(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1))
chisq.test(xtabs( ~ compare_to_naive_linear_MASE+Method.code,phase1_exp)) #just comparison of academics
##PHASE 2
#who won?
top.1.MASE.t2<-academic_only  %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 1) %>% select(domain,mean_abs_error_w2,MASE1_w2,team_name,mean_abs_percent_error_w2,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE_w2,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
write.csv(top.1.MASE.t2,"top.t2.csv")
#examine top 5
top.5.MASE.t2<-academic_only %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w2,domain,compare_to_naive_linear_MASE_w2,compare_to_naive_rwf_MASE_w2,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,phase,revised)
top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=Method.code)) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_aaas(name="Approach")+ylab("MASE")
proportions(xtabs( ~ Method.code,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ domain+Method.code,top.5.MASE.t2),"domain")*100 #by domain
top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=compare_to_naive_linear_MASE_w2, shape =compare_to_naive_rwf_MASE_w2 )) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Compared to\nLinear Model")+scale_shape_discrete(name="Compared to\nRandom Walk")+ylab("MASE")
top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=discipline)) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Field")+ylab("MASE")
proportions(xtabs( ~ discipline,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ domain+discipline,top.5.MASE.t2),"domain")*100 #by domain
top.5.MASE.t2 %>%  ggplot(aes(x=domain, y=MASE1_w2, colour=as.factor(previous_tournament.coded))) +
geom_point(size=3, position=pd, alpha = .5) + scale_x_discrete(labels=labels, name="")+geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="top")+scale_colour_d3(name="Prior Forecasting Experience")+ylab("MASE")
proportions(xtabs( ~ previous_tournament.coded,top.5.MASE.t2))*100 #in total
proportions(xtabs( ~ previous_tournament.coded,academic_only%>% filter(!(phase == 1 & revised == 1))))*100 #baserate of prior experience to compare to top 5
proportions(xtabs( ~ domain+previous_tournament.coded,top.5.MASE.t2),"domain")*100 #by domain
academic_only   %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
ggplot(aes(x = domain, y = team_size.coded))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Size of Top 10 Teams (M +/- 95%CI)")
academic_only    %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)")
academic_only%>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 5) %>% select(team_name,MASE1_w1,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise)%>%
ggplot(aes(x = domain, y = Method.complex))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="Model complexity (M +/- 95%CI)") #same as for top 10
academic_only   %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_gender))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Female per Team (M +/- 95%CI)")
academic_only   %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_education))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non_PHD per Team (M +/- 95%CI)")
academic_only   %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = team_Age))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Average Team Age (M +/- 95%CI)")
academic_only  %>% filter(!(phase == 1 & revised == 1)) %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% dplyr::slice_head(n = 10) %>% select(team_name,MASE1_w2,domain,team_size.coded,discipline,previous_tournament.coded,Method.code,model,theory,numpred,parameters,Method.complex,team_expertise,team_gender,team_education,team_Age,non_US )%>%
ggplot(aes(x = domain, y = non_US))+
stat_summary(fun.data="mean_cl_boot",  position=pd)+theme_minimal(base_size = 14) +
theme(legend.position="bottom") +scale_x_discrete(labels=labels, name="")+
labs(colour = "Approach",fill="Approach", x="",y="% Non-US per Team (M +/- 95%CI)")
##comparison by method among academics
proportions(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,academic_only %>% filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_rwf_MASE_w2+Method.code,subset(academic_only%>% filter(!(phase == 1 & revised == 1)), compare_to_naive_rwf_MASE_w2!="Equal to Naive rwf"))) #exclude equal as it is negligible and screws up calculation
proportions(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))),"Method.code")*100 #
chisq.test(xtabs( ~ compare_to_naive_linear_MASE_w2+Method.code,academic_only%>% filter(!(phase == 1 & revised == 1))))
#############################################################
historical<-read.csv("historical_data.csv")
library(tsibble)
historical_tsbl <- as_tsibble(historical, index = Month)
historical_tsbl %>% pivot_longer(negaffect:polar,names_to="Domain",values_to="Score") %>%
ggplot(aes(x = Month, y = Score, colour = Domain))+
geom_smooth(aes(x = Month, y = Score, colour = Domain),method = "loess") +
facet_wrap(~Domain, scales = "free", nrow = 3, labeller=labeller(Domain=labels))+
theme_minimal(base_size = 14) +
theme(legend.position="none") +
labs(x="Months (< 0 = before May 2020)",y="Estimate")
#do by method (among experts now)
#get ground truth markers (subset)
dat_long$Month0<-dat_long$Month-1
objective<-as.data.frame(subset(dat_long,phase == 1 & !is.na(Method.code)& Method.code=="Ground Truth"))
#get subset for analyses, focusing on value.dif column i -  absolute percent deviation for each predicted Month
#For models evaluating accuracy of individual time points, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain and time points as predictors, with absolute percent deviation scores nested within teams.
dat_long_phase1<-dat_long %>%subset(phase == 1 & Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw")
dat_long_phase1$Method.code <- relevel(factor(dat_long_phase1$Method.code), "Lay People") #use lay people as a reference group
phase1$Method.code <- relevel(factor(phase1$Method.code), "Lay People") #use lay people as a reference group
phase1_exp$updated<-ifelse(phase1_exp$revised==1,"update","no update")
phase1$compare_to_naive_rwf_MASE.update<-ifelse(phase1$compare_to_naive_rwf_MASE!="Equal to Naive rwf",phase1$compare_to_naive_rwf_MASE,ifelse(phase1$compare_to_naive_rwf_MASE=="Equal to Naive rwf","Below Naive rwf",NA))
phase1_exp$teamS<-as.factor(ifelse(phase1_exp$team_size.coded>=6,3,ifelse(phase1_exp$team_size.coded<6&phase1_exp$team_size.coded>1,2,ifelse(phase1_exp$team_size.coded==1,1,NA))))
phase1_exp$is_multidisciplinary<-ifelse(phase1_exp$discipline=="Multi-disciplinary",1,0)
phase1_exp$objectivexpert<-ifelse(phase1_exp$pub==1,"Expert",ifelse(phase1_exp$pub==2,"Non Expert",NA))
dat_long_phase1$teamS<-as.factor(ifelse(dat_long_phase1$team_size.coded>=6,3,ifelse(dat_long_phase1$team_size.coded<6&dat_long_phase1$team_size.coded>1,2,ifelse(dat_long_phase1$team_size.coded==1,1,NA))))
dat_long_phase1$is_multidisciplinary<-ifelse(dat_long_phase1$discipline=="Multi-disciplinary",1,0)
dat_long_phase1$objectivexpert<-ifelse(dat_long_phase1$pub==1,"Expert",ifelse(dat_long_phase1$pub==2,"Non Expert",NA))
## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
model.phase1.base<-  lmer(MASE1_w1~domain+(1|ResponseId), data=phase1_exp)
emmeans(model.phase1.base,pairwise ~domain, adjust = "none")
emmeans(model.phase1.base, ~domain, adjust = "none"
)
emmeans(model.phase1.base, ~|domain, adjust = "none")
?emmeans
?predict
ggeffects::ggpredict(model.phase1.base,"domain")
phase1_exp %>%
group_by(domain) %>%
summarise_at(vars(MASE1_w1), list(name = mean))
hist(phase1_exp$MASE1_w1)
## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
model.phase1.base<-  glmer(MASE1_w1~domain+(1|ResponseId), data=phase1_exp, family="poisson")
ggeffects::ggpredict(model.phase1.base,"domain") #compare to ggpredict effects (using predict())
#raw means
phase1_exp %>%
group_by(domain) %>%
summarise_at(vars(MASE1_w1), list(name = mean))
## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
model.phase1.base<-  glmer(MASE1_w1~domain+(1|ResponseId), data=phase1_exp, family="quasipoisson")
## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
model.phase1.base<-  glmer(MASE1_w1~domain+(1|ResponseId), data=phase1_exp, family="Gamma")
plot(model.phase1.base)
qqplot(model.phase1.base)
resid(model.phase1.base)
plot(resid(model.phase1.base))
=======
iafric = "Imp. Bias Vs. Afr.-Am.\nhigher=stereo-consistent\n(IAT D score)",
iasian = "Imp. Bias Vs. Asian.-Am.\nhigher=stereo-consistent\n(IAT D score)",
ideoldem = "Democratic Support\n(% Population)",
ideolrep ="Republican Support\n(% Population)",
igend = "Imp. Bias Vs. Women-Career\nhigher=stereo-consistent\n(IAT D score)",
lifesat = "Life Satisfaction\nCantril ladder\n(0-10 scale)",
negaffect = "Negative Affect\nstandardized Vs. historical M/SD\n(z-score)",
polar = "Polit. Polarization\n% of Rep. Vs. Dem. approvals\n(absolute difference score) ",
posaffect = "Positive Affect\n(z-score)")
objective.t<-subset(hist_long,Month>0)
hist.t<-subset(hist_long,Month %in% c(-2:-1))
hist.t$phaseF<-"Historical"
# with 3 historical months before the tournament
hist_long%>% subset(Month %in% c(-2:12))%>%
ggplot(aes(x = Month, y = value, colour = phaseF, fill=phaseF))+
theme_pubclean()+
geom_line(data=objective.t,alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=objective.t,alpha=.9,aes(x = Month)) +geom_line(data=hist.t,alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=hist.t,alpha=.9,aes(x = Month))+   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ scale_x_continuous(breaks=c(-2:12), labels =c("Feb","","","May","","","Aug","","","Nov","","","Feb","",""))+  labs(colour = "",fill="", x="",y="Forecasted & Observed Change")+facet_wrap(~domain, scales = "free_y", nrow = 4, labeller=labeller(domain=labels))+ geom_line(data=dat_longX,alpha=.09,aes(x = Month, group=team_name), na.rm=TRUE)+  #geom_point(data = dat_longX,alpha=.1,aes(x = Month0, group=team_name)) +
theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=1, size=rel(0.8)))+geom_smooth(data=dat_long %>% subset(!is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" &Method.code!="Lay People"& Month %in% c(-2:12)), aes(x = Month, y = value, colour = phaseF, fill=phaseF),method = "loess")
# select just negative affect
plot.negaffect<-hist_long%>% subset(Month %in% c(-2:12) & domain %in% c("negaffect"))%>%
ggplot(aes(x = Month, y = value, colour = phaseF, fill=phaseF))+
theme_pubclean()+
geom_line(data=subset(objective.t,domain %in% c("negaffect")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(objective.t, domain %in% c("negaffect")),alpha=.9,aes(x = Month)) +geom_line(data=subset(hist.t,domain %in% c("negaffect")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(hist.t,domain %in% c("negaffect")),alpha=.9,aes(x = Month))+   theme(legend.position="bottom") +  theme(legend.position="bottom", legend.text = element_text(size=7)) +scale_color_d3()+scale_fill_d3()+ scale_x_continuous(breaks=c(-2:12), labels =c("Feb","","","May","","","Aug","","","Nov","","","Feb","",""))+  labs(colour = "",fill="", x="",y="z-score", title="Negative Affect", subtitle = "Standartized against historical M/SD")+ geom_line(data=subset(dat_longX, domain %in% c("negaffect")),alpha=.13,aes(x = Month, group=team_name), na.rm=TRUE)+  #geom_point(data = dat_longX,alpha=.1,aes(x = Month0, group=team_name)) +
theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=1, size=rel(0.8)))+geom_smooth(data=dat_long %>% subset(!is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" &Method.code!="Lay People"& Month %in% c(-2:12) & domain %in% c("negaffect")), aes(x = Month, y = value, colour = phaseF, fill=phaseF),method = "loess") +theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))
# select pos affect and life satisfaction
plot.LS.and.posaffect<-hist_long%>% subset(Month %in% c(-2:12)& domain %in% c("posaffect", "lifesat"))%>%
ggplot(aes(x = Month, y = value, colour = phaseF, fill=phaseF))+
theme_pubclean()+
geom_line(data=subset(objective.t,domain %in% c("posaffect", "lifesat")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(objective.t, domain %in% c("posaffect", "lifesat")),alpha=.9,aes(x = Month)) +geom_line(data=subset(hist.t,domain %in% c("posaffect", "lifesat")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(hist.t,domain %in% c("posaffect", "lifesat")),alpha=.9,aes(x = Month))+
theme(legend.position="none") +scale_color_d3()+scale_fill_d3()+ scale_x_continuous(breaks=c(-2:12), labels =c("Feb","","","May","","","Aug","","","Nov","","","Feb","",""))+  labs(colour = "",fill="", x="",y="")+facet_wrap(~domain, scales = "free_y", nrow = 4, labeller=labeller(domain=labels))+ geom_line(data=subset(dat_longX, domain %in% c("posaffect", "lifesat")) ,alpha=.09,aes(x = Month, group=team_name), na.rm=TRUE)+  #geom_point(data = dat_longX,alpha=.1,aes(x = Month0, group=team_name)) +
theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=1, size=rel(0.8)))+geom_smooth(data=dat_long  %>% subset(!is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" &Method.code!="Lay People"& Month %in% c(-2:12)& domain %in% c("posaffect", "lifesat")), aes(x = Month, y = value, colour = phaseF, fill=phaseF),method = "loess")
plot.wb<-ggarrange(plot.negaffect,plot.LS.and.posaffect,  ncol=2, nrow=1,widths=c(2,1))
#graph for slides
##graph for paper
# select just negative affect
plot.negaffectX<-hist_long%>% subset(Month %in% c(-2:12) & domain %in% c("negaffect"))%>%
ggplot(aes(x = Month, y = value, colour = phaseF, fill=phaseF))+
theme_pubclean()+
geom_line(data=subset(objective.t,domain %in% c("negaffect")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(objective.t, domain %in% c("negaffect")),alpha=.9,aes(x = Month)) +geom_line(data=subset(hist.t,domain %in% c("negaffect")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(hist.t,domain %in% c("negaffect")),alpha=.9,aes(x = Month))+
theme(legend.position="none") +scale_color_d3()+scale_fill_d3()+ scale_x_continuous(breaks=c(-2:12), labels =c("Feb","","","May","","","Aug","","","Nov","","","Feb","",""))+  labs(colour = "",fill="", x="",y="z-score", title="Negative Affect", subtitle = "Standardized against historical M/SD")+ geom_line(data=subset(dat_longX, domain %in% c("negaffect")),alpha=.13,aes(x = Month, group=team_name), na.rm=TRUE)+  #geom_point(data = dat_longX,alpha=.1,aes(x = Month0, group=team_name)) +
theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=1, size=rel(0.8)))+geom_smooth(data=dat_long %>% subset(!is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" &Method.code!="Lay People"& Month %in% c(-2:12) & domain %in% c("negaffect")), aes(x = Month, y = value, colour = phaseF, fill=phaseF),method = "loess") +theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5))
plot.wbX<-ggarrange(plot.negaffectX,plot.LS.and.posaffect,  ncol=2, nrow=1,widths=c(1.8,1))
#biases and politics
plot.all.but.WB<-hist_long%>% subset(Month %in% c(-2:12)& domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep"))%>%
ggplot(aes(x = Month, y = value, colour = phaseF, fill=phaseF))+
theme_pubclean()+
geom_line(data=subset(objective.t,domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(objective.t, domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")),alpha=.9,aes(x = Month)) +geom_line(data=subset(hist.t,domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")),alpha=.8,aes(x = Month), na.rm=TRUE)+  geom_point(data=subset(hist.t,domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")),alpha=.9,aes(x = Month))+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ scale_x_continuous(breaks=c(-2:12), labels =c("Feb","","","May","","","Aug","","","Nov","","","Feb","",""))+  labs(colour = "",fill="", x="",y="")+facet_wrap(~domain, scales = "free_y", nrow = 4, labeller=labeller(domain=labels))+ geom_line(data=subset(dat_longX, domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")) ,alpha=.09,aes(x = Month, group=team_name), na.rm=TRUE)+  #geom_point(data = dat_longX,alpha=.1,aes(x = Month0, group=team_name)) +
theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=1, size=rel(0.8)))+geom_smooth(data=dat_long  %>% subset(!is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" &Method.code!="Lay People"& Month %in% c(-2:12)& domain %in% c("egend","easian","eafric",
"igend","iasian","iafric","polar","ideoldem","ideolrep")), aes(x = Month, y = value, colour = phaseF, fill=phaseF),method = "loess")
#combine into megaplot
plot.all<-ggarrange(plot.wbX,plot.all.but.WB,  ncol=1, nrow=2, heights = c(1.2,1.8),  common.legend = TRUE, legend="bottom")
plot.all
# Chunk 9: Phases 1 and 2 along with sims
pd <- position_dodge(0.7) # move them .07 to the left and right
##by method for phase 1
###inspect data for distribution properties
hist(log(phase1$MASE1_w1)) #possibly do it on logs?
describe(phase1$MASE1_w1)
#analyses of phase 1  - MASE overall
model.phase1.together<-  lmer(log(MASE1_w1)~domain*isExpert.factor+(1|ResponseId), data=phase1)
car::Anova(model.phase1.together,type="III") #sig interaction!
data.phase1.MASE.together<-as.data.frame(emmeans(model.phase1.together, pairwise~domain*isExpert.factor, adjust = "none", type = "response")$emmeans) #backtransformed to the original scale
#phase 2
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
model.phase2.together<-  lmer(log(MASE1_w2)~domain+(1|team_name), data=dat_phase2)
car::Anova(model.phase2.together,type="III") #sig interaction!
data.phase2.MASE.together<-as.data.frame(emmeans(model.phase2.together, pairwise~domain, adjust = "none", type = "response")$emmeans) #backtransformed to the original scale
data.phase1.MASE.together$Wave<-"First Tournament (May 2020)"
data.phase1.MASE.together$Type[data.phase1.MASE.together$isExpert.factor=="Academic"]<-"Scientists"
data.phase1.MASE.together$Type[data.phase1.MASE.together$isExpert.factor=="Prolific"]<-"Naive Crowd"
data.phase2.MASE.together$Wave<-"Second Tournament (Nov 2020)"
data.phase2.MASE.together$Type<-"Scientists"
#add simulation benchmarks
sim.w1<- load("sim/BenchmarkData_Combined.RData")
sim.w1<-Stats_all_benchmarks_raw
sim.w1$Wave<-"First Tournament (May 2020)"
sim.w1<-subset(sim.w1,source!="Experts"&source!="Lay People")
sim.w1$response<-sim.w1$Mean
sim.w1$lower.CL<-sim.w1$CI_L
sim.w1$upper.CL<-sim.w1$CI_U
sim.w1$Type[sim.w1$source=="Benchmark 1"]<-"Historic Mean"
sim.w1$Type[sim.w1$source=="Benchmark 2"]<-"Random Walk"
sim.w1$Type[sim.w1$source=="Benchmark 3"]<-"Linear Regression"
sim.w2<- load("sim/BenchmarkData_Combined_W2.RData")
sim.w2<-Stats_all_benchmarks_raw_w2
sim.w2$Wave<-"Second Tournament (Nov 2020)"
sim.w2<-subset(sim.w2,source!="ExpertsW2")
sim.w2$response<-sim.w2$Mean
sim.w2$lower.CL<-sim.w2$CI_L
sim.w2$upper.CL<-sim.w2$CI_U
sim.w2$Type[sim.w1$source=="Benchmark 1"]<-"Historic Mean"
sim.w2$Type[sim.w1$source=="Benchmark 2"]<-"Random Walk"
sim.w2$Type[sim.w1$source=="Benchmark 3"]<-"Linear Regression"
#combine
means.compare.to.naive<-bind_rows(data.phase1.MASE.together,data.phase2.MASE.together,sim.w1,sim.w2)
#arrange in descending order based on MASE w1 of academics
means.compare.to.naive$domain<-factor(means.compare.to.naive$domain,levels=c("iafric","ideolrep","eafric",
"negaffect", "lifesat","easian","ideoldem","iasian", "polar", "igend","posaffect","egend"))
#arrange in descending order based on MASE w2 of academics
means.compare.to.naive$Wave<-factor(means.compare.to.naive$Wave,levels=c("First Tournament (May 2020)","Second Tournament (Nov 2020)"))
#arrange groups
means.compare.to.naive$Type<-factor(means.compare.to.naive$Type,levels=c("Scientists","Naive Crowd","Historic Mean","Random Walk","Linear Regression"))
#add var for Scientists vs. rest (to define colors)
means.compare.to.naive$Group[means.compare.to.naive$Type=="Scientists"]<-"Estimate"
means.compare.to.naive$Group[means.compare.to.naive$Type!="Scientists"]<-"Non Estimate"
labeling<-c(
eafric = "Exp. Afr.-Am. Bias",
easian = "Exp. Asian-Am. Bias",
egend = "Exp. Gender Bias",
iafric = "Imp. Afr.-Am. Bias",
iasian = "Imp. Asian-Am. Bias",
ideoldem = "Democrat. Support",
ideolrep ="Republic. Support",
igend = "Imp. Gender Bias",
lifesat = "Life Satisfaction",
negaffect = "Negative Affect",
polar = "Polarization",
posaffect = "Positive Affect")
#plot
means.compare.to.naive %>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Forecasting Error - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
#subplots for presentation
#scientists
means.compare.to.naive %>%  subset(Type=="Scientists")%>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Forecasting Error - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
#scientists & lay crowd
means.compare.to.naive %>%  subset(Type=="Scientists"|Type=="Naive Crowd")%>%
ggplot(aes(x = response, y = domain, color = Type, shape=Type))+
geom_pointrange(aes(xmin=lower.CL, xmax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_vline(xintercept =1, linetype='dashed', color='red',14)+theme(legend.position="bottom")+scale_color_jama()+  labs(x="Forecasting Error - MASE (M +/- 95%CI)",shape="",color="")+scale_y_discrete(labels=labeling, name="")+facet_grid(~Wave)
# Chunk 10
#to examine difference in inaccuracy from benchmark vs. domain estimates from scientists in the LME, we can do the following:
#1. create ratio of  benchmark inaccuracy to forecasting inaccuracy -  score above 1 means forecast is more accurate compared to the benchmark
#2 run an intercept model, to see if intercept is sig different from 1
##Tournament 1 - phase1_exp
phase1_exp_wbench<-phase1_exp %>% left_join(pivot_wider(sim.w1 %>% select(domain,response, source),
names_from="source",values_from="response"))
phase1_exp_wbench$MASE_ratio1<- phase1_exp_wbench$'Benchmark 1'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$MASE_ratio2<- phase1_exp_wbench$'Benchmark 2'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$MASE_ratio3<- phase1_exp_wbench$'Benchmark 3'/phase1_exp_wbench$MASE1_w1
phase1_exp_wbench$domain <- factor(phase1_exp_wbench$domain,      # Reordering group factor levels
levels = c("ideolrep","ideoldem","polar",
"lifesat","negaffect","posaffect",
"iafric","iasian","igend",
"eafric","easian","egend" ))
#skewness test suggests that sqrt is the most reasonable transofmration across the three metrics (esp. the first one) hence we will use it.
(emmeans(lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
(emmeans(lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
(emmeans(lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
#get pvalues
test(emmeans(lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
test(emmeans(lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
test(emmeans(lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench), ~1, type="response"))
model.phase1.hist.mean.ratio<-  lmer(sqrt(MASE_ratio1)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.hist.mean.ratio, test.statistic = "F")
test(emmeans(model.phase1.hist.mean.ratio,~domain, type="response"))
plot.t1.hist.mean<-plot(emmeans(model.phase1.hist.mean.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Historical Mean")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="Tournament 1 (May 2020)")
model.phase1.randwalk.ratio<-  lmer(sqrt(MASE_ratio2)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.randwalk.ratio, test.statistic = "F")
test(emmeans(model.phase1.randwalk.ratio,~domain, type="response"))
plot.t1.randwalk<-plot(emmeans(model.phase1.randwalk.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Random Walk")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")
model.phase1.linreg.ratio<-  lmer(sqrt(MASE_ratio3)~domain+(1|team_name), data=phase1_exp_wbench)
Anova(model.phase1.linreg.ratio, test.statistic = "F")
test(emmeans(model.phase1.linreg.ratio,~domain, type="response"))
plot.t1.linreg<-plot(emmeans(model.phase1.linreg.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(labels=labeling, name="Linear Regression")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")
#Tournament 2
phase2_exp_wbench<-dat_phase2 %>% left_join(pivot_wider(sim.w2 %>% select(domain,response, source),
names_from="source",values_from="response"))
phase2_exp_wbench$domain <- factor(phase2_exp_wbench$domain,      # Reordering group factor levels
levels = c("ideolrep","ideoldem","polar",
"lifesat","negaffect","posaffect",
"iafric","iasian","igend",
"eafric","easian","egend" ))
phase2_exp_wbench$MASE_ratio1<- phase2_exp_wbench$'Benchmark 1'/phase2_exp_wbench$MASE1_w2
phase2_exp_wbench$MASE_ratio2<- phase2_exp_wbench$'Benchmark 2'/phase2_exp_wbench$MASE1_w2
phase2_exp_wbench$MASE_ratio3<- phase2_exp_wbench$'Benchmark 3'/phase2_exp_wbench$MASE1_w2
#here we use logs, because skewness suggests that sqrt is not enough and logs do a good job across all three markers
print(emmeans(lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
print(emmeans(lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
print(emmeans(lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
test(emmeans(lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench), ~1, type="response"))
model.phase2.hist.mean.ratio<-  lmer(log(MASE_ratio1)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.hist.mean.ratio, test.statistic = "F")
test(emmeans(model.phase2.hist.mean.ratio,~domain, type="response"))
plot.t2.hist.mean<-plot(emmeans(model.phase2.hist.mean.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="Tournament 2 (Nov 2020)")+theme(axis.text.y=element_blank())
model.phase2.randwalk.ratio<-  lmer(log(MASE_ratio2)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.randwalk.ratio, test.statistic = "F")
test(emmeans(model.phase2.randwalk.ratio,~domain, type="response"))
plot.t2.randwalk<-plot(emmeans(model.phase2.randwalk.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")+theme(axis.text.y=element_blank())
model.phase2.linreg.ratio<-  lmer(log(MASE_ratio3)~domain+(1|team_name), data=phase2_exp_wbench)
Anova(model.phase2.linreg.ratio, test.statistic = "F")
test(emmeans(model.phase2.linreg.ratio,~domain, type="response"))
plot.t2.linreg<-plot(emmeans(model.phase2.linreg.ratio,~domain, type="response"),comparisons=T, color="black")+scale_y_discrete(name="")+geom_vline(xintercept =1, linetype='dashed', color='black',14)+theme_minimal()+  labs(x="",shape="",color="", title="")+theme(axis.text.y=element_blank())
#combine all graphs
figs2<-ggarrange(plot.t1.hist.mean,plot.t2.hist.mean,
plot.t1.randwalk,plot.t2.randwalk,
plot.t1.linreg, plot.t2.linreg,  ncol=2, nrow=3,widths=c(1.3,1))
figs2
# Chunk 11
#analyses of phase 1  - MASE overall
#For models evaluating overall accuracy of the forecasted model, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain as predictors, with MASE scores nested within teams.
#first, what is the percentage using different method?
prop.table(table(phase1_exp$Method.code))
perc.by.domain.phase1<-phase1_exp %>%
group_by(domain,Method.code) %>%
summarise(n = n()) %>%
mutate(perc = round(n / sum(n)*100),2) %>%
ggplot(aes(x = "", y = perc, fill = Method.code)) +
geom_col(color = "black") +
geom_label(aes(label = perc),
color = "white",
position = position_stack(vjust = 0.5),
show.legend = FALSE) +scale_fill_jama()+labs(fill="")+
coord_polar(theta = "y")+theme_void()+facet_wrap(~domain, nrow = 4, labeller=labeller(domain=labels))+theme(legend.position="bottom")
perc.by.domain.phase1
#recorder levels of the domains
dat_long$domain <- factor(dat_long$domain,      # Reordering group factor levels
levels = c("egend","easian","eafric",
"igend","iasian","iafric",
"posaffect","negaffect","lifesat",
"polar","ideoldem","ideolrep"))
#next run models
model.phase1<-  lmer(log(MASE1_w1)~domain*Method.code+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1,type="III") #sig interaction!
summ(model.phase1, digits=4)
emmeans(model.phase1,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")
data.phase1.MASE<-as.data.frame(emmeans(model.phase1,pairwise ~Method.code|domain, type = "response", adjust = "none")$emmeans)
model.phase1.across.domains<-  lmer(log(MASE1_w1)~Method.code+domain+(1|ResponseId), data=subset(phase1,isExpert.factor=="Academic"))
car::Anova(model.phase1.across.domains,type="III", test.statistic="F")
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)
model.phase1.contrast<-  lmer(log(MASE1_w1)~method.contrast+domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast,type="III", test.statistic="F") #sig domain effect,  and sig interaction
summ(model.phase1.contrast, digits=4) #get effect size for the overall model
model.phase1.contrast.by.domain<-  lmer(log(MASE1_w1)~method.contrast*domain+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast.by.domain, type=3, test.statistic="F")
emmeans(model.phase1.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
write.csv(emmeans(model.phase1.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
$contrasts,"contrast1.csv")
# EXAMINE ACADEMICS DATA VS. NO DATA AND LAY PEOPLE
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1$method.contrast.layppl[phase1$Method.code=='Intuition/Theory']<-"Sci data-free"
phase1$method.contrast.layppl[phase1$Method.code=='Lay People']<-"lay people"
phase1$method.contrast.layppl[phase1$Method.code=='Data-Driven']<-"Sci data-incl."
phase1$method.contrast.layppl[phase1$Method.code=='Hybrid']<-"Sci data-incl."
model.phase1.contrast.lay<-  lmer(log(MASE1_w1)~method.contrast.layppl+(1|ResponseId), data=phase1)
car::Anova(model.phase1.contrast.lay,type="III") #sig domain effect,  and sig interaction
emmeans(model.phase1.contrast.lay,specs = trt.vs.ctrl ~method.contrast.layppl, adjust = "fdr",type="response" )
#significant difference between academics who used data and lay people, but not between academics who did not use data and lay peope
#arrange in descending order based on MASE w2 of academics
data.phase1.MASE$domain<-factor(data.phase1.MASE$domain,levels=c("ideolrep","negaffect","ideoldem","polar","iafric","lifesat","eafric","easian","egend","iasian","igend","posaffect"))
data.phase1.MASE %>%
ggplot(aes(x = domain, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase1.MASE.total %>%
ggplot(aes(x = Method.code, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
#phase 2
dat_phase2<-academic_only %>%filter(!(phase == 1 & revised == 1)) #just academics
#first, what is the percentage using different method?
prop.table(table(dat_phase2$Method.code))
table(phase2$Method.code)
perc.by.domain.phase2<-dat_phase2 %>%
group_by(domain,Method.code) %>%
summarise(n = n()) %>%
mutate(perc = round(n / sum(n)*100),2) %>%
ggplot(aes(x = "", y = perc, fill = Method.code)) +
geom_col(color = "black") +
geom_label(aes(label = perc),
color = "white",
position = position_stack(vjust = 0.5),
show.legend = FALSE) +scale_fill_jama()+labs(fill="")+
coord_polar(theta = "y")+theme_void()+facet_wrap(~domain, nrow = 4, labeller=labeller(domain=labels))+theme(legend.position="bottom")
#combine plots
cowplot::plot_grid(perc.by.domain.phase1,perc.by.domain.phase2,labels=c("1st Tournament","2nd Tournament"), label_size = 10,
align = "v")
#next run models
data.phase2.model<-  lmer(log(MASE1_w2)~domain*Method.code+(1|ResponseId), data=dat_phase2)
car::Anova(data.phase2.model,type="III") #sig interaction!
data.phase2.MASE<-as.data.frame(emmeans(data.phase2.model, pairwise~Method.code|domain, adjust = "none", type = "response")$emmeans) #backtransformed to the original scale
data.phase2.model.across.domains<-  lmer(log(MASE1_w2)~Method.code+domain+(1|ResponseId), data=dat_phase2)
car::Anova(data.phase2.model.across.domains,type="III", test.statistic="F") #sig interaction!
data.phase2.MASE.total<-as.data.frame(emmeans(data.phase2.model.across.domains,pairwise ~Method.code, type = "response", adjust = "none")$emmeans)
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
dat_phase2$method.contrast<-ifelse(dat_phase2$Method.code=='Intuition/Theory',0,1)
model.phase2.contrast<-  lmer(log(MASE1_w2)~method.contrast+domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast,type="III", test.statistic="F") #sig domain effect,  and sig interaction
summ(model.phase2.contrast, digits=4) #get effect size for the overall model
model.phase2.contrast.by.domain<-  lmer(log(MASE1_w2)~method.contrast*domain+(1|ResponseId), data=dat_phase2)
car::Anova(model.phase2.contrast.by.domain, type=3, test.statistic="F")
emmeans(model.phase2.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "fdr",type="response" )
write.csv(emmeans(model.phase2.contrast.by.domain,pairwise ~method.contrast|domain, adjust = "none",type="response" )
$contrasts,"contrast2.csv")
data.phase1.MASE.total<-as.data.frame(emmeans(model.phase1.across.domains,pairwise ~Method.code, type = "response", adjust = "none")$emmeans)
#arrange in descending order based on MASE w2 of academics
data.phase2.MASE.total$domain<-factor(data.phase2.MASE.total$domain,levels=c("ideolrep","negaffect","ideoldem","polar","iafric","lifesat","eafric","easian","egend","iasian","igend","posaffect"))
data.phase2.MASE %>%
ggplot(aes(x = domain, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase2.MASE.total %>%
ggplot(aes(x = Method.code, y = response, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+coord_flip()+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+  scale_x_discrete(labels=labeling, name="")+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
data.phase1.MASE.total$Wave<-"First Tournament (May 2020)"
data.phase2.MASE.total$Wave<-"Second Tournament (Nov 2020)"
#combine
means.compare.by.method<-bind_rows(data.phase1.MASE.total,data.phase2.MASE.total)
means.compare.by.method$Method[means.compare.by.method$Method.code=="Data-Driven"&
means.compare.by.method$Wave=="First Tournament (May 2020)"]<-"Data-Driven/n51%"
#arrange in descending order based on MASE w2 of academics
means.compare.by.method$Wave<-factor(means.compare.by.method$Wave,levels=c("First Tournament (May 2020)","Second Tournament (Nov 2020)"))
means.compare.by.method$Method<-c('Data-Driven\n51%','Hybrid\n7%','Intuition/\nTheory\n42%','Data-Driven\n53%','Hybrid\n8%','Intuition/\nTheory\n39%')
means.compare.by.method %>%
ggplot(aes(x = Method, y = response, color = Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14)+geom_hline(yintercept =1, linetype='dashed', color='red',14)+theme(legend.position="none")+scale_color_futurama()+  labs(y="MASE (M +/- 95%CI)",x="",shape="",color="")+ facet_wrap(~ Wave, scales = "free_x")
# Chunk 12
#count how many domains per person
phase1_exp<-phase1_exp %>%group_by(team_name) %>%  mutate(n_domains = n())
phase1_exp$Domain_Publications<-ifelse(phase1_exp$pub==1,1,ifelse(phase1_exp$pub==2,0,NA))
#count how many domains per person
dat_phase2<-dat_phase2 %>%group_by(team_name) %>%  mutate(n_domains = n())
dat_phase2$Domain_Publications<-ifelse(dat_phase2$pub==1,1,ifelse(dat_phase2$pub==2,0,NA))
subset1<- phase1_exp %>% ungroup() %>% select(MASE1_w1,domain,Method.code,ResponseId,team_name,covidcondyn,CounterFactual_Presence_Final,Method.complex,parameters_coded,n_domains,multi_dis.factor,team_discipline.coded,non_US,team_size.coded,team_gender,team_education,confidence,subexpert,Domain_Publications,previous_tournament.coded,TournamentStart) %>% mutate(inaccuracy = MASE1_w1,phase = "first")
subset2<- dat_phase2 %>% ungroup() %>% select(MASE1_w2,domain,Method.code,ResponseId,team_name,covidcondyn,CounterFactual_Presence_Final,Method.complex,parameters_coded,n_domains,multi_dis.factor,team_discipline.coded,non_US,team_size.coded,team_gender,team_education,confidence,subexpert,Domain_Publications,previous_tournament.coded,TournamentStart) %>% mutate(inaccuracy = MASE1_w2,phase = "second")
##compare effects by domain for each tournament
subset1.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=subset1)
car::Anova(subset1.model,type="III", test.statistic="F") #sig effect
emmeans(subset1.model,~domain, type="response")
subset2.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=subset2)
car::Anova(subset2.model,type="III", test.statistic="F") #sig effect
emmeans(subset2.model,~domain, type="response")
#combine
both.sets<-bind_rows(subset1,subset2)
both.sets$covidconditional<-ifelse(both.sets$covidcondyn==1,1,0)
both.sets$covidconditional[is.na(both.sets$covidconditional)]<-0
both.sets$Method.complex[is.na(both.sets$Method.complex)]<-1 #simple when no extra info is provided, because the rest {number of parameters et.) suggests no extra factors considered}
both.sets$multi_dis.factor[is.na(both.sets$multi_dis.factor)]<-"Single domain expertise" #(setting is NA to non multidisciplinary)
both.sets$team_discipline.coded[is.na(both.sets$team_discipline.coded)]<-5 #(setting is NA to other)
both.sets$team_discipline.datasci<-ifelse(both.sets$team_discipline.coded==3,1,0)
both.sets$team_discipline.SBsci<-ifelse(both.sets$team_discipline.coded==1,1,ifelse(both.sets$team_discipline.coded==2,1,0))
#add complexity
both.sets<-both.sets %>% left_join(complexity)
both.sets$sd_hist<-ifelse(both.sets$phase=="first",both.sets$sd_hist_w1,both.sets$sd_hist_w2)
both.sets$mad_hist<-ifelse(both.sets$phase=="first",both.sets$mad_hist_w1,both.sets$mad_hist_w2)
both.sets$perp_entropy_hist<-ifelse(both.sets$phase=="first",both.sets$perp_entropy_hist_w1,both.sets$perp_entropy_hist_w2)
both.sets$sd<-ifelse(both.sets$phase=="first",both.sets$sd_w1,both.sets$sd_w2)
both.sets$mad<-ifelse(both.sets$phase=="first",both.sets$mad_w1,both.sets$mad_w2)
both.sets$perp_entropy<-ifelse(both.sets$phase=="first",both.sets$perp_entropy_w1,both.sets$perp_entropy_w2)
#add domain differences in complexity between waves
both.sets$sd_hist_diff<-both.sets$sd_hist_w2-both.sets$sd_hist_w1
both.sets$mad_hist_diff<-both.sets$mad_hist_w2-both.sets$mad_hist_w1
both.sets$perp_entropy_hist_diff<-both.sets$perp_entropy_hist_w2-both.sets$perp_entropy_hist_w1
both.sets$sd_diff<-both.sets$sd_w2-both.sets$sd_w1
both.sets$mad_diff<-both.sets$mad_w2-both.sets$mad_w1
both.sets$perp_entropy_diff<-both.sets$perp_entropy_w2-both.sets$perp_entropy_w1
#analyze comparison of tournament 1 to tournament 2
both.sets.model<-  lmer(log(inaccuracy)~phase+(1|team_name), data=both.sets)
car::Anova(both.sets.model,type="III", test.statistic="F") #sig effect
emmeans(both.sets.model,~phase, type="response")
both.sets.model.by.domain<-  lmer(log(inaccuracy)~phase*domain+(1|team_name), data=both.sets)
car::Anova(both.sets.model.by.domain,type="III", test.statistic="F") #sig effect
emmeans(both.sets.model.by.domain,~phase|domain, type="response")
emmeans(both.sets.model.by.domain,pairwise~phase|domain, type="response")
t.comparison.effects<-as.data.frame(emmeans(both.sets.model.by.domain,pairwise~phase|domain, type="response")$emmeans)
t.comparison<-as.data.frame(emmeans(both.sets.model.by.domain,pairwise~phase|domain, type="response")$contrasts)
both.sets.model.cov<-  lmer(log(inaccuracy)~phase+domain+
n_domains+team_discipline.datasci+team_discipline.SBsci+multi_dis.factor+team_size.coded+team_gender+team_education+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(both.sets.model.cov,type="III", test.statistic="F") #sig effect
emmeans(both.sets.model.cov,~phase, type="response")
both.sets.domain.model<-  lmer(log(inaccuracy)~domain+(1|team_name), data=both.sets)
car::Anova(both.sets.domain.model,type="III", test.statistic="F") #sig effect
emmeans(both.sets.domain.model,pairwise~domain, type="response")
# Chunk 13
#get ranking of scores among academics in May and November
median.MASE.t1$phase<-"first"
median.MASE.t2$phase<-"second"
median.MASE.t1$Wave<-"First Tournament\nMay 2020"
median.MASE.t2$Wave<-"Second Tournament\nNov 2020"
median.ranks<-bind_rows(median.MASE.t1,median.MASE.t2)
median.ranks$Domain[median.ranks$domain=="eafric"]<-"Exp. Afr.-Am. Bias"
median.ranks$Domain[median.ranks$domain=="easian"]<-"Exp. Asian-Am. Bias"
median.ranks$Domain[median.ranks$domain=="egend"]<-"Exp. Gender Bias"
median.ranks$Domain[median.ranks$domain=="iafric"]<-"Imp. Afr.-Am. Bias"
median.ranks$Domain[median.ranks$domain=="iasian"]<-"Imp. Asian-Am. Bias"
median.ranks$Domain[median.ranks$domain=="ideoldem"]<-"Democrat. Support"
median.ranks$Domain[median.ranks$domain=="ideolrep"]<-"Republic. Support"
median.ranks$Domain[median.ranks$domain=="igend"]<-"Imp. Gender Bias"
median.ranks$Domain[median.ranks$domain=="lifesat"]<-"Life Satisfaction"
median.ranks$Domain[median.ranks$domain=="polar"]<-"Polarization"
median.ranks$Domain[median.ranks$domain=="negaffect"]<-"Negative Affect"
median.ranks$Domain[median.ranks$domain=="posaffect"]<-"Positive Affect"
median.ranks<-median.ranks %>% left_join(t.comparison.effects) %>% left_join(t.comparison %>% select(domain,ratio,t.ratio,p.value)) #add the sig testing from the tournament comparisons, incl ratio size and p-values
#NOTE: here we have median ranks per domain, but also the estimates scores from multi-level models accounting for multiple predictions by different scientist groups. Due to this dependence in the data, we use the latter estimates.
median.ranks$sig<-ifelse(median.ranks$p.value<.05,"eff","noeff")
median.ranks$MASE<-round(median.ranks$response,2) #two decimals
median.ranks$ranksize<-round(median.ranks$ratio,2) #two decimals
newggslopegraph(dataframe = median.ranks,
Times = Wave,
Measurement = MASE,
Grouping = Domain,LineThickness = 2,
WiderLabels=T,
Title = "Which domains are harder to predict?",TitleJustify = "center",
SubTitle = NULL,
Caption = "Ranking based on MASE scores per domain",
ThemeChoice="ipsum")+scale_color_d3(palette = "category20")+geom_line(aes(linetype=sig, color="black",alpha=1))
# Chunk 14: ranking in phase 1 and complexity
#covert to wide
median.ranks.wide<-median.ranks %>% select(domain:phase,MASE) %>%
pivot_wider(names_from="phase",values_from=c("MASE","MASE_med"))
rank_complex_wide<-median.ranks.wide%>%left_join(complexity)
#For complexity,we used SD and MAD. Additionally, I consider permutation_entropy, which is Ra substitution the Shannon entropy with a monoparametric entropy.
rank_complex_w1<-median.MASE.t1%>%left_join(complexity)
rank_complex_w2<-median.MASE.t2%>%left_join(complexity)
rank_complex<-median.ranks%>%left_join(complexity)
correlation::correlation(rank_complex%>%filter(phase=="first") %>%
select(MASE,sd_hist_w1,mad_hist_w1,perp_entropy_hist_w1,sd_w1,mad_w1,perp_entropy_w1), p_adjust="none", ranktransform=T)
correlation::correlation(rank_complex%>%filter(phase=="second") %>%
select(MASE,sd_hist_w2,mad_hist_w2,perp_entropy_hist_w2,sd_w2,mad_w2,perp_entropy_w2), p_adjust="none", ranktransform=T)
#add difference scores in complexity to the dataset
rank_complex$sd_hist_diff<-rank_complex$sd_hist_w2-rank_complex$sd_hist_w1
rank_complex$mad_hist_diff<-rank_complex$mad_hist_w2-rank_complex$mad_hist_w1
rank_complex$perp_entropy_hist_diff<-rank_complex$perp_entropy_hist_w2-rank_complex$perp_entropy_hist_w1
rank_complex$sd_diff<-rank_complex$sd_w2-rank_complex$sd_w1
rank_complex$mad_diff<-rank_complex$mad_w2-rank_complex$mad_w1
rank_complex$perp_entropy_diff<-rank_complex$perp_entropy_w2-rank_complex$perp_entropy_w1
rank_complex$wave<-ifelse(rank_complex$phase=="first",0,1)
domain.SD.change<-  lmer(MASE~wave*sd_hist_diff+(1|Domain), data=rank_complex)
car::Anova(domain.SD.change,type="III", test.statistic="F") #sig effect
emtrends(domain.SD.change,specs=~wave,var="sd_hist_diff") #
interactions::sim_slopes(domain.SD.change,pred="wave",modx="sd_hist_diff", digits=4)
#this interaction shows that when change in SD is high (domains become more variable at t2 compared to t1), there is no difference in inaccuracy
domain.MAD.change<-  lmer(MASE~wave*mad_hist_diff+(1|Domain), data=rank_complex)
car::Anova(domain.MAD.change,type="III", test.statistic="F") #sig effect
emtrends(domain.MAD.change,specs=~wave,var="mad_hist_diff") #
interactions::sim_slopes(domain.MAD.change,pred="wave",modx="mad_hist_diff", digits=4)
#this interaction shows that when change in MAD is high (domains become more variable at t2 compared to t1), there is no difference in inaccuracy between t1 and t2
##examine difference scores via corr
rank_complex_wide$sd_hist_diff<-rank_complex_wide$sd_hist_w2-rank_complex_wide$sd_hist_w1
rank_complex_wide$mad_hist_diff<-rank_complex_wide$mad_hist_w2-rank_complex_wide$mad_hist_w1
rank_complex_wide$perp_entropy_hist_diff<-rank_complex_wide$perp_entropy_hist_w2-rank_complex_wide$perp_entropy_hist_w1
rank_complex_wide$sd_diff<-rank_complex_wide$sd_w2-rank_complex_wide$sd_w1
rank_complex_wide$mad_diff<-rank_complex_wide$mad_w2-rank_complex_wide$mad_w1
rank_complex_wide$perp_entropy_diff<-rank_complex_wide$perp_entropy_w2-rank_complex_wide$perp_entropy_w1
rank_complex_wide$MASE_diff<-rank_complex_wide$MASE_second-rank_complex_wide$MASE_first
rank_complex_wide$MASE_med_diff<-rank_complex_wide$MASE_med_second-rank_complex_wide$MASE_med_first
correlation::correlation(rank_complex_wide%>%
select(MASE_diff,MASE_med_diff,sd_hist_diff,mad_hist_diff,perp_entropy_hist_diff,sd_diff,mad_diff,perp_entropy_diff), p_adjust="none", ranktransform=T)
#added info about change in variability correlating to changes in accuracy.
# Chunk 15
#turn to long format (firstmonths and lastmonths MASE data)
data.t1.t2.exp.long<- phase1_exp %>% ungroup() %>%pivot_longer(cols=c("MASE1_w1_firstmonths","MASE1_w1_lastmonths"), names_to="Time",values_to="MASE")
model.t1.t2<-lmer(log(MASE)~Time+domain+(1|team_name), data=data.t1.t2.exp.long)
summary(model.t1.t2)
car::Anova(model.t1.t2,type="III",test.statistic="F") #sig interaction!
emmeans(model.t1.t2,specs = trt.vs.ctrl ~Time|Method.code,  type="response",adjust = "fdr")
#compare last months from the T1 to T2
##turn to long format (lastmonths T1 an t2 MASE data)
subset1.lastsix<- phase1_exp %>% ungroup() %>% select(MASE1_w1_lastmonths,domain,Method.code,ResponseId,team_name,covidcondyn,CounterFactual_Presence_Final,Method.complex,parameters_coded,n_domains,multi_dis.factor,team_discipline.coded,team_size.coded,team_gender,team_education,confidence,subexpert,Domain_Publications,previous_tournament.coded, TournamentStart) %>% mutate(inaccuracy = MASE1_w1_lastmonths,phase = "first")
#combine
both.sets.lastsix<-bind_rows(subset1.lastsix,subset2)
model.t1.t2.lastsix<-lmer(log(inaccuracy)~phase+domain+(1|team_name), data=subset(both.sets.lastsix,TournamentStart=="May"))
car::Anova(model.t1.t2.lastsix,type="III",test.statistic="F")
emmeans(model.t1.t2.lastsix,specs = trt.vs.ctrl ~phase,  type="response",adjust = "fdr")
names(rank_complex)
correlation::correlation(rank_complex%>%filter(phase=="first") %>%
select(MASE_med,sd_hist_w1,mad_hist_w1,perp_entropy_hist_w1,sd_w1,mad_w1,perp_entropy_w1), p_adjust="none", ranktransform=T)
correlation::correlation(rank_complex%>%filter(phase=="second") %>%
select(MASE_med,sd_hist_w2,mad_hist_w2,perp_entropy_hist_w2,sd_w2,mad_w2,perp_entropy_w2), p_adjust="none", ranktransform=T)
both.sets$inaccuracy_log<-log(both.sets$inaccuracy)
both.sets$Multidisciplinary<-ifelse(both.sets$multi_dis.factor=="Single domain expertise",0,1)
both.sets$covidconditional[is.na(both.sets$covidconditional)]<-0
both.sets$Method.complex[is.na(both.sets$Method.complex)]<-1 #simple when no extra info is provided, because the rest {number of parameters et.) suggests no extra factors considered}
both.sets$multi_dis.factor[is.na(both.sets$multi_dis.factor)]<-"Single domain expertise" #(setting is NA to non multidisciplinary)
###analyses with domain
model.bothTournaments.COVs<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs,type="III",test.statistic="F")
summ(model.bothTournaments.COVs, conf.method="boot", digits=3, center=T)
model.bothTournaments.no.COVs<-lmer(inaccuracy_log~domain+(1|team_name), data=both.sets)
summ(model.bothTournaments.no.COVs, conf.method="boot", digits=3, center=T)
#xtra analysis with US residents on the team - not included to avoi doverfitting.
model.bothTournaments.COVs.incl.US<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+non_US+team_size.coded+team_education+confidence+subexpert+Domain_Publications+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs.incl.US,type="III",test.statistic="F")
#no effect of US residency
#xtra analysis without objective expertise to examine partial Rsq
model.bothTournaments.COVs.no.obj.expertise<-lmer(inaccuracy_log~domain+parameters_coded+Method.complex+covidconditional+CounterFactual_Presence_Final+n_domains+team_discipline.datasci+team_discipline.SBsci+Multidisciplinary+team_size.coded+team_education+confidence+subexpert+previous_tournament.coded+(1|team_name), data=both.sets)
car::Anova(model.bothTournaments.COVs.no.obj.expertise,type="III",test.statistic="F")
summ(model.bothTournaments.COVs.no.obj.expertise, conf.method="boot", digits=3, center=T)
0.314-0.304
#Rsq - 0.304
anova(model.bothTournaments.COVs,model.bothTournaments.COVs.no.obj.expertise)
summ(model.bothTournaments.COVs, conf.method="boot", digits=4, center=T)
summ(model.bothTournaments.COVs, conf.method="boot", digits=5, center=T)
summ(model.bothTournaments.COVs.no.obj.expertise, conf.method="boot", digits=5, center=T)
0.31437-0.30449
>>>>>>> Stashed changes

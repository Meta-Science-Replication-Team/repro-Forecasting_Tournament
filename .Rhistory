dplyr::summarise(
numberOfTeams = length(unique(team_name))
)
# Number of teams total
team_num_total <- length(unique(academic_only$team_name))
# 121 teams total, 86 teams participated during phase 1 (88th team is NA because I didn't filter out lay sample and 87th team indicated their predictions were for another country), 72 during phase 2
# Filter so that only one row per team is retained
unique_teams <- academic_only[!duplicated(academic_only$team_name),]
describe(unique_teams$team_size.coded)
#    vars   n mean   sd median trimmed mad min max range skew kurtosis   se
# X1    1 105 1.66 1.16      1     1.4   0   1   7     6 2.04     4.32 0.11
# team size ranged from 1-7, n = 100, Md = 1, M = 1.67
# 1 was the most common team size (65%)
# Summarize spread of teams size (does not exclude NAs)
as.data.frame(table(unique_teams$team_size.coded))
#   team_size.coded  N               Percent
# 1         1 70 0.5737704918032786594
# 2         2 16 0.1311475409836065642
# 3         3 10 0.0819672131147540922
# 4         4  5 0.0409836065573770461
# 5         5  3 0.0245901639344262291
# 6         7  1 0.0081967213114754103
# 7        NA 17 0.1393442622950819554
# Filter data set by project wave
phase1_team <- filter(unique_teams, team_name %in% phase1$team_name)
# distribution of team size for phase 1
as.data.frame(table(phase1_team$team_size.coded))
#   team_size.coded  N              Percent
# 1         1 48 0.551724137931034475
# 2         2 12 0.137931034482758619
# 3         3  5 0.057471264367816091
# 4         4  4 0.045977011494252873
# 5         5  2 0.022988505747126436
# 6         7  1 0.011494252873563218
# 7        NA 15 0.172413793103448287
phase2_team <- filter(unique_teams, team_name %in% phase2$team_name)
# distribution of team size for phase 2
as.data.frame(table(phase2_team$team_size.coded))
# Number of predictions below/above RMSE cutoff
# overall
as.data.frame(table(phase1_exp$RMSE_cutoff_Naive_linear.factor))
#   RMSE_cutoff.factor     N
#
# 1 below cutoff          109 - 30%
# 2 above cutoff         251  - 70%
# 70% of predictions were above the RMSE cutoff
# Per domain
naive_RMSE_domain <- phase1_exp %>% group_by(domain, RMSE_cutoff_Naive_linear.factor) %>%
dplyr::summarise(
N = length(RMSE_cutoff_Naive_linear.factor)
)
naive_RMSE_domain$Percent <- NA
for (i in 1:nrow(naive_RMSE_domain)) {
filter <- filter(phase1_exp, domain == naive_RMSE_domain$domain[i])
naive_RMSE_domain$Percent[i] <- naive_RMSE_domain$N[i] / nrow(filter)
}
# Implicit Asian bias, explicit African American, and positive affect were all 100% above the cutoff
# More than 60% of predictions for implicit gender, ideology-republican, and ideology-democrat were below the cutoff
# look at multi-disciplinarity
multidisciplinarity <- phase1_exp %>% group_by(is_multidisciplinary) %>%
dplyr::summarise(
N = length(is_multidisciplinary),
Percent = N / nrow(phase1_exp)
)
#   is_multidisciplinary     N Percent
#
# 1                    0   301  0.836
# 2                    1    20  0.0556
# 3                   NA    39  0.108
# Chunk 10: Prolific Descriptives
# List of descriptives for prolific sample
# filter sample to only include unflagged Prolific responses
dat_lay_demo <- subset(dat, isExpert == 0 & flag_lay_response == 0)
# time spent on upload task
time_spent_desc_up <- describe(dat_lay_demo$time_upload)
#    vars    n   mean     sd median trimmed   mad min     max   range skew kurtosis   se
# X1    1 2226 126.69 200.94   75.1   87.48 68.64   0 3434.49 3434.49 6.47    75.26 4.26
age_stats <- describe(dat_lay_demo$Age)
#    vars    n  mean    sd median trimmed mad min max range skew kurtosis   se
# X1    1 2200 29.94 10.18     28    28.5 8.9  18  78    60 1.33     1.95 0.22
#Education
prolific_edu <- dat_lay_demo %>% group_by(education.factor) %>%
dplyr::summarise(
N = length(education.factor),
Percent =  N / nrow(dat_lay_demo)
)
as.data.frame(table(dat_lay_demo$education.factor))
#   education.factor                 N Percent
#
# 1 less than highschool             5 0.00340
# 2 high school                    114 0.0776
# 3 some college                   341 0.232
# 4 Vocation or technical school    59 0.0401
# 5 Bachelor's                     582 0.396
# 6 Master's                       226 0.154
# 7 Doctorate                       24 0.0163
# 8 Professional degree             41 0.0279
# 9 NA                              78 0.0531
# Ethnicity
prolific_eth <- dat_lay_demo %>% group_by(Ethnicity.factor) %>%
dplyr::summarise(
N = length(Ethnicity.factor),
Percent =  N / nrow(dat_lay_demo)
)
as.data.frame(table(dat_lay_demo$Ethnicity.factor))
#    Ethnicity.factor      N Percent
#
#  1 Aboriginal/Native    10 0.00680
#  2 Asian               237 0.161
#  3 Black               131 0.0891
#  4 White               828 0.563
#  5 Middle Eastern       10 0.00680
#  6 Hispanic            103 0.0701
#  7 East Indian          11 0.00748
#  8 Mixed Race           48 0.0327
#  9 Other/Not Listed     11 0.00748
# 10 NA                   81 0.0551
# Religion
prolific_rel <- dat_lay_demo %>% group_by(Religion.factor) %>%
dplyr::summarise(
N = length(Religion.factor),
Percent =  N / nrow(dat_lay_demo)
)
#    Religion.factor            N  Percent
#
#  1 Buddhist                  29 0.0197
#  2 Christian - Catholic     199 0.135
#  3 Christian - Protestant   214 0.146
#  4 Christian - Other        131 0.0891
#  5 Hindu                     27 0.0184
#  6 Jewish                    36 0.0245
#  7 Muslim                    57 0.0388
#  8 Sikh                       2 0.00136
#  9 Other                     57 0.0388
# 10 Non-Religious            638 0.434
# 11 NA                        80 0.0544
# Politics
prolific_pol <- dat_lay_demo %>% group_by(Politics_1) %>%
dplyr::summarise(
N = length(Politics_1),
Percent =  N / nrow(dat_lay_demo)
)
#   Politics_1     N Percent
#
# 1          1   343  0.233
# 2          2   313  0.213
# 3          3   192  0.131
# 4          4   300  0.204
# 5          5   128  0.0871
# 6          6    84  0.0571
# 7          7    32  0.0218
# 8         NA    78  0.0531
# Residential Area
prolific_res <- dat_lay_demo %>% group_by(Residential.Area.factor) %>%
dplyr::summarise(
N = length(Residential.Area.factor),
Percent =  N / nrow(dat_lay_demo)
)
#   Residential.Area.factor     N Percent
#
# 1 Urban                     452  0.307
# 2 Suburban                  791  0.538
# 3 Rural                     147  0.1
# 4 NA                         80  0.0544
# Income
prolific_inc <- dat_lay_demo %>% group_by(Income.factor) %>%
dplyr::summarise(
N = length(Income.factor),
Percent =  N / nrow(dat_lay_demo)
)
#   Income.factor           N Percent
#
# 1 Under $15,000          92  0.0626
# 2 $15,001 - $25,000     106  0.0721
# 3 $25,001 - $35,000     129  0.0878
# 4 $35,001 - $50,000     179  0.122
# 5 $50,001 - $75,000     292  0.199
# 6 $75,001 - $100,000    227  0.154
# 7 $100,001 - $150,000   189  0.129
# 8 Over $150,000         165  0.112
# 9 NA                     91  0.0619
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
#datasets that are filtered by phase (1 = May, 2 = November)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)
# dataset that only includes academic predictions
academic_only <- filter(dat, isExpert == 1)
#####download of phase 1 and 2 files########################
t1.academ.sorted<-phase1_exp %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1)
View(t1.academ.sorted)
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1) %>%
group_by(domain) %>% summarise(across(where(is.numeric), mean)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="average non-academic")
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1) %>%
group_by(domain) %>% summarise(across(where(is.numeric), median)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="median non-academic")
View(t1.nonacadem.av.sorted)
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1) %>%
group_by(domain) %>% summarise(across(where(is.numeric), mean)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="average non-academic")
View(t1.nonacadem.av.sorted)
t1.scores<-rbind(t1.academ.sorted,t1.nonacadem.av.sorted)
write.csv(t1.scores,"wave1.scores.csv")
t2.academ.sorted<-phase2_exp %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% select(team_name,domain,Month.7:Month.12,mean_abs_error_w2,MASE1_w2)
View(t2.academ.sorted)
View(t1.nonacadem.av.sorted)
View(t1.academ.sorted)
View(t2.academ.sorted)
#PHASE 1
#do by method (among experts now)
#get ground truth markers (subset)
objective<-as.data.frame(subset(dat_long,phase == 1 & !is.na(Method.code)& Method.code=="Ground Truth"))
dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth") %>%
ggplot(aes(x = Month, y = value, colour = Method.code, fill=Method.code))+
geom_smooth(aes(x = Month, y = value, colour = Method.code, fill=Method.code),method = "loess") +
facet_wrap(vars(domain), scales = "free", nrow = 3)+theme_minimal(base_size = 14) +
geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)")
#without the naive benchmarks
dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw") %>%
ggplot(aes(x = Month, y = value, colour = Method.code, fill=Method.code))+
geom_smooth(aes(x = Month, y = value, colour = Method.code, fill=Method.code),method = "loess") +
facet_wrap(vars(domain), scales = "free", nrow = 3)+theme_minimal(base_size = 14) +
geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)")
dat_long_phase1<-dat_long %>%subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw")
dat_long_phase1$Method.code <- relevel(factor(dat_long_phase1$Method.code), "Lay People") #use lay people as a reference group
dat_long_phase1$Month0<-dat_long_phase1$Month-1
model.long.phase1<-  lmer(value.dif~domain*Method.code*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #sig effect of domain, method, Month, and domain * method
summ(model.long.phase1, digits=4, center=T)
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain, adjust = "none") #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain|Month0, adjust = "none", at=list(Month0=c(0,5,11))) #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric
emmeans(model.long.phase1,pairwise ~domain*Month0|Method.code, adjust = "none") #overall month (half a year estimate)
emmeans(model.long.phase1,pairwise ~domain|Method.code, adjust = "none") #overall month (half a year estimate)
#get scores for analyses
model.long.phase1<-  lmer(value.dif~domain*Method.code*as.factor(Month0)+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #sig effect of domain, method, Month, and domain * method
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none")$emmeans) #overall month (half a year estimate)
model.long.phase1<-  lmer(value.dif~domain*Method.code*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #sig effect of domain, method, Month, and domain * method
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=asymp.LCL, ymax=asymp.UCL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
pd <- position_dodge(0.7) # move them .07 to the left and right
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=asymp.LCL, ymax=asymp.UCL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
data.long.phase1.abs.dev
emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none")
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none",pbkrtest.limit = 21458)$emmeans) #overall month (half a year estimate)
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none", lmer.df = "satterthwaite")$emmeans) #overall month (half a year estimate)
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none", lmer.df = "satterthwaite", lmerTest.limit = 21458)$emmeans) #overall month (half a year estimate)
data.long.phase1.abs.dev
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)
options(max.print = 20000, scipen = 1000)
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
data.long.phase1.abs.dev
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
#datasets that are filtered by phase (1 = May, 2 = November)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)
# dataset that only includes academic predictions
academic_only <- filter(dat, isExpert == 1)
#####download of phase 1 and 2 files########################
t1.academ.sorted<-phase1_exp %>%
arrange(domain,MASE1_w1) %>%group_by(domain) %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1)
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1) %>%
group_by(domain) %>% summarise(across(where(is.numeric), mean)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="average non-academic")
t1.nonacadem.av.sorted<-phase1 %>% filter(isExpert.factor == 'Prolific') %>% select(team_name,domain,Month.1:Month.12,mean_abs_error_w1,MASE1_w1) %>%
group_by(domain) %>% summarise(across(where(is.numeric), median)) %>% arrange(domain,MASE1_w1) %>% mutate(team_name="median non-academic")
t1.scores<-rbind(t1.academ.sorted,t1.nonacadem.av.sorted)
write.csv(t1.scores,"wave1.scores.csv")
t2.academ.sorted<-phase2_exp %>%
arrange(domain,MASE1_w2) %>%group_by(domain) %>% select(team_name,domain,Month.7:Month.12,mean_abs_error_w2,MASE1_w2)
write.csv(t2.academ.sorted,"wave2.scores.csv")
pd <- position_dodge(0.7) # move them .07 to the left and right
#PHASE 1
#do by method (among experts now)
#get ground truth markers (subset)
objective<-as.data.frame(subset(dat_long,phase == 1 & !is.na(Method.code)& Method.code=="Ground Truth"))
dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth") %>%
ggplot(aes(x = Month, y = value, colour = Method.code, fill=Method.code))+
geom_smooth(aes(x = Month, y = value, colour = Method.code, fill=Method.code),method = "loess") +
facet_wrap(vars(domain), scales = "free", nrow = 3)+theme_minimal(base_size = 14) +
geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)")
#without the naive benchmarks
dat_long %>% subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw") %>%
ggplot(aes(x = Month, y = value, colour = Method.code, fill=Method.code))+
geom_smooth(aes(x = Month, y = value, colour = Method.code, fill=Method.code),method = "loess") +
facet_wrap(vars(domain), scales = "free", nrow = 3)+theme_minimal(base_size = 14) +
geom_smooth(data=objective,se=F) + #here we add the ground truth markers without confidence band
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Estimate (M +/- 95%CI)")
#get subset for analyses, focusing on value.dif column i -  absolute percent deviation for each predicted Month
#For models evaluating accuracy of individual time points, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain and time points as predictors, with absolute percent deviation scores nested within teams.
dat_long_phase1<-dat_long %>%subset(phase == 1 & !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw")
dat_long_phase1$Method.code <- relevel(factor(dat_long_phase1$Method.code), "Lay People") #use lay people as a reference group
dat_long_phase1$Month0<-dat_long_phase1$Month-1
#######JUST PLOT _ ==>ELEGANT BUT ERRORS!
#dat_long_phase1 %>% ggplot(aes(x = as.factor(Month), y = value.dif,colour = Method.code, fill=Method.code))+
#   stat_summary(fun.data="mean_cl_boot",  position=pd)+
#    facet_wrap(vars(domain), scales = "free", nrow = 4)+theme_minimal(base_size = 14) +
#   theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
#  labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
# THIS METHOD ASSUMES INDEPENDENCE OF RESPONSES!!!
model.long.phase1<-  lmer(value.dif~domain*Method.code*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #sig effect of domain, method, Month, and domain * method
summ(model.long.phase1, digits=4) #to get R2
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain, adjust = "none") #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric, easian (marg for iasian)
emmeans(model.long.phase1,specs = trt.vs.ctrl ~Method.code|domain|Month0, adjust = "none", at=list(Month0=c(0,5,11))) #overall month (half a year estimate), contrast to lay people. Lay ppl sig worse for eafric
emmeans(model.long.phase1,pairwise ~domain|Method.code, adjust = "none") #overall differences by domain.
#get scores for analyses
model.long.phase1<-  lmer(value.dif~domain*Method.code*as.factor(Month0)+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1,type="III") #sig effect of domain, method, Month, and domain * method
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none", lmer.df = "satterthwaite", lmerTest.limit = 21458)$emmeans) #overall month (half a year estimate), use satterthaite (a bit faster, though still fairly sloow)
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
data.long.phase1.abs.dev<-as.data.frame(emmeans(model.long.phase1,pairwise ~Method.code|domain|as.factor(Month0), adjust = "none")$emmeans) #overall month (half a year estimate), use satterthaite (a bit faster, though still fairly sloow)
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
data.long.phase1.abs.dev
data.long.phase1.abs.dev %>%
ggplot(aes(x = Month0, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=asymp.LCL, ymax=asymp.UCL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+ facet_wrap(vars(domain), scales = "free", nrow = 4)+
labs(colour = "Sample",fill="Sample", x="Time (in months)",y="Absolute Percentage Deviation (M +/- 95%CI)")
phase1$Method.code <- relevel(factor(phase1$Method.code), "Lay People") #use lay people as a reference group
#analyses of phase 1  - MASE overall
#For models evaluating overall accuracy of the forecasted model, we will use forecasting type (purely theoretical, purely data-driven and hybrid models), forecasting domain as predictors, with MASE scores nested within teams.
model.phase1<-  lmer(MASE1_w1~domain*Method.code+(1|ResponseId), data=phase1)
car::Anova(model.phase1,type="III") #no interaction, so just look at main effects
summ(model.phase1, digits=4)
emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")
emmeans(model.phase1,trt.vs.ctrl ~Method.code|domain, adjust = "none") #lay vs. rest
data.phase1.MASE<-as.data.frame(emmeans(model.phase1,pairwise ~Method.code|domain, adjust = "none")$emmeans)
data.phase1.MASE %>%
ggplot(aes(x = domain, y = emmean, colour = Method.code, fill=Method.code))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
#get scores for visualizations
phase1.means<-as.data.frame(emmeans(model.phase1,pairwise ~domain|Method.code, adjust = "none")$emmeans)
# reorder and get the order variable to maintain facet-specific orders (otherwise it get screwy)
phase1.means <- phase1.means %>%
# 1. Remove grouping
ungroup() %>%
# 2. Arrange by
#   i.  facet group
#   ii. bar height
arrange(Method.code, emmean) %>%
# 3. Add order column of row numbers
mutate(order = row_number())
#lollipop chart
phase1.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +
geom_point(size=3) +
geom_segment(aes(x=order,
xend=order,
y=0,
yend=emmean)) +facet_wrap(vars(Method.code), scales = "free")+
scale_x_continuous(   # Add categories to axis
breaks = phase1.means$order,
labels = phase1.means$domain)+theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE")
#errorbar charts, with scores ordered
phase1.means %>% ggplot(aes(x=order, y=emmean, color=Method.code)) +
geom_point(size=3) +
geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL))+
facet_wrap(vars(Method.code), scales = "free", nrow=4)+theme_minimal() +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+theme(legend.position="none")+
scale_x_continuous(   # Add categories to axis
breaks = phase1.means$order,
labels = phase1.means$domain,expand = c(0,0))+
scale_color_aaas()+ labs(colour = "Method",x="",y="Average MASE +/- 95% CI")
## EXAMINE ONLY ACADEMICS, USING CONTRAST OF THEORY vs. DATA.HYBRID
phase1_exp$method.contrast<-ifelse(phase1_exp$Method.code=='Intuition/Theory',0,1)
model.phase1.contrast<-  lmer(MASE1_w1~domain*method.contrast+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.contrast,type="III") #sig domain effect, marginal contrast and sig interaction
summ(model.phase1.contrast, digits=4)
emmeans(model.phase1.contrast,pairwise ~method.contrast|domain, adjust = "none")
View(phase1_exp)
## EXAMINE EFFECTS OF UPDATING FOR PHASE I PREDICTIONS AMONG ACADEMICS
phase1_exp$updated<-ifelse(phase1_exp$revised==1,"update","no update")
model.phase1.update<-  lmer(MASE1_w1~domain*updated+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.update,type="III") #no interaction, just a sig effect of domain
emmeans(model.phase1.update,pairwise ~updated|domain, adjust = "none") #nonsig
data.phase1.update<-as.data.frame(emmeans(model.phase1.update,pairwise ~updated|domain, adjust = "none")$emmeans) #nonsig
#visualize
data.phase1.update %>%
ggplot(aes(x = domain, y = emmean, colour = updated, fill=updated))+
geom_pointrange(aes(ymin=lower.CL, ymax=upper.CL), position=pd)+  theme_minimal(base_size = 14) +geom_hline(yintercept =1, linetype='dashed', color='red', 14)+
theme(legend.position="bottom") +scale_color_d3()+scale_fill_d3()+
labs(colour = "",fill="", x="",y="MASE (M +/- 95%CI)")
table(phase1_exp$Method.code)
dat.phase1<-dat %>% subset(phase == 1 & !is.na(isExpert.factor)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw")
table(dat.phase1_exp$Method.code)
table(dat.phase1$Method.code)
### overall MASE
#### first, confidence
model.phase1.conf<-  lmer(MASE1_w1~domain*confidence+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.conf,type="III") #no interaction, and no main effects of confidence
summ(model.phase1.conf, digits=4, center=T)
emtrends(model.phase1.conf,specs=pairwise~domain,var="confidence") #confidence plays a role for ideology republicans - the more confident the LOWER the mase scores and for LIFE SATISFACTION - the MORE confident the MORE error
##### second, team type - just academics
phase1_exp$teamS<-as.factor(ifelse(phase1_exp$team_size>=6,3,ifelse(phase1_exp$team_size<6&phase1_exp$team_size>1,2,ifelse(phase1_exp$team_size==1,1,NA))))
#####just count
model.phase1.team<-  lmer(MASE1_w1~domain*team_size+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team,type="III") #sig interaction between domain and team size
emtrends(model.phase1.team,specs=pairwise~domain,var="team_size") #for ideology rep and life satisfaction, larger team is linked to lower accuracy
#####apriori defined groups
model.phase1.team3<-  lmer(MASE1_w1~domain*teamS+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.team3,type="III") #no interaction between domain and team size
summ(model.phase1.team3, digits=4, center=T)
emmeans(model.phase1.team3,pairwise ~teamS|domain, adjust = "none") #nonsig
#### third, multidisciplinarity of the teams - just academics
model.phase1.multidis.team<-  lmer(MASE1_w1~domain*is_multidisciplinary+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.multidis.team,type="III") #interdisciplinary did not matter
emmeans(model.phase1.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #nonsig
#### first, confidence
model.long.phase1.conf<-  lmer(value.dif~domain*confidence*Month0+(1|ResponseId), data=subset(dat_long_phase1, isExpert.factor == 'Academic'))
car::Anova(model.long.phase1.conf,type="III") #sig interaction between domain and confidence, also a marginal 3 way - domai x confidence x month
summ(model.long.phase1.conf, digits=4, center=T) #the more confidence, the greater the error!
emtrends(model.long.phase1.conf,specs=pairwise~domain*Month0,var="confidence") #confidence does  play a role for explicit bias (african american): high confidence LESS error, east asian bias - higher confidence means MORE error, ideology reps (high confidence lESS error), negative affect: higher confidence less error). But not for other domains.
names(phase1_exp)
emtrends(model.long.phase1.conf,specs=pairwise~domain*Month0,var="confidence") #confidence does  play a role for explicit bias (african american): high confidence LESS error, east asian bias - higher confidence means MORE error, ideology reps (high confidence lESS error), negative affect: higher confidence less error). But not for other domains.
emtrends(model.long.phase1.conf,specs=pairwise~domain,var="confidence") #confidence does  play a role for explicit bias (african american): high confidence LESS error, east asian bias - higher confidence means MORE error, ideology reps (high confidence lESS error), negative affect: higher confidence less error). But not for other domains.
emtrends(model.long.phase1.conf,~Month0|domain,var="confidence", at=list(Month0=c(0,5,11))) #
##### second, team type - just academics
dat_long_phase1$teamS<-as.factor(ifelse(dat_long_phase1$team_size>=6,3,ifelse(dat_long_phase1$team_size<6&dat_long_phase1$team_size>1,2,ifelse(dat_long_phase1$team_size==1,1,NA))))
#####just count
model.long.phase1.team<-  lmer(value.dif~domain*team_size*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1.team,type="III") #sig interaction between domain and team size, and domain and month
emtrends(model.long.phase1.team,specs=pairwise~domain,var="team_size") #larger team size linked to less bias for east asian explicit bias, but not any other domain
#####apriori defined groups
model.long.phase1.team3<-  lmer(value.dif~domain*teamS*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1.team3,type="III") #sig interaction between domain and team size, and marginal main effect of team size
summ(model.long.phase1.team3, digits=4, center=T) #marginal contrast between single vs. 3 ppl.
emmeans(model.long.phase1.team3, pairwise~teamS|domain*Month0, adjust = "none",at=list(Month0=c(0,5,11))) #implicit and explicit asian bias - larger team is less inaaccurate (but note reversal for explicit african american bias.)
emmeans(model.long.phase1.team3, pairwise~teamS|domain, adjust = "none")) #implicit and explicit asian bias - larger team is less inaaccurate (but note reversal for explicit african american bias.)
emmeans(model.long.phase1.team3, pairwise~teamS|domain, adjust = "none") #implicit and explicit asian bias - larger team is less inaaccurate (but note reversal for explicit african american bias.)
model.long.phase1.multidis.team<-  lmer(value.dif~domain*is_multidisciplinary*Month0+(1|ResponseId), data=dat_long_phase1)
car::Anova(model.long.phase1.multidis.team,type="III") #interdisciplinary matters for interaction.
summ(model.long.phase1.multidis.team, digits=4, center=T)
emmeans(model.long.phase1.multidis.team,pairwise ~is_multidisciplinary|domain, adjust = "none") #for e asian bias, more interdisciplionary is better at M1,and M12,
##CONDITIONALS - where they right for wrong reasons?
#### first, MASE
model.phase1.covid<-  lmer(MASE1_w1~domain*MASE1_covid+(1|ResponseId), data=phase1_exp)
car::Anova(model.phase1.covid,type="III") #
summ(model.phase1.covid, digits=4, center=T)
emtrends(model.phase1.covid,specs=pairwise~domain,var="MASE1_covid") #
##CONDITIONALS - where they right for wrong reasons?
#### first, MASE
model.phase1.covid<-  lmer(MASE1_w1~domain*MASE1_covid+(1|ResponseId), data=phase1)
car::Anova(model.phase1.covid,type="III") #
summ(model.phase1.covid, digits=4, center=T)
emtrends(model.phase1.covid,specs=pairwise~domain,var="MASE1_covid") #
names(phase1_exp)
table(phase1_exp$covidcondyn)
table(phase1_exp$pub)
table(phase1_exp$pub,phase1_exp$domain)

Method.coded = 7,
phase = 2
)
}
# [1] "lifesat"   "posaffect" "negaffect" "ideoldem"  "ideolrep"  "polar"     "iasian"    "easian"    "iafric"    "eafric"    "igend" #[12] "egend"
# Chunk 35: Correct ideoldem and ideolrep MASE - Phase 2
# correcting ideoldem and ideolrep forecasts because of the missing data point (Jan 2021) in the ground truth data.
# Due to the missing data point, the uneven number of predictions vs ground truth were resulting in NAs for MASE scores
# As a result, we are recalculating accuracy scores, ignoring forecasts submitted for Jan 2011 so that both ground truth and predictions contain 11 data points to calculate MASE
# get list of relevant rows that submitted predictions for ideology domains
rows_ideol <- which((dat$domain == "ideoldem" | dat$domain == "ideolrep"))
# for each relevant row,
for (i in rows_ideol) {
# Avoid generating accuracy scores for ground truth values
if (dat$Method.coded[i] != 5 | is.na(dat$Method.coded[i])) {
domain <- dat$domain[i]
# pull values for all months except month 9 (Jan 2021)
val_w2 <- c(
dat$Month.7[i],
dat$Month.8[i],
dat$Month.10[i],
dat$Month.11[i],
dat$Month.12[i])
# Pull ground truth data for predicted months minus Jan 2021
hist_w2 <- dat_hist[c(47:48, 50:52), domain]
# calculate accuracy
acc_w2 <- forecast::accuracy(val_w2, hist_w2)
# Update relevant columns for the row
dat$mean_error_w2[i] <- acc_w2 [1]
dat$root_mean_sqr_error_w2[i] <- acc_w2 [2]
dat$mean_abs_error_w2[i] <- acc_w2 [3]
dat$mean_percent_error_w2[i] <- acc_w2 [4]
dat$mean_abs_percent_error_w2[i] <- acc[5]
dat$MASE1_w2[i] <- computeMASE(val_w2 , dat_hist[1:46, domain], hist_w2, 1)
}
# Chunk 36: Compare forecast RMSE to naive approach - phase 2
# Compare each prediction's RMSE score to the two types of naive approaches generated and create a cutoff score, indicating whether the row's RMSE value is greater or less than the naive forecast's RMSE value
dat$RMSE_cutoff_Naive_linear_w2 <- NA
dat$RMSE_cutoff_Naive_rwf_w2 <- NA
for (i in 1:length(domains)) {
cutoff1_w2 <- dat$root_mean_sqr_error_w2[which(dat$domain == domains[i] & dat$Method %in% "Naive - linear" & dat$phase == 2)]
cutoff2_w2 <- dat$root_mean_sqr_error_w2[which(dat$domain == domains[i] & dat$Method %in% "Naive - rwf" & dat$phase == 2)]
list_val_w2 <- which(dat$phase == 2 & dat$domain == domains[i] & !dat$Method %in% c("Naive - rwf", "Naive - linear", "Objective"))
for (n in 1:length(list_val_w2)) {
if (!is.na(dat$root_mean_sqr_error_w2[list_val_w2[n]]) & dat$root_mean_sqr_error_w2[list_val_w2[n]] < cutoff1_w2) {
dat$RMSE_cutoff_Naive_linear_w2[list_val_w2[n]] <- 0
} else if (!is.na(dat$root_mean_sqr_error_w2[list_val_w2[n]]) & dat$root_mean_sqr_error_w2[list_val_w2[n]] > cutoff1_w2){
dat$RMSE_cutoff_Naive_linear_w2[list_val_w2[n]] <- 1
}
if (!is.na(dat$root_mean_sqr_error_w2[list_val_w2[n]]) & dat$root_mean_sqr_error_w2[list_val_w2[n]] < cutoff2_w2) {
dat$RMSE_cutoff_Naive_rwf_w2[list_val_w2[n]] <- 0
} else if (!is.na(dat$root_mean_sqr_error_w2[list_val_w2[n]]) & dat$root_mean_sqr_error_w2[list_val_w2[n]] > cutoff2_w2){
dat$RMSE_cutoff_Naive_rwf_w2[list_val_w2[n]] <- 1
}
dat$compare_to_naive_linear_w2 <- factor(dat$RMSE_cutoff_Naive_linear_w2, levels = c(0, 1),
labels = c("Below Naive linear", "Above Naive linear"))
dat$compare_to_naive_rwf_w2 <- factor(dat$RMSE_cutoff_Naive_rwf_w2, levels = c(0, 1),
labels = c("Below Naive rwf", "Above Naive rwf"))
# Chunk 37: Convert NAs to 0s
# correct certain variables so that NA responses are properly treated as 0s
dat$numpred[which(is.na(dat$numpred))] <- 0
dat$team_size[which(is.na(dat$team_size))] <- 1
dat$team_size.coded[which(is.na(dat$team_size.coded))] <- 1
dat$CounterFactual_Presence.Final[which(is.na(dat$CounterFactual_Presence.Final))] <- 0
# Chunk 38: Remove unnecessary columns
# Remove columns that were used during coding / review that are not required for analyses
dat <- dat[, c(7, 10, 21, 27, 29:49, 55:58, 60:71, 77:82, 92, 100:102, 104:112, 122, 127:128, 130, 132:138, 165, 169:179, 181:202)]
# Chunk 39: TournamentStart column
# Add column indicating whether team started in May 2020 or October 2020
dat$TournamentStart[dat$phase == 1 | (dat$phase == 2 & dat$revised == 1)] <- "May"
dat$TournamentStart[dat$phase == 2 & dat$revised == 0] <- "November"
# Add column indicating whether the forecast is a new one or an updated one
dat$ForecastisUpdated[dat$phase == 2 & dat$revised == 1] <- "Updated in Nov"
dat$ForecastisUpdated[dat$phase == 2 & dat$revised == 0] <- "Novel Forecast in November"
# Chunk 41: output files
setwd("~/GitHub/Forecasting-Tournament") #change directory to save int he general space
write.csv(dat, "Wave1+2data.csv")
write.csv(demographics_unique, "Wave1+2demographics.csv")
# write.csv(dat_long, "wave1+2data_long_2021-06-30.csv")
# write.csv(dat_lay, "Wave1_Lay sample.csv")
# write.csv(dat_hist, "historical_data_2021-05-19.csv")
write.csv(dat_comp_1, "team_size.csv")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)
options(max.print = 20000, scipen = 1000)
# Chunk 2: Global Variables
# indicates the linetype used in all graphs
lineStyle <- "loess"
# xAxis <- scale_x_continuous(breaks=seq(2, 19, 2))
# xAxis2 <- scale_x_continuous(breaks=seq(-11, 13, 4))
# list of domains
domains <- c("lifesat", "posaffect", "negaffect", "ideoldem",  "ideolrep",  "polar", "iasian", "easian", "iafric", "eafric", "igend", "egend")
# Chunk 3: Functions
pct_change <- function(previous, new, as_decimal = FALSE) {
x <- abs(((new - previous) / previous) * 100)
if (as_decimal) x <- x / 100
return(x)
}
# Chunk 4: setup working directory
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
# Chunk 5: historical data
# import 46 months of historical values up to October 2020
dat_hist <- read.csv("historical_data.csv", stringsAsFactors = FALSE)
# Create a list of trends for each domain, ordered in the same manner as domains variable up above
hist_trend <- list()
for (i in 1:length(domains)) {
trend <- dat_hist[40, domains[i]] - dat_hist[1, domains[i]]
hist_trend[[i]] <- trend
}
# Chunk 6: Import Data
# filters by completion time, so that prolific sample excludes predictions that took less than 50 seconds to make
dat <- read.csv("Wave1+2data.csv", stringsAsFactors = FALSE)
# data set below does not filter lay sample by completion time
# dat <- read.csv("Wave1+2data_coded_2021-05-18.csv", stringsAsFactors = FALSE)
# list of notable columns and what they mean:
# * some columns are omitted because they will be removed / are redundant
# phase - value of 1 indicates submission was received during phase 1 (June 2020), value of 2 indicates submission was received during phase 2 (November 2020)
# isExpert - indicates whether submission is by an academic (1) or layperson (0)
dat$isExpert.factor <- factor(dat$isExpert, levels = c(0,1), labels = c("Prolific", "Academic"))
# revised - indicates whether a team submitted to both phase 1 & 2 of the tournament (i.e. submitted in June and then sent a revised submission in November)
# domain - indicates which domain the forecast is for. Shorthand is used here with the following terms referring to each domain:
# lifesat = Life Satisfaction
# posaffect = Positive Affect
# negaffect = Negative Affect
# ideoldem = Political Ideology - Democrat
# ideolrep = Political Ideology - Republican
# polar = Political Polarization
# iasian = Implicit Asian-American Bias
# easian = Explicit Asian-American Bias
# iafric = Implicit African-American Bias
# eafric = Explicit African-American Bias
# igend = Implicit Gender-Career Bias
# egend = Explicit Gender-Career Bias
# Month.1 - Month.18 columns list participant predictions for a given domain.
#   All phase 1 (June) predictions range from Month.1 - Month.12
#   All phase 2 (November) predictions range from Month.7 - Month.18
# mean_error - output of forecast package's accuracy() function - displays the mean error (ME) of Month.1 - Month.6 predictions compared to the objective data
# root_mean_sqr_error - displays the root mean square error (RMSE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_error - displays the root mean absolute error (MAE) of Month.1 - Month.6 predictions compared to the objective data
# mean_percent_error - displays the mean percent error (MPE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_percent_error - displays the mean absolute percent error (MAPE) of Month.1 - Month.6 predictions compared to the objective data
# mean_abs_scaled_error_1 - MASE computed using custom computeMASE function
# mean_abs_scaled_error_2 - MASE computed using Metrics::mase function
# RMSE_cutoff - whether the prediction's RMSE is less than or greater than a naive forecast for the same time period
dat$RMSE_cutoff_Naive_linear.factor <- factor(dat$RMSE_cutoff_Naive_linear, levels = c(0, 1), labels = c("below cutoff", "above cutoff"))
dat$RMSE_cutoff_Naive_rwf.factor <- factor(dat$RMSE_cutoff_Naive_rwf, levels = c(0, 1), labels = c("below cutoff", "above cutoff"))
# confidence - indicates on scale of 1-7 how confident participants were in their predictions
# subexpert - indicates on scale of 1-7 the participant's self-reported expertise in the domain they are predicting
# pub - the number of publications the team has made on the predicted domain
# model, theory, parameters - all contain participant written responses regarding what model they used, what theory they relied on, and what conditionals they considered
# numpred - number of conditionals (beyond the domain predicted) that participants considered in their prediction
# covidcondyn - whether covid-19 was considered as a conditional in their forecast
# datatrain - whether participants used the forecast data that was provided to them
# counterfact & othercounter - written response indicating the counterfactual participants considered
# counter_imp & othercountim - how important they consider their counterfactual to be
# Method - indicates forecasting method used to generate forecast - either Intuition/Theory, Data-Driven, Mixed, Simulation, or Objective - latter category is used to indicate the objective data for each domain for Months 1-6
# Method.coded - 1 - Intuition / 2 - Theory / 3 - Data-driven / 4 - Mixed / 5 - Objective / 6 - Naive - linear / 7 - Naive - rwf
dat$Method.code[dat$Method.coded==1]<-"Intuition/Theory"
dat$Method.code[dat$Method.coded==2]<-"Intuition/Theory"
dat$Method.code[dat$Method.coded==3]<-"Data-Driven"
dat$Method.code[dat$Method.coded==4]<-"Hybrid"
dat$Method.code[dat$Method.coded==5]<-"Ground Truth"
dat$Method.code[dat$Method.coded==6]<-"Naive-linear"
dat$Method.code[dat$Method.coded==7]<-"Naive-rfw"
dat$Method.code[dat$isExpert==0]<-"Lay People"
# Method.complex - ONLY PHASE 1, coded 1-3 scale indicating whether the Data-driven or Mixed method used is simple (e.g., regression to the mean), moderate (e.g., auto-regression w time lag, univariate time series), or complex (e.g., ARIMA, dynamic econometric model)
dat$Method.complex.factor <- factor(dat$Method.complex, levels = c(1:3), labels = c("simple", "moderate", "complex"))
# team_size.coded - self-reported measure indicating number of team-members in the team
# team_expertise - written response of team's general expertise
# FOLLOWING VARIABLES ARE EXCLUSIVE TO LAY SAMPLE because it consists entirely of individuals whereas academic sample consists of teams
# Age (num)
# Sex (1 = Male, 2 = Female, 3 = Prefer not to say)
dat$Sex.factor <- factor(dat$Sex, levels = c(1:3), labels = c("Male", "Female", "Prefer not to say"))
# Genderident (1 = trans/woman, 2= trans/man, 3= genderqueer, 4 = Prefer not to say, 5 = other)
dat$Genderident.factor <- factor(dat$Genderident, levels = c(1:5), labels = c("trans/woman", "trans/man", "genderqueer", "Prefer not to say", "other"))
# education (1-8 = less than highschool, high school, some college, Vocation or technical school, Bachelor's, Master's, Doctorate, Professional degree)
dat$education.factor <- factor(dat$Education, levels = c(1:8), labels = c("less than highschool", "high school", "some college", "Vocation or technical school", "Bachelor's", "Master's", "Doctorate", "Professional degree"))
# occupation (written response)
# Ethnicity
dat$Ethnicity.factor <- factor(dat$Ethnicity, levels = c(1:9), labels = c("Aboriginal/Native", "Asian", "Black", "White", "Middle Eastern", "Hispanic", "East Indian", "Mixed Race", "Other/Not Listed"))
# Religion
dat$Religion.factor <- factor(dat$Religion, levels = c(1:10), labels = c("Buddhist", "Christian - Catholic", "Christian - Protestant", "Christian - Other", "Hindu", "Jewish", "Muslim", "Sikh", "Other", "Non-Religious"))
# Income
dat$Income.factor <- factor(dat$Income, levels = c(1:8), labels = c("Under $15,000", "$15,001 - $25,000", "$25,001 - $35,000", "$35,001 - $50,000", "$50,001 - $75,000", "$75,001 - $100,000", "$100,001 - $150,000", "Over $150,000"))
# Residential Area
dat$Residential.Area.factor <- factor(dat$Residential.Area, levels = c(1:3), labels = c("Urban", "Suburban", "Rural"))
# Whether the team is multi-disciplinary (1) or mono (0)
dat$multi_dis.factor <- factor(dat$is_multidisciplinary, levels = c(0, 1), labels = c("Single domain expertise", "Multi domain expertise"))
write.csv(dat,"dat_for_analyses.csv")
# Chunk 7: Data - long format + absolute percent difference
# set dataframe to long format
dat_long <- pivot_longer(dat, cols = starts_with("Month"), names_to = "Month", names_prefix = "Month.")
dat_long$Month <- as.numeric(dat_long$Month)
# exclude rows without values in the "value" column
dat_long <- filter(dat_long, !is.na(value))
# add column to store difference values as change compared to objective results for that given month/domain
dat_long$value.dif <- as.numeric(NA)
# for each of the 12 domains:
for (i in 1:length(domains)) {
# Retrieve row with correct historical value for the domain
hist <-  dat[which(dat$domain == domains[i] & dat$Method.coded == 5), ]
for (n in 1:12) {
# retrieve all rows from dat_long that match the domain + Month n and calculate the correct absolute percent difference
histval <- hist[1, paste0("Month.", n)]
predval <- dat_long[which(dat_long$domain == domains[i] & dat_long$Month == n), "value" ]
dat_long[which(dat_long$domain == domains[i] & dat_long$Month == n), "value.dif" ] <- pct_change(histval, predval)
}
# create subsetted version that only includes
# dat_long <- dat_long %>% subset(flag_lay_response == 0 | is.na(flag_lay_response))
dat_long$Method.code[dat_long$Method.coded==1]<-"Intuition/Theory"
dat_long$Method.code[dat_long$Method.coded==2]<-"Intuition/Theory"
dat_long$Method.code[dat_long$Method.coded==3]<-"Data-Driven"
dat_long$Method.code[dat_long$Method.coded==4]<-"Hybrid"
dat_long$Method.code[dat_long$Method.coded==5]<-"Ground Truth"
dat_long$Method.code[dat_long$Method.coded==6]<-"Naive-linear"
dat_long$Method.code[dat_long$Method.coded==7]<-"Naive-rfw"
dat_long$Method.code[dat_long$isExpert==0]<-"Lay People"
write.csv(dat_long,"dat_long.csv")
# Chunk 8: Import Team member Demographic info
# contains demographics info from participants who responded to the survey. Team names have been corrected to match those in the dat_exp dataframe
dat_demo <- read.csv("Wave1+2demographics.csv", stringsAsFactors = FALSE)
# demo_1 - participant name
# demo_2 - participant email
# education - 1-5 indicating current role: undergrad, grad, postdoc/fellow, Professor, Other (with text entry)
# educaton2 - 1-5 indicating how much education they have: some uni/college, bachelors, masters, PhD, Other
# gender - 1 = Male, 2 = Female
# org - what kind of organization they're affiliated with - 1 = college/university, 2 = government, 3 = Private Company, 4 = self-employed, 5 = other
# expertise 1 & 2 - written responses on areas of expertise
# prevtournament - Whether they participated in a previous forecasting tournament 1 = Yes, 2 = No
# prevtour_list - written response of previous tournaments
# creating factor columns for the following variables:
# Academic sample - academic position
dat_demo$position.factor <- factor(dat_demo$education, levels = c(1:5), labels = c("Undergrad", "Grad", "Postdoc/fellow", "Professor", "Other"))
# Academic sample - education attained
dat_demo$education.factor <- factor(dat_demo$education, levels = c(1:5), labels = c("some uni/college", "bachelors", "masters", "PhD", "Other"))
# Academic sample - sex
dat_demo$sex_acad.factor <- factor(dat_demo$gender, levels = c(1:3), labels = c("Male", "Female", "Other"))
# Academic sample - organization/affiliation
dat_demo$org.factor <- factor(dat_demo$org, levels = c(1:5), labels = c("College/University", "Government", "Private Company", "Self-Employed", "Other"))
# Chunk 9: Academic sample descriptives
#datasets that are filtered by phase (1 = May, 2 = November)
phase1 <- filter(dat, phase == 1)
phase2 <- filter(dat, phase == 2)
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1)
phase2_exp <-filter(phase2, isExpert == 1)
# dataset that only includes academic predictions
academic_only <- filter(dat, isExpert == 1)
# Number of predictions by project phase + group
num_forecast <- dat %>% group_by(phase, isExpert.factor) %>%
dplyr::summarise(
N = length(isExpert.factor),
Percent =  N / nrow(dat)
)
print(num_forecast)
# Number of teams per phase
team_num <- academic_only %>% group_by(phase) %>%
dplyr::summarise(
numberOfTeams = length(unique(team_name))
)
# Number of teams total
team_num_total <- length(unique(academic_only$team_name))
# 121 teams total, 86 teams participated during phase 1 (88th team is NA because I didn't filter out lay sample and 87th team indicated their predictions were for another country), 72 during phase 2
# Filter so that only one row per team is retained
unique_teams <- academic_only[!duplicated(academic_only$team_name),]
describe(unique_teams$team_size.coded)
#    vars   n mean   sd median trimmed mad min max range skew kurtosis   se
# X1    1 105 1.66 1.16      1     1.4   0   1   7     6 2.04     4.32 0.11
# team size ranged from 1-7, n = 100, Md = 1, M = 1.67
# 1 was the most common team size (65%)
# Summarize spread of teams size (does not exclude NAs)
as.data.frame(table(unique_teams$team_size.coded))
#   team_size.coded  N               Percent
# 1         1 70 0.5737704918032786594
# 2         2 16 0.1311475409836065642
# 3         3 10 0.0819672131147540922
# 4         4  5 0.0409836065573770461
# 5         5  3 0.0245901639344262291
# 6         7  1 0.0081967213114754103
# 7        NA 17 0.1393442622950819554
# Filter data set by project wave
phase1_team <- filter(unique_teams, team_name %in% phase1$team_name)
# distribution of team size for phase 1
as.data.frame(table(phase1_team$team_size.coded))
#   team_size.coded  N              Percent
# 1         1 48 0.551724137931034475
# 2         2 12 0.137931034482758619
# 3         3  5 0.057471264367816091
# 4         4  4 0.045977011494252873
# 5         5  2 0.022988505747126436
# 6         7  1 0.011494252873563218
# 7        NA 15 0.172413793103448287
phase2_team <- filter(unique_teams, team_name %in% phase2$team_name)
# distribution of team size for phase 2
as.data.frame(table(phase2_team$team_size.coded))
# Number of predictions below/above RMSE cutoff
# overall
as.data.frame(table(phase1_exp$RMSE_cutoff_Naive_linear.factor))
#   RMSE_cutoff.factor     N
#
# 1 below cutoff          109 - 30%
# 2 above cutoff         251  - 70%
# 70% of predictions were above the RMSE cutoff
# Per domain
naive_RMSE_domain <- phase1_exp %>% group_by(domain, RMSE_cutoff_Naive_linear.factor) %>%
dplyr::summarise(
N = length(RMSE_cutoff_Naive_linear.factor)
)
naive_RMSE_domain$Percent <- NA
for (i in 1:nrow(naive_RMSE_domain)) {
filter <- filter(phase1_exp, domain == naive_RMSE_domain$domain[i])
naive_RMSE_domain$Percent[i] <- naive_RMSE_domain$N[i] / nrow(filter)
}
# Implicit Asian bias, explicit African American, and positive affect were all 100% above the cutoff
# More than 60% of predictions for implicit gender, ideology-republican, and ideology-democrat were below the cutoff
# look at multi-disciplinarity
multidisciplinarity <- phase1_exp %>% group_by(is_multidisciplinary) %>%
dplyr::summarise(
N = length(is_multidisciplinary),
Percent = N / nrow(phase1_exp)
)
#   is_multidisciplinary     N Percent
#
# 1                    0   301  0.836
# 2                    1    20  0.0556
# 3                   NA    39  0.108
# Chunk 10: Prolific Descriptives
# List of descriptives for prolific sample
# filter sample to only include unflagged Prolific responses
dat_lay_demo <- subset(dat, isExpert == 0 & flag_lay_response == 0)
# time spent on upload task
time_spent_desc_up <- describe(dat_lay_demo$time_upload)
#    vars    n   mean     sd median trimmed   mad min     max   range skew kurtosis   se
# X1    1 2226 126.69 200.94   75.1   87.48 68.64   0 3434.49 3434.49 6.47    75.26 4.26
age_stats <- describe(dat_lay_demo$Age)
#    vars    n  mean    sd median trimmed mad min max range skew kurtosis   se
# X1    1 2200 29.94 10.18     28    28.5 8.9  18  78    60 1.33     1.95 0.22
#Education
prolific_edu <- dat_lay_demo %>% group_by(education.factor) %>%
dplyr::summarise(
N = length(education.factor),
Percent =  N / nrow(dat_lay_demo)
)
as.data.frame(table(dat_lay_demo$education.factor))
#   education.factor                 N Percent
#
# 1 less than highschool             5 0.00340
# 2 high school                    114 0.0776
# 3 some college                   341 0.232
# 4 Vocation or technical school    59 0.0401
# 5 Bachelor's                     582 0.396
# 6 Master's                       226 0.154
# 7 Doctorate                       24 0.0163
# 8 Professional degree             41 0.0279
# 9 NA                              78 0.0531
# Ethnicity
prolific_eth <- dat_lay_demo %>% group_by(Ethnicity.factor) %>%
dplyr::summarise(
N = length(Ethnicity.factor),
Percent =  N / nrow(dat_lay_demo)
)
as.data.frame(table(dat_lay_demo$Ethnicity.factor))
#    Ethnicity.factor      N Percent
#
#  1 Aboriginal/Native    10 0.00680
#  2 Asian               237 0.161
#  3 Black               131 0.0891
#  4 White               828 0.563
#  5 Middle Eastern       10 0.00680
#  6 Hispanic            103 0.0701
#  7 East Indian          11 0.00748
#  8 Mixed Race           48 0.0327
#  9 Other/Not Listed     11 0.00748
# 10 NA                   81 0.0551
# Religion
prolific_rel <- dat_lay_demo %>% group_by(Religion.factor) %>%
dplyr::summarise(
N = length(Religion.factor),
Percent =  N / nrow(dat_lay_demo)
)
#    Religion.factor            N  Percent
#
#  1 Buddhist                  29 0.0197
#  2 Christian - Catholic     199 0.135
#  3 Christian - Protestant   214 0.146
#  4 Christian - Other        131 0.0891
#  5 Hindu                     27 0.0184
#  6 Jewish                    36 0.0245
#  7 Muslim                    57 0.0388
#  8 Sikh                       2 0.00136
#  9 Other                     57 0.0388
# 10 Non-Religious            638 0.434
# 11 NA                        80 0.0544
# Politics
prolific_pol <- dat_lay_demo %>% group_by(Politics_1) %>%
dplyr::summarise(
N = length(Politics_1),
Percent =  N / nrow(dat_lay_demo)
)
#   Politics_1     N Percent
#
# 1          1   343  0.233
# 2          2   313  0.213
# 3          3   192  0.131
# 4          4   300  0.204
# 5          5   128  0.0871
# 6          6    84  0.0571
# 7          7    32  0.0218
# 8         NA    78  0.0531
# Residential Area
prolific_res <- dat_lay_demo %>% group_by(Residential.Area.factor) %>%
dplyr::summarise(
N = length(Residential.Area.factor),
Percent =  N / nrow(dat_lay_demo)
)
#   Residential.Area.factor     N Percent
#
# 1 Urban                     452  0.307
# 2 Suburban                  791  0.538
# 3 Rural                     147  0.1
# 4 NA                         80  0.0544
# Income
prolific_inc <- dat_lay_demo %>% group_by(Income.factor) %>%
dplyr::summarise(
N = length(Income.factor),
Percent =  N / nrow(dat_lay_demo)
)
#   Income.factor           N Percent
#
# 1 Under $15,000          92  0.0626
# 2 $15,001 - $25,000     106  0.0721
# 3 $25,001 - $35,000     129  0.0878
# 4 $35,001 - $50,000     179  0.122
# 5 $50,001 - $75,000     292  0.199
# 6 $75,001 - $100,000    227  0.154
# 7 $100,001 - $150,000   189  0.129
# 8 Over $150,000         165  0.112
# 9 NA                     91  0.0619
knitr::opts_chunk$set(echo = TRUE)
library(forecast)
library(psych)
library(tidyverse)
library(irr)
library(lme4)
library(ggplot2)
library(tidyr)
library(emmeans)
library(car)
library(jtools)
library(dplyr)
library(ggsci)
library(dplyr)
library(Hmisc)
options(max.print = 20000, scipen = 1000)
setwd("~/GitHub/Forecasting-Tournament") #igor's working directory
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 & !is.na(Method.code))
#datasets that are filtered by phase (1 = May submission, 2 = November submission)
phase1 <- filter(dat, phase == 1& !is.na(Method.code))
phase2 <- filter(dat, phase == 2& !is.na(Method.code))
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1& !is.na(Method.code))
phase2_exp <-filter(phase2, isExpert == 1& !is.na(Method.code))
pd <- position_dodge(0.7) # move them .07 to the left and right
dat_long$Month7<-dat_long$Month-7
dat_long_phase2<-dat_long %>%filter(!(phase == 1 & revised == 1)& !is.na(Method.code)& Method.code!="Ground Truth"& Method.code!="Naive-linear"&Method.code!="Naive-rfw" & Month %in% c(7,8,9,10,11,12))
#get ground truth markers (subset)
objective2<-as.data.frame(filter(dat_long,phase != 1 & !is.na(Method.code)& Method.code=="Ground Truth" & (Month >6|Month<13) ))
## EXAMINE EFFECTS OF new teams at phase 2 vs. OG teams who updated their forecasts: Just ACADEMICS
##revised  - Indicates whether or not the team has a matching submission in both phase 1 & 2 for the same domain
academic_only$updated<-ifelse(academic_only$ForecastisUpdate==1,"Revised in Nov",ifelse(academic_only$ForecastisUpdate==0,"May",NA))
table(academic_only$academic_only)
table(academic_only$ForecastisUpdated)
table9dat$ForecastisUpdated
table(dat$ForecastisUpdated)
dat <- read.csv("dat_for_analyses.csv", stringsAsFactors = FALSE)
dat_long <- read.csv("dat_long.csv", stringsAsFactors = FALSE)
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 & !is.na(Method.code))
#datasets that are filtered by phase (1 = May submission, 2 = November submission)
phase1 <- filter(dat, phase == 1& !is.na(Method.code))
phase2 <- filter(dat, phase == 2& !is.na(Method.code))
# Phase 1 & 2further filtered to only include academics won't be necessary once we have updated objective data
phase1_exp <- filter(phase1, isExpert == 1& !is.na(Method.code))
phase2_exp <-filter(phase2, isExpert == 1& !is.na(Method.code))
table(dat$ForecastisUpdated)
117/12
254/12
table(academic_only$ForecastisUpdated)
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1 & !is.na(Method.code))
table(academic_only$ForecastisUpdated)
table(dat$ForecastisUpdated,dat$isExpert)
# dataset that only includes academic predictions and those who provided open-ended data
academic_only <- filter(dat, isExpert == 1)
table(academic_only$ForecastisUpdated)
